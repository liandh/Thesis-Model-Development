{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "from torchvision.transforms import functional as F\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset for property images\n",
    "class PropertyImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(('.jpg', '.png'))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutout:\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, x):\n",
    "        w, h = x.shape[2], x.shape[1]  # Use shape instead of size\n",
    "        mask = torch.ones((1, h, w), dtype=torch.float32)\n",
    "        for _ in range(self.n_holes):\n",
    "            y = random.randint(0, h)\n",
    "            x_coord = random.randint(0, w)  # Renamed to avoid conflict with the x parameter\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x_coord - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x_coord + self.length // 2, 0, w)\n",
    "            mask[:, y1:y2, x1:x2] = 0\n",
    "        return x * mask\n",
    "\n",
    "# Define SimCLR augmentations (two views for contrastive learning)\n",
    "class SimCLRTransform:\n",
    "    def __init__(self):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224, scale=(0.2, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n",
    "            transforms.ToTensor(),  # Move this line up\n",
    "            Cutout(n_holes=1, length=20),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.transform(x), self.transform(x)  # Two augmented versions of the same image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, batch_size, temperature=0.5):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "        self.mask = self._get_correlated_mask()\n",
    "\n",
    "    def _get_correlated_mask(self):\n",
    "        N = self.batch_size * 2\n",
    "        mask = torch.ones((N, N), dtype=bool)\n",
    "        mask.fill_diagonal_(False)\n",
    "        for i in range(self.batch_size):\n",
    "            mask[i, i + self.batch_size] = False\n",
    "            mask[i + self.batch_size, i] = False\n",
    "        return mask\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        N = self.batch_size * 2\n",
    "        z = torch.cat((z_i, z_j), dim=0)\n",
    "        similarity_matrix = torch.matmul(z, z.T) / self.temperature\n",
    "\n",
    "        mask = self.mask.to(z.device)\n",
    "        positives = torch.cat([\n",
    "            torch.diag(similarity_matrix, self.batch_size),\n",
    "            torch.diag(similarity_matrix, -self.batch_size)\n",
    "        ]).unsqueeze(1)\n",
    "\n",
    "        negatives = similarity_matrix[mask].view(N, -1)\n",
    "        logits = torch.cat((positives, negatives), dim=1)\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(z.device)\n",
    "\n",
    "        loss = self.criterion(logits, labels)\n",
    "        loss /= N\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SimCLR model\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_model, out_dim):\n",
    "        super(SimCLR, self).__init__()\n",
    "        self.backbone = nn.Sequential(*list(base_model.children())[:-1])  # Remove the classification layer\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(base_model.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x).squeeze()  # Get the backbone representation\n",
    "        z = self.projection_head(h)  # Get the projection\n",
    "        return h, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the SimCLR model\n",
    "def train_simclr(image_folder, epochs=10, batch_size=32, lr=3e-4):\n",
    "    print(\"Starting SimCLR training process...\")\n",
    "    transform = SimCLRTransform()\n",
    "    dataset = PropertyImageDataset(image_folder=image_folder, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    print(f\"Dataset contains {len(dataset)} images.\")\n",
    "    print(\"Initializing model and optimizer...\")\n",
    "\n",
    "    base_model = models.resnet50(weights='ResNet50_Weights.DEFAULT')  # Load ResNet50 with updated weights\n",
    "    simclr_model = SimCLR(base_model, out_dim=128)\n",
    "    optimizer = optim.Adam(simclr_model.parameters(), lr=lr)\n",
    "    criterion = NTXentLoss(batch_size=batch_size)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    simclr_model = simclr_model.to(device)\n",
    "    print(f\"Model moved to {device}.\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Starting epoch {epoch + 1} of {epochs}...\")\n",
    "        epoch_loss = 0\n",
    "        for step, (x_i, x_j) in enumerate(dataloader):\n",
    "            x_i, x_j = x_i.to(device), x_j.to(device)\n",
    "\n",
    "            # Forward pass for both augmented views\n",
    "            h_i, z_i = simclr_model(x_i)\n",
    "            h_j, z_j = simclr_model(x_j)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(z_i, z_j)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print the progress of training\n",
    "            current_image_idx = step * batch_size\n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}], Step [{step}/{len(dataloader)}], \"\n",
    "                  f\"Image [{current_image_idx + 1}/{len(dataset)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] completed. Average Loss: {epoch_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(simclr_model.state_dict(), 'simclr_model1.pth')\n",
    "    print(\"Training complete. Model saved as 'simclr_model1.pth'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SimCLR training process...\n",
      "Dataset contains 8158 images.\n",
      "Initializing model and optimizer...\n",
      "Model moved to cuda.\n",
      "Starting epoch 1 of 10...\n",
      "Epoch [1/10], Step [0/254], Image [1/8158], Loss: 4.0706\n",
      "Epoch [1/10], Step [1/254], Image [33/8158], Loss: 4.0285\n",
      "Epoch [1/10], Step [2/254], Image [65/8158], Loss: 3.9384\n",
      "Epoch [1/10], Step [3/254], Image [97/8158], Loss: 3.7931\n",
      "Epoch [1/10], Step [4/254], Image [129/8158], Loss: 3.5261\n",
      "Epoch [1/10], Step [5/254], Image [161/8158], Loss: 3.3340\n",
      "Epoch [1/10], Step [6/254], Image [193/8158], Loss: 3.2721\n",
      "Epoch [1/10], Step [7/254], Image [225/8158], Loss: 2.9448\n",
      "Epoch [1/10], Step [8/254], Image [257/8158], Loss: 3.2044\n",
      "Epoch [1/10], Step [9/254], Image [289/8158], Loss: 2.8147\n",
      "Epoch [1/10], Step [10/254], Image [321/8158], Loss: 2.8128\n",
      "Epoch [1/10], Step [11/254], Image [353/8158], Loss: 2.9969\n",
      "Epoch [1/10], Step [12/254], Image [385/8158], Loss: 2.7205\n",
      "Epoch [1/10], Step [13/254], Image [417/8158], Loss: 2.8277\n",
      "Epoch [1/10], Step [14/254], Image [449/8158], Loss: 2.6450\n",
      "Epoch [1/10], Step [15/254], Image [481/8158], Loss: 2.3650\n",
      "Epoch [1/10], Step [16/254], Image [513/8158], Loss: 2.2805\n",
      "Epoch [1/10], Step [17/254], Image [545/8158], Loss: 2.2103\n",
      "Epoch [1/10], Step [18/254], Image [577/8158], Loss: 2.4640\n",
      "Epoch [1/10], Step [19/254], Image [609/8158], Loss: 2.5398\n",
      "Epoch [1/10], Step [20/254], Image [641/8158], Loss: 1.8989\n",
      "Epoch [1/10], Step [21/254], Image [673/8158], Loss: 2.4443\n",
      "Epoch [1/10], Step [22/254], Image [705/8158], Loss: 2.2915\n",
      "Epoch [1/10], Step [23/254], Image [737/8158], Loss: 2.2715\n",
      "Epoch [1/10], Step [24/254], Image [769/8158], Loss: 2.0245\n",
      "Epoch [1/10], Step [25/254], Image [801/8158], Loss: 1.7765\n",
      "Epoch [1/10], Step [26/254], Image [833/8158], Loss: 1.8990\n",
      "Epoch [1/10], Step [27/254], Image [865/8158], Loss: 1.5598\n",
      "Epoch [1/10], Step [28/254], Image [897/8158], Loss: 1.8780\n",
      "Epoch [1/10], Step [29/254], Image [929/8158], Loss: 1.9250\n",
      "Epoch [1/10], Step [30/254], Image [961/8158], Loss: 1.7938\n",
      "Epoch [1/10], Step [31/254], Image [993/8158], Loss: 1.8900\n",
      "Epoch [1/10], Step [32/254], Image [1025/8158], Loss: 1.9231\n",
      "Epoch [1/10], Step [33/254], Image [1057/8158], Loss: 1.9036\n",
      "Epoch [1/10], Step [34/254], Image [1089/8158], Loss: 1.9526\n",
      "Epoch [1/10], Step [35/254], Image [1121/8158], Loss: 1.9277\n",
      "Epoch [1/10], Step [36/254], Image [1153/8158], Loss: 1.7829\n",
      "Epoch [1/10], Step [37/254], Image [1185/8158], Loss: 1.8659\n",
      "Epoch [1/10], Step [38/254], Image [1217/8158], Loss: 1.5801\n",
      "Epoch [1/10], Step [39/254], Image [1249/8158], Loss: 1.4779\n",
      "Epoch [1/10], Step [40/254], Image [1281/8158], Loss: 1.6347\n",
      "Epoch [1/10], Step [41/254], Image [1313/8158], Loss: 1.5466\n",
      "Epoch [1/10], Step [42/254], Image [1345/8158], Loss: 1.3221\n",
      "Epoch [1/10], Step [43/254], Image [1377/8158], Loss: 1.8124\n",
      "Epoch [1/10], Step [44/254], Image [1409/8158], Loss: 1.4030\n",
      "Epoch [1/10], Step [45/254], Image [1441/8158], Loss: 1.9486\n",
      "Epoch [1/10], Step [46/254], Image [1473/8158], Loss: 1.8956\n",
      "Epoch [1/10], Step [47/254], Image [1505/8158], Loss: 1.2467\n",
      "Epoch [1/10], Step [48/254], Image [1537/8158], Loss: 1.3298\n",
      "Epoch [1/10], Step [49/254], Image [1569/8158], Loss: 1.1568\n",
      "Epoch [1/10], Step [50/254], Image [1601/8158], Loss: 1.9377\n",
      "Epoch [1/10], Step [51/254], Image [1633/8158], Loss: 1.5220\n",
      "Epoch [1/10], Step [52/254], Image [1665/8158], Loss: 1.3716\n",
      "Epoch [1/10], Step [53/254], Image [1697/8158], Loss: 1.1611\n",
      "Epoch [1/10], Step [54/254], Image [1729/8158], Loss: 1.3819\n",
      "Epoch [1/10], Step [55/254], Image [1761/8158], Loss: 1.1257\n",
      "Epoch [1/10], Step [56/254], Image [1793/8158], Loss: 1.9149\n",
      "Epoch [1/10], Step [57/254], Image [1825/8158], Loss: 1.3501\n",
      "Epoch [1/10], Step [58/254], Image [1857/8158], Loss: 0.9691\n",
      "Epoch [1/10], Step [59/254], Image [1889/8158], Loss: 1.1536\n",
      "Epoch [1/10], Step [60/254], Image [1921/8158], Loss: 1.0059\n",
      "Epoch [1/10], Step [61/254], Image [1953/8158], Loss: 1.7465\n",
      "Epoch [1/10], Step [62/254], Image [1985/8158], Loss: 1.3052\n",
      "Epoch [1/10], Step [63/254], Image [2017/8158], Loss: 1.3676\n",
      "Epoch [1/10], Step [64/254], Image [2049/8158], Loss: 0.9701\n",
      "Epoch [1/10], Step [65/254], Image [2081/8158], Loss: 1.5308\n",
      "Epoch [1/10], Step [66/254], Image [2113/8158], Loss: 0.6810\n",
      "Epoch [1/10], Step [67/254], Image [2145/8158], Loss: 1.8760\n",
      "Epoch [1/10], Step [68/254], Image [2177/8158], Loss: 1.6479\n",
      "Epoch [1/10], Step [69/254], Image [2209/8158], Loss: 1.7947\n",
      "Epoch [1/10], Step [70/254], Image [2241/8158], Loss: 1.0001\n",
      "Epoch [1/10], Step [71/254], Image [2273/8158], Loss: 1.3842\n",
      "Epoch [1/10], Step [72/254], Image [2305/8158], Loss: 0.7309\n",
      "Epoch [1/10], Step [73/254], Image [2337/8158], Loss: 1.1236\n",
      "Epoch [1/10], Step [74/254], Image [2369/8158], Loss: 1.0114\n",
      "Epoch [1/10], Step [75/254], Image [2401/8158], Loss: 1.4418\n",
      "Epoch [1/10], Step [76/254], Image [2433/8158], Loss: 1.0134\n",
      "Epoch [1/10], Step [77/254], Image [2465/8158], Loss: 1.0680\n",
      "Epoch [1/10], Step [78/254], Image [2497/8158], Loss: 0.9588\n",
      "Epoch [1/10], Step [79/254], Image [2529/8158], Loss: 1.1981\n",
      "Epoch [1/10], Step [80/254], Image [2561/8158], Loss: 1.2617\n",
      "Epoch [1/10], Step [81/254], Image [2593/8158], Loss: 1.1979\n",
      "Epoch [1/10], Step [82/254], Image [2625/8158], Loss: 1.2139\n",
      "Epoch [1/10], Step [83/254], Image [2657/8158], Loss: 0.9050\n",
      "Epoch [1/10], Step [84/254], Image [2689/8158], Loss: 1.0797\n",
      "Epoch [1/10], Step [85/254], Image [2721/8158], Loss: 0.9681\n",
      "Epoch [1/10], Step [86/254], Image [2753/8158], Loss: 0.7422\n",
      "Epoch [1/10], Step [87/254], Image [2785/8158], Loss: 0.7801\n",
      "Epoch [1/10], Step [88/254], Image [2817/8158], Loss: 1.3048\n",
      "Epoch [1/10], Step [89/254], Image [2849/8158], Loss: 1.2868\n",
      "Epoch [1/10], Step [90/254], Image [2881/8158], Loss: 1.4099\n",
      "Epoch [1/10], Step [91/254], Image [2913/8158], Loss: 1.2712\n",
      "Epoch [1/10], Step [92/254], Image [2945/8158], Loss: 1.0072\n",
      "Epoch [1/10], Step [93/254], Image [2977/8158], Loss: 0.7127\n",
      "Epoch [1/10], Step [94/254], Image [3009/8158], Loss: 1.2281\n",
      "Epoch [1/10], Step [95/254], Image [3041/8158], Loss: 0.9879\n",
      "Epoch [1/10], Step [96/254], Image [3073/8158], Loss: 0.9635\n",
      "Epoch [1/10], Step [97/254], Image [3105/8158], Loss: 0.9970\n",
      "Epoch [1/10], Step [98/254], Image [3137/8158], Loss: 0.9180\n",
      "Epoch [1/10], Step [99/254], Image [3169/8158], Loss: 1.7742\n",
      "Epoch [1/10], Step [100/254], Image [3201/8158], Loss: 1.4049\n",
      "Epoch [1/10], Step [101/254], Image [3233/8158], Loss: 1.3255\n",
      "Epoch [1/10], Step [102/254], Image [3265/8158], Loss: 0.5316\n",
      "Epoch [1/10], Step [103/254], Image [3297/8158], Loss: 0.9203\n",
      "Epoch [1/10], Step [104/254], Image [3329/8158], Loss: 1.0204\n",
      "Epoch [1/10], Step [105/254], Image [3361/8158], Loss: 0.8440\n",
      "Epoch [1/10], Step [106/254], Image [3393/8158], Loss: 0.7236\n",
      "Epoch [1/10], Step [107/254], Image [3425/8158], Loss: 1.0521\n",
      "Epoch [1/10], Step [108/254], Image [3457/8158], Loss: 1.2296\n",
      "Epoch [1/10], Step [109/254], Image [3489/8158], Loss: 1.0311\n",
      "Epoch [1/10], Step [110/254], Image [3521/8158], Loss: 0.7408\n",
      "Epoch [1/10], Step [111/254], Image [3553/8158], Loss: 1.0784\n",
      "Epoch [1/10], Step [112/254], Image [3585/8158], Loss: 0.8865\n",
      "Epoch [1/10], Step [113/254], Image [3617/8158], Loss: 0.9736\n",
      "Epoch [1/10], Step [114/254], Image [3649/8158], Loss: 0.9780\n",
      "Epoch [1/10], Step [115/254], Image [3681/8158], Loss: 0.8218\n",
      "Epoch [1/10], Step [116/254], Image [3713/8158], Loss: 1.0781\n",
      "Epoch [1/10], Step [117/254], Image [3745/8158], Loss: 1.2605\n",
      "Epoch [1/10], Step [118/254], Image [3777/8158], Loss: 0.5022\n",
      "Epoch [1/10], Step [119/254], Image [3809/8158], Loss: 1.2262\n",
      "Epoch [1/10], Step [120/254], Image [3841/8158], Loss: 1.0980\n",
      "Epoch [1/10], Step [121/254], Image [3873/8158], Loss: 0.8590\n",
      "Epoch [1/10], Step [122/254], Image [3905/8158], Loss: 0.8439\n",
      "Epoch [1/10], Step [123/254], Image [3937/8158], Loss: 0.9934\n",
      "Epoch [1/10], Step [124/254], Image [3969/8158], Loss: 0.6670\n",
      "Epoch [1/10], Step [125/254], Image [4001/8158], Loss: 0.9126\n",
      "Epoch [1/10], Step [126/254], Image [4033/8158], Loss: 0.5098\n",
      "Epoch [1/10], Step [127/254], Image [4065/8158], Loss: 1.0147\n",
      "Epoch [1/10], Step [128/254], Image [4097/8158], Loss: 1.2249\n",
      "Epoch [1/10], Step [129/254], Image [4129/8158], Loss: 0.4628\n",
      "Epoch [1/10], Step [130/254], Image [4161/8158], Loss: 1.2184\n",
      "Epoch [1/10], Step [131/254], Image [4193/8158], Loss: 1.0181\n",
      "Epoch [1/10], Step [132/254], Image [4225/8158], Loss: 0.9648\n",
      "Epoch [1/10], Step [133/254], Image [4257/8158], Loss: 0.9593\n",
      "Epoch [1/10], Step [134/254], Image [4289/8158], Loss: 0.5094\n",
      "Epoch [1/10], Step [135/254], Image [4321/8158], Loss: 1.0093\n",
      "Epoch [1/10], Step [136/254], Image [4353/8158], Loss: 0.9786\n",
      "Epoch [1/10], Step [137/254], Image [4385/8158], Loss: 1.2303\n",
      "Epoch [1/10], Step [138/254], Image [4417/8158], Loss: 1.3508\n",
      "Epoch [1/10], Step [139/254], Image [4449/8158], Loss: 0.5345\n",
      "Epoch [1/10], Step [140/254], Image [4481/8158], Loss: 1.3219\n",
      "Epoch [1/10], Step [141/254], Image [4513/8158], Loss: 0.6440\n",
      "Epoch [1/10], Step [142/254], Image [4545/8158], Loss: 0.4843\n",
      "Epoch [1/10], Step [143/254], Image [4577/8158], Loss: 0.7680\n",
      "Epoch [1/10], Step [144/254], Image [4609/8158], Loss: 0.9031\n",
      "Epoch [1/10], Step [145/254], Image [4641/8158], Loss: 0.8962\n",
      "Epoch [1/10], Step [146/254], Image [4673/8158], Loss: 0.6686\n",
      "Epoch [1/10], Step [147/254], Image [4705/8158], Loss: 1.2971\n",
      "Epoch [1/10], Step [148/254], Image [4737/8158], Loss: 0.5336\n",
      "Epoch [1/10], Step [149/254], Image [4769/8158], Loss: 0.9799\n",
      "Epoch [1/10], Step [150/254], Image [4801/8158], Loss: 0.7902\n",
      "Epoch [1/10], Step [151/254], Image [4833/8158], Loss: 1.0425\n",
      "Epoch [1/10], Step [152/254], Image [4865/8158], Loss: 1.0159\n",
      "Epoch [1/10], Step [153/254], Image [4897/8158], Loss: 1.0831\n",
      "Epoch [1/10], Step [154/254], Image [4929/8158], Loss: 1.2684\n",
      "Epoch [1/10], Step [155/254], Image [4961/8158], Loss: 0.7221\n",
      "Epoch [1/10], Step [156/254], Image [4993/8158], Loss: 0.8426\n",
      "Epoch [1/10], Step [157/254], Image [5025/8158], Loss: 1.5531\n",
      "Epoch [1/10], Step [158/254], Image [5057/8158], Loss: 0.8491\n",
      "Epoch [1/10], Step [159/254], Image [5089/8158], Loss: 1.1448\n",
      "Epoch [1/10], Step [160/254], Image [5121/8158], Loss: 0.6836\n",
      "Epoch [1/10], Step [161/254], Image [5153/8158], Loss: 0.5434\n",
      "Epoch [1/10], Step [162/254], Image [5185/8158], Loss: 0.7734\n",
      "Epoch [1/10], Step [163/254], Image [5217/8158], Loss: 0.6820\n",
      "Epoch [1/10], Step [164/254], Image [5249/8158], Loss: 0.8796\n",
      "Epoch [1/10], Step [165/254], Image [5281/8158], Loss: 1.1281\n",
      "Epoch [1/10], Step [166/254], Image [5313/8158], Loss: 0.8675\n",
      "Epoch [1/10], Step [167/254], Image [5345/8158], Loss: 0.7841\n",
      "Epoch [1/10], Step [168/254], Image [5377/8158], Loss: 0.6925\n",
      "Epoch [1/10], Step [169/254], Image [5409/8158], Loss: 1.1385\n",
      "Epoch [1/10], Step [170/254], Image [5441/8158], Loss: 0.5835\n",
      "Epoch [1/10], Step [171/254], Image [5473/8158], Loss: 0.8034\n",
      "Epoch [1/10], Step [172/254], Image [5505/8158], Loss: 0.8174\n",
      "Epoch [1/10], Step [173/254], Image [5537/8158], Loss: 0.6561\n",
      "Epoch [1/10], Step [174/254], Image [5569/8158], Loss: 0.2619\n",
      "Epoch [1/10], Step [175/254], Image [5601/8158], Loss: 0.7246\n",
      "Epoch [1/10], Step [176/254], Image [5633/8158], Loss: 0.9260\n",
      "Epoch [1/10], Step [177/254], Image [5665/8158], Loss: 1.1356\n",
      "Epoch [1/10], Step [178/254], Image [5697/8158], Loss: 0.5725\n",
      "Epoch [1/10], Step [179/254], Image [5729/8158], Loss: 0.6561\n",
      "Epoch [1/10], Step [180/254], Image [5761/8158], Loss: 0.9531\n",
      "Epoch [1/10], Step [181/254], Image [5793/8158], Loss: 0.6204\n",
      "Epoch [1/10], Step [182/254], Image [5825/8158], Loss: 0.6900\n",
      "Epoch [1/10], Step [183/254], Image [5857/8158], Loss: 0.9084\n",
      "Epoch [1/10], Step [184/254], Image [5889/8158], Loss: 0.9223\n",
      "Epoch [1/10], Step [185/254], Image [5921/8158], Loss: 1.2643\n",
      "Epoch [1/10], Step [186/254], Image [5953/8158], Loss: 0.5844\n",
      "Epoch [1/10], Step [187/254], Image [5985/8158], Loss: 1.0163\n",
      "Epoch [1/10], Step [188/254], Image [6017/8158], Loss: 0.5688\n",
      "Epoch [1/10], Step [189/254], Image [6049/8158], Loss: 0.7786\n",
      "Epoch [1/10], Step [190/254], Image [6081/8158], Loss: 0.3433\n",
      "Epoch [1/10], Step [191/254], Image [6113/8158], Loss: 0.7447\n",
      "Epoch [1/10], Step [192/254], Image [6145/8158], Loss: 0.7375\n",
      "Epoch [1/10], Step [193/254], Image [6177/8158], Loss: 0.8341\n",
      "Epoch [1/10], Step [194/254], Image [6209/8158], Loss: 0.5652\n",
      "Epoch [1/10], Step [195/254], Image [6241/8158], Loss: 0.6112\n",
      "Epoch [1/10], Step [196/254], Image [6273/8158], Loss: 0.4897\n",
      "Epoch [1/10], Step [197/254], Image [6305/8158], Loss: 0.2577\n",
      "Epoch [1/10], Step [198/254], Image [6337/8158], Loss: 0.3209\n",
      "Epoch [1/10], Step [199/254], Image [6369/8158], Loss: 1.0977\n",
      "Epoch [1/10], Step [200/254], Image [6401/8158], Loss: 0.5261\n",
      "Epoch [1/10], Step [201/254], Image [6433/8158], Loss: 0.8695\n",
      "Epoch [1/10], Step [202/254], Image [6465/8158], Loss: 0.5838\n",
      "Epoch [1/10], Step [203/254], Image [6497/8158], Loss: 0.6180\n",
      "Epoch [1/10], Step [204/254], Image [6529/8158], Loss: 0.6214\n",
      "Epoch [1/10], Step [205/254], Image [6561/8158], Loss: 0.8268\n",
      "Epoch [1/10], Step [206/254], Image [6593/8158], Loss: 0.7829\n",
      "Epoch [1/10], Step [207/254], Image [6625/8158], Loss: 1.1011\n",
      "Epoch [1/10], Step [208/254], Image [6657/8158], Loss: 0.6144\n",
      "Epoch [1/10], Step [209/254], Image [6689/8158], Loss: 0.5710\n",
      "Epoch [1/10], Step [210/254], Image [6721/8158], Loss: 0.7062\n",
      "Epoch [1/10], Step [211/254], Image [6753/8158], Loss: 0.5895\n",
      "Epoch [1/10], Step [212/254], Image [6785/8158], Loss: 0.4605\n",
      "Epoch [1/10], Step [213/254], Image [6817/8158], Loss: 0.4714\n",
      "Epoch [1/10], Step [214/254], Image [6849/8158], Loss: 1.0825\n",
      "Epoch [1/10], Step [215/254], Image [6881/8158], Loss: 0.5228\n",
      "Epoch [1/10], Step [216/254], Image [6913/8158], Loss: 0.9241\n",
      "Epoch [1/10], Step [217/254], Image [6945/8158], Loss: 0.7599\n",
      "Epoch [1/10], Step [218/254], Image [6977/8158], Loss: 0.8530\n",
      "Epoch [1/10], Step [219/254], Image [7009/8158], Loss: 0.8158\n",
      "Epoch [1/10], Step [220/254], Image [7041/8158], Loss: 0.9603\n",
      "Epoch [1/10], Step [221/254], Image [7073/8158], Loss: 0.8628\n",
      "Epoch [1/10], Step [222/254], Image [7105/8158], Loss: 1.0167\n",
      "Epoch [1/10], Step [223/254], Image [7137/8158], Loss: 0.6983\n",
      "Epoch [1/10], Step [224/254], Image [7169/8158], Loss: 0.8658\n",
      "Epoch [1/10], Step [225/254], Image [7201/8158], Loss: 0.7650\n",
      "Epoch [1/10], Step [226/254], Image [7233/8158], Loss: 1.0760\n",
      "Epoch [1/10], Step [227/254], Image [7265/8158], Loss: 0.7789\n",
      "Epoch [1/10], Step [228/254], Image [7297/8158], Loss: 0.4072\n",
      "Epoch [1/10], Step [229/254], Image [7329/8158], Loss: 0.7514\n",
      "Epoch [1/10], Step [230/254], Image [7361/8158], Loss: 0.7465\n",
      "Epoch [1/10], Step [231/254], Image [7393/8158], Loss: 0.6180\n",
      "Epoch [1/10], Step [232/254], Image [7425/8158], Loss: 0.4602\n",
      "Epoch [1/10], Step [233/254], Image [7457/8158], Loss: 0.7616\n",
      "Epoch [1/10], Step [234/254], Image [7489/8158], Loss: 0.6138\n",
      "Epoch [1/10], Step [235/254], Image [7521/8158], Loss: 0.8015\n",
      "Epoch [1/10], Step [236/254], Image [7553/8158], Loss: 0.8977\n",
      "Epoch [1/10], Step [237/254], Image [7585/8158], Loss: 0.9638\n",
      "Epoch [1/10], Step [238/254], Image [7617/8158], Loss: 0.6505\n",
      "Epoch [1/10], Step [239/254], Image [7649/8158], Loss: 0.6266\n",
      "Epoch [1/10], Step [240/254], Image [7681/8158], Loss: 1.1824\n",
      "Epoch [1/10], Step [241/254], Image [7713/8158], Loss: 0.5511\n",
      "Epoch [1/10], Step [242/254], Image [7745/8158], Loss: 0.3955\n",
      "Epoch [1/10], Step [243/254], Image [7777/8158], Loss: 0.9063\n",
      "Epoch [1/10], Step [244/254], Image [7809/8158], Loss: 0.7522\n",
      "Epoch [1/10], Step [245/254], Image [7841/8158], Loss: 0.9570\n",
      "Epoch [1/10], Step [246/254], Image [7873/8158], Loss: 0.3941\n",
      "Epoch [1/10], Step [247/254], Image [7905/8158], Loss: 0.3201\n",
      "Epoch [1/10], Step [248/254], Image [7937/8158], Loss: 0.7835\n",
      "Epoch [1/10], Step [249/254], Image [7969/8158], Loss: 1.3454\n",
      "Epoch [1/10], Step [250/254], Image [8001/8158], Loss: 1.1764\n",
      "Epoch [1/10], Step [251/254], Image [8033/8158], Loss: 0.8319\n",
      "Epoch [1/10], Step [252/254], Image [8065/8158], Loss: 0.7180\n",
      "Epoch [1/10], Step [253/254], Image [8097/8158], Loss: 0.5642\n",
      "Epoch [1/10] completed. Average Loss: 1.1883\n",
      "Starting epoch 2 of 10...\n",
      "Epoch [2/10], Step [0/254], Image [1/8158], Loss: 0.6826\n",
      "Epoch [2/10], Step [1/254], Image [33/8158], Loss: 0.4407\n",
      "Epoch [2/10], Step [2/254], Image [65/8158], Loss: 0.4323\n",
      "Epoch [2/10], Step [3/254], Image [97/8158], Loss: 0.7952\n",
      "Epoch [2/10], Step [4/254], Image [129/8158], Loss: 0.5327\n",
      "Epoch [2/10], Step [5/254], Image [161/8158], Loss: 0.7608\n",
      "Epoch [2/10], Step [6/254], Image [193/8158], Loss: 0.4989\n",
      "Epoch [2/10], Step [7/254], Image [225/8158], Loss: 0.5056\n",
      "Epoch [2/10], Step [8/254], Image [257/8158], Loss: 0.4936\n",
      "Epoch [2/10], Step [9/254], Image [289/8158], Loss: 0.9835\n",
      "Epoch [2/10], Step [10/254], Image [321/8158], Loss: 0.5688\n",
      "Epoch [2/10], Step [11/254], Image [353/8158], Loss: 0.4570\n",
      "Epoch [2/10], Step [12/254], Image [385/8158], Loss: 1.0385\n",
      "Epoch [2/10], Step [13/254], Image [417/8158], Loss: 0.8155\n",
      "Epoch [2/10], Step [14/254], Image [449/8158], Loss: 0.4014\n",
      "Epoch [2/10], Step [15/254], Image [481/8158], Loss: 0.5079\n",
      "Epoch [2/10], Step [16/254], Image [513/8158], Loss: 0.4202\n",
      "Epoch [2/10], Step [17/254], Image [545/8158], Loss: 0.4596\n",
      "Epoch [2/10], Step [18/254], Image [577/8158], Loss: 1.2134\n",
      "Epoch [2/10], Step [19/254], Image [609/8158], Loss: 1.0612\n",
      "Epoch [2/10], Step [20/254], Image [641/8158], Loss: 0.3266\n",
      "Epoch [2/10], Step [21/254], Image [673/8158], Loss: 0.7141\n",
      "Epoch [2/10], Step [22/254], Image [705/8158], Loss: 0.7769\n",
      "Epoch [2/10], Step [23/254], Image [737/8158], Loss: 0.3354\n",
      "Epoch [2/10], Step [24/254], Image [769/8158], Loss: 0.4434\n",
      "Epoch [2/10], Step [25/254], Image [801/8158], Loss: 0.4292\n",
      "Epoch [2/10], Step [26/254], Image [833/8158], Loss: 0.5763\n",
      "Epoch [2/10], Step [27/254], Image [865/8158], Loss: 1.0007\n",
      "Epoch [2/10], Step [28/254], Image [897/8158], Loss: 1.2232\n",
      "Epoch [2/10], Step [29/254], Image [929/8158], Loss: 0.7257\n",
      "Epoch [2/10], Step [30/254], Image [961/8158], Loss: 0.5354\n",
      "Epoch [2/10], Step [31/254], Image [993/8158], Loss: 0.7611\n",
      "Epoch [2/10], Step [32/254], Image [1025/8158], Loss: 0.9671\n",
      "Epoch [2/10], Step [33/254], Image [1057/8158], Loss: 0.6035\n",
      "Epoch [2/10], Step [34/254], Image [1089/8158], Loss: 0.7239\n",
      "Epoch [2/10], Step [35/254], Image [1121/8158], Loss: 0.6795\n",
      "Epoch [2/10], Step [36/254], Image [1153/8158], Loss: 0.8040\n",
      "Epoch [2/10], Step [37/254], Image [1185/8158], Loss: 0.4764\n",
      "Epoch [2/10], Step [38/254], Image [1217/8158], Loss: 0.4129\n",
      "Epoch [2/10], Step [39/254], Image [1249/8158], Loss: 0.9308\n",
      "Epoch [2/10], Step [40/254], Image [1281/8158], Loss: 0.5880\n",
      "Epoch [2/10], Step [41/254], Image [1313/8158], Loss: 0.8358\n",
      "Epoch [2/10], Step [42/254], Image [1345/8158], Loss: 0.2931\n",
      "Epoch [2/10], Step [43/254], Image [1377/8158], Loss: 0.9651\n",
      "Epoch [2/10], Step [44/254], Image [1409/8158], Loss: 0.6149\n",
      "Epoch [2/10], Step [45/254], Image [1441/8158], Loss: 1.0326\n",
      "Epoch [2/10], Step [46/254], Image [1473/8158], Loss: 0.9281\n",
      "Epoch [2/10], Step [47/254], Image [1505/8158], Loss: 0.3428\n",
      "Epoch [2/10], Step [48/254], Image [1537/8158], Loss: 0.4183\n",
      "Epoch [2/10], Step [49/254], Image [1569/8158], Loss: 1.6126\n",
      "Epoch [2/10], Step [50/254], Image [1601/8158], Loss: 1.1734\n",
      "Epoch [2/10], Step [51/254], Image [1633/8158], Loss: 0.8441\n",
      "Epoch [2/10], Step [52/254], Image [1665/8158], Loss: 0.3697\n",
      "Epoch [2/10], Step [53/254], Image [1697/8158], Loss: 0.2546\n",
      "Epoch [2/10], Step [54/254], Image [1729/8158], Loss: 0.4168\n",
      "Epoch [2/10], Step [55/254], Image [1761/8158], Loss: 1.0044\n",
      "Epoch [2/10], Step [56/254], Image [1793/8158], Loss: 0.3634\n",
      "Epoch [2/10], Step [57/254], Image [1825/8158], Loss: 0.7585\n",
      "Epoch [2/10], Step [58/254], Image [1857/8158], Loss: 0.7703\n",
      "Epoch [2/10], Step [59/254], Image [1889/8158], Loss: 1.1405\n",
      "Epoch [2/10], Step [60/254], Image [1921/8158], Loss: 0.7632\n",
      "Epoch [2/10], Step [61/254], Image [1953/8158], Loss: 0.8904\n",
      "Epoch [2/10], Step [62/254], Image [1985/8158], Loss: 0.5469\n",
      "Epoch [2/10], Step [63/254], Image [2017/8158], Loss: 0.8166\n",
      "Epoch [2/10], Step [64/254], Image [2049/8158], Loss: 0.6570\n",
      "Epoch [2/10], Step [65/254], Image [2081/8158], Loss: 0.7757\n",
      "Epoch [2/10], Step [66/254], Image [2113/8158], Loss: 0.5404\n",
      "Epoch [2/10], Step [67/254], Image [2145/8158], Loss: 0.4922\n",
      "Epoch [2/10], Step [68/254], Image [2177/8158], Loss: 0.6127\n",
      "Epoch [2/10], Step [69/254], Image [2209/8158], Loss: 0.6840\n",
      "Epoch [2/10], Step [70/254], Image [2241/8158], Loss: 0.3443\n",
      "Epoch [2/10], Step [71/254], Image [2273/8158], Loss: 0.3314\n",
      "Epoch [2/10], Step [72/254], Image [2305/8158], Loss: 0.9352\n",
      "Epoch [2/10], Step [73/254], Image [2337/8158], Loss: 0.4171\n",
      "Epoch [2/10], Step [74/254], Image [2369/8158], Loss: 0.5870\n",
      "Epoch [2/10], Step [75/254], Image [2401/8158], Loss: 0.3872\n",
      "Epoch [2/10], Step [76/254], Image [2433/8158], Loss: 0.4204\n",
      "Epoch [2/10], Step [77/254], Image [2465/8158], Loss: 0.9011\n",
      "Epoch [2/10], Step [78/254], Image [2497/8158], Loss: 0.7758\n",
      "Epoch [2/10], Step [79/254], Image [2529/8158], Loss: 0.6690\n",
      "Epoch [2/10], Step [80/254], Image [2561/8158], Loss: 0.8465\n",
      "Epoch [2/10], Step [81/254], Image [2593/8158], Loss: 0.6523\n",
      "Epoch [2/10], Step [82/254], Image [2625/8158], Loss: 0.5256\n",
      "Epoch [2/10], Step [83/254], Image [2657/8158], Loss: 0.4205\n",
      "Epoch [2/10], Step [84/254], Image [2689/8158], Loss: 0.2557\n",
      "Epoch [2/10], Step [85/254], Image [2721/8158], Loss: 0.5008\n",
      "Epoch [2/10], Step [86/254], Image [2753/8158], Loss: 0.3872\n",
      "Epoch [2/10], Step [87/254], Image [2785/8158], Loss: 0.5491\n",
      "Epoch [2/10], Step [88/254], Image [2817/8158], Loss: 1.0702\n",
      "Epoch [2/10], Step [89/254], Image [2849/8158], Loss: 0.5594\n",
      "Epoch [2/10], Step [90/254], Image [2881/8158], Loss: 1.3310\n",
      "Epoch [2/10], Step [91/254], Image [2913/8158], Loss: 0.7034\n",
      "Epoch [2/10], Step [92/254], Image [2945/8158], Loss: 0.7820\n",
      "Epoch [2/10], Step [93/254], Image [2977/8158], Loss: 0.8654\n",
      "Epoch [2/10], Step [94/254], Image [3009/8158], Loss: 0.5028\n",
      "Epoch [2/10], Step [95/254], Image [3041/8158], Loss: 1.1208\n",
      "Epoch [2/10], Step [96/254], Image [3073/8158], Loss: 0.3844\n",
      "Epoch [2/10], Step [97/254], Image [3105/8158], Loss: 0.9004\n",
      "Epoch [2/10], Step [98/254], Image [3137/8158], Loss: 0.2659\n",
      "Epoch [2/10], Step [99/254], Image [3169/8158], Loss: 0.3750\n",
      "Epoch [2/10], Step [100/254], Image [3201/8158], Loss: 0.8960\n",
      "Epoch [2/10], Step [101/254], Image [3233/8158], Loss: 0.5359\n",
      "Epoch [2/10], Step [102/254], Image [3265/8158], Loss: 1.0369\n",
      "Epoch [2/10], Step [103/254], Image [3297/8158], Loss: 0.8078\n",
      "Epoch [2/10], Step [104/254], Image [3329/8158], Loss: 0.6966\n",
      "Epoch [2/10], Step [105/254], Image [3361/8158], Loss: 0.6210\n",
      "Epoch [2/10], Step [106/254], Image [3393/8158], Loss: 0.5487\n",
      "Epoch [2/10], Step [107/254], Image [3425/8158], Loss: 0.3964\n",
      "Epoch [2/10], Step [108/254], Image [3457/8158], Loss: 0.5589\n",
      "Epoch [2/10], Step [109/254], Image [3489/8158], Loss: 0.4856\n",
      "Epoch [2/10], Step [110/254], Image [3521/8158], Loss: 0.8201\n",
      "Epoch [2/10], Step [111/254], Image [3553/8158], Loss: 0.5496\n",
      "Epoch [2/10], Step [112/254], Image [3585/8158], Loss: 1.0272\n",
      "Epoch [2/10], Step [113/254], Image [3617/8158], Loss: 0.6009\n",
      "Epoch [2/10], Step [114/254], Image [3649/8158], Loss: 0.8403\n",
      "Epoch [2/10], Step [115/254], Image [3681/8158], Loss: 0.3017\n",
      "Epoch [2/10], Step [116/254], Image [3713/8158], Loss: 0.5436\n",
      "Epoch [2/10], Step [117/254], Image [3745/8158], Loss: 0.7469\n",
      "Epoch [2/10], Step [118/254], Image [3777/8158], Loss: 0.4241\n",
      "Epoch [2/10], Step [119/254], Image [3809/8158], Loss: 1.1952\n",
      "Epoch [2/10], Step [120/254], Image [3841/8158], Loss: 0.2958\n",
      "Epoch [2/10], Step [121/254], Image [3873/8158], Loss: 0.7480\n",
      "Epoch [2/10], Step [122/254], Image [3905/8158], Loss: 0.6585\n",
      "Epoch [2/10], Step [123/254], Image [3937/8158], Loss: 0.9662\n",
      "Epoch [2/10], Step [124/254], Image [3969/8158], Loss: 0.2481\n",
      "Epoch [2/10], Step [125/254], Image [4001/8158], Loss: 0.7340\n",
      "Epoch [2/10], Step [126/254], Image [4033/8158], Loss: 0.5741\n",
      "Epoch [2/10], Step [127/254], Image [4065/8158], Loss: 0.4746\n",
      "Epoch [2/10], Step [128/254], Image [4097/8158], Loss: 0.3085\n",
      "Epoch [2/10], Step [129/254], Image [4129/8158], Loss: 0.3556\n",
      "Epoch [2/10], Step [130/254], Image [4161/8158], Loss: 0.8109\n",
      "Epoch [2/10], Step [131/254], Image [4193/8158], Loss: 0.5649\n",
      "Epoch [2/10], Step [132/254], Image [4225/8158], Loss: 0.8356\n",
      "Epoch [2/10], Step [133/254], Image [4257/8158], Loss: 0.4252\n",
      "Epoch [2/10], Step [134/254], Image [4289/8158], Loss: 0.7596\n",
      "Epoch [2/10], Step [135/254], Image [4321/8158], Loss: 0.2132\n",
      "Epoch [2/10], Step [136/254], Image [4353/8158], Loss: 0.6340\n",
      "Epoch [2/10], Step [137/254], Image [4385/8158], Loss: 0.6211\n",
      "Epoch [2/10], Step [138/254], Image [4417/8158], Loss: 0.9596\n",
      "Epoch [2/10], Step [139/254], Image [4449/8158], Loss: 0.3115\n",
      "Epoch [2/10], Step [140/254], Image [4481/8158], Loss: 0.6681\n",
      "Epoch [2/10], Step [141/254], Image [4513/8158], Loss: 0.4801\n",
      "Epoch [2/10], Step [142/254], Image [4545/8158], Loss: 0.6684\n",
      "Epoch [2/10], Step [143/254], Image [4577/8158], Loss: 0.4609\n",
      "Epoch [2/10], Step [144/254], Image [4609/8158], Loss: 0.8702\n",
      "Epoch [2/10], Step [145/254], Image [4641/8158], Loss: 0.6719\n",
      "Epoch [2/10], Step [146/254], Image [4673/8158], Loss: 0.7351\n",
      "Epoch [2/10], Step [147/254], Image [4705/8158], Loss: 0.5232\n",
      "Epoch [2/10], Step [148/254], Image [4737/8158], Loss: 0.3778\n",
      "Epoch [2/10], Step [149/254], Image [4769/8158], Loss: 0.3391\n",
      "Epoch [2/10], Step [150/254], Image [4801/8158], Loss: 0.5353\n",
      "Epoch [2/10], Step [151/254], Image [4833/8158], Loss: 0.7605\n",
      "Epoch [2/10], Step [152/254], Image [4865/8158], Loss: 0.4869\n",
      "Epoch [2/10], Step [153/254], Image [4897/8158], Loss: 0.5151\n",
      "Epoch [2/10], Step [154/254], Image [4929/8158], Loss: 0.7941\n",
      "Epoch [2/10], Step [155/254], Image [4961/8158], Loss: 0.4094\n",
      "Epoch [2/10], Step [156/254], Image [4993/8158], Loss: 0.4425\n",
      "Epoch [2/10], Step [157/254], Image [5025/8158], Loss: 0.9460\n",
      "Epoch [2/10], Step [158/254], Image [5057/8158], Loss: 0.3854\n",
      "Epoch [2/10], Step [159/254], Image [5089/8158], Loss: 0.7722\n",
      "Epoch [2/10], Step [160/254], Image [5121/8158], Loss: 0.2481\n",
      "Epoch [2/10], Step [161/254], Image [5153/8158], Loss: 0.7858\n",
      "Epoch [2/10], Step [162/254], Image [5185/8158], Loss: 0.7822\n",
      "Epoch [2/10], Step [163/254], Image [5217/8158], Loss: 0.3911\n",
      "Epoch [2/10], Step [164/254], Image [5249/8158], Loss: 0.4479\n",
      "Epoch [2/10], Step [165/254], Image [5281/8158], Loss: 0.4817\n",
      "Epoch [2/10], Step [166/254], Image [5313/8158], Loss: 0.2861\n",
      "Epoch [2/10], Step [167/254], Image [5345/8158], Loss: 0.4463\n",
      "Epoch [2/10], Step [168/254], Image [5377/8158], Loss: 0.5125\n",
      "Epoch [2/10], Step [169/254], Image [5409/8158], Loss: 0.6630\n",
      "Epoch [2/10], Step [170/254], Image [5441/8158], Loss: 0.3252\n",
      "Epoch [2/10], Step [171/254], Image [5473/8158], Loss: 0.4784\n",
      "Epoch [2/10], Step [172/254], Image [5505/8158], Loss: 0.3112\n",
      "Epoch [2/10], Step [173/254], Image [5537/8158], Loss: 0.2724\n",
      "Epoch [2/10], Step [174/254], Image [5569/8158], Loss: 0.6114\n",
      "Epoch [2/10], Step [175/254], Image [5601/8158], Loss: 0.3207\n",
      "Epoch [2/10], Step [176/254], Image [5633/8158], Loss: 0.3357\n",
      "Epoch [2/10], Step [177/254], Image [5665/8158], Loss: 0.3725\n",
      "Epoch [2/10], Step [178/254], Image [5697/8158], Loss: 0.2530\n",
      "Epoch [2/10], Step [179/254], Image [5729/8158], Loss: 0.6459\n",
      "Epoch [2/10], Step [180/254], Image [5761/8158], Loss: 0.6589\n",
      "Epoch [2/10], Step [181/254], Image [5793/8158], Loss: 0.4363\n",
      "Epoch [2/10], Step [182/254], Image [5825/8158], Loss: 0.4738\n",
      "Epoch [2/10], Step [183/254], Image [5857/8158], Loss: 0.4076\n",
      "Epoch [2/10], Step [184/254], Image [5889/8158], Loss: 0.2119\n",
      "Epoch [2/10], Step [185/254], Image [5921/8158], Loss: 0.4780\n",
      "Epoch [2/10], Step [186/254], Image [5953/8158], Loss: 0.7588\n",
      "Epoch [2/10], Step [187/254], Image [5985/8158], Loss: 1.0262\n",
      "Epoch [2/10], Step [188/254], Image [6017/8158], Loss: 0.8285\n",
      "Epoch [2/10], Step [189/254], Image [6049/8158], Loss: 0.9727\n",
      "Epoch [2/10], Step [190/254], Image [6081/8158], Loss: 0.7867\n",
      "Epoch [2/10], Step [191/254], Image [6113/8158], Loss: 0.5597\n",
      "Epoch [2/10], Step [192/254], Image [6145/8158], Loss: 0.5691\n",
      "Epoch [2/10], Step [193/254], Image [6177/8158], Loss: 0.4487\n",
      "Epoch [2/10], Step [194/254], Image [6209/8158], Loss: 0.4403\n",
      "Epoch [2/10], Step [195/254], Image [6241/8158], Loss: 0.4245\n",
      "Epoch [2/10], Step [196/254], Image [6273/8158], Loss: 0.3511\n",
      "Epoch [2/10], Step [197/254], Image [6305/8158], Loss: 0.5771\n",
      "Epoch [2/10], Step [198/254], Image [6337/8158], Loss: 0.5051\n",
      "Epoch [2/10], Step [199/254], Image [6369/8158], Loss: 0.6756\n",
      "Epoch [2/10], Step [200/254], Image [6401/8158], Loss: 0.5854\n",
      "Epoch [2/10], Step [201/254], Image [6433/8158], Loss: 0.6440\n",
      "Epoch [2/10], Step [202/254], Image [6465/8158], Loss: 0.5874\n",
      "Epoch [2/10], Step [203/254], Image [6497/8158], Loss: 0.3563\n",
      "Epoch [2/10], Step [204/254], Image [6529/8158], Loss: 0.2948\n",
      "Epoch [2/10], Step [205/254], Image [6561/8158], Loss: 0.5348\n",
      "Epoch [2/10], Step [206/254], Image [6593/8158], Loss: 0.7123\n",
      "Epoch [2/10], Step [207/254], Image [6625/8158], Loss: 0.5325\n",
      "Epoch [2/10], Step [208/254], Image [6657/8158], Loss: 0.2935\n",
      "Epoch [2/10], Step [209/254], Image [6689/8158], Loss: 0.3202\n",
      "Epoch [2/10], Step [210/254], Image [6721/8158], Loss: 0.4830\n",
      "Epoch [2/10], Step [211/254], Image [6753/8158], Loss: 0.5524\n",
      "Epoch [2/10], Step [212/254], Image [6785/8158], Loss: 0.2566\n",
      "Epoch [2/10], Step [213/254], Image [6817/8158], Loss: 1.1656\n",
      "Epoch [2/10], Step [214/254], Image [6849/8158], Loss: 0.3650\n",
      "Epoch [2/10], Step [215/254], Image [6881/8158], Loss: 0.6105\n",
      "Epoch [2/10], Step [216/254], Image [6913/8158], Loss: 0.3855\n",
      "Epoch [2/10], Step [217/254], Image [6945/8158], Loss: 0.6333\n",
      "Epoch [2/10], Step [218/254], Image [6977/8158], Loss: 0.6381\n",
      "Epoch [2/10], Step [219/254], Image [7009/8158], Loss: 0.8769\n",
      "Epoch [2/10], Step [220/254], Image [7041/8158], Loss: 0.4451\n",
      "Epoch [2/10], Step [221/254], Image [7073/8158], Loss: 0.6388\n",
      "Epoch [2/10], Step [222/254], Image [7105/8158], Loss: 0.5961\n",
      "Epoch [2/10], Step [223/254], Image [7137/8158], Loss: 0.3537\n",
      "Epoch [2/10], Step [224/254], Image [7169/8158], Loss: 0.4061\n",
      "Epoch [2/10], Step [225/254], Image [7201/8158], Loss: 0.5658\n",
      "Epoch [2/10], Step [226/254], Image [7233/8158], Loss: 0.4993\n",
      "Epoch [2/10], Step [227/254], Image [7265/8158], Loss: 0.7458\n",
      "Epoch [2/10], Step [228/254], Image [7297/8158], Loss: 0.2959\n",
      "Epoch [2/10], Step [229/254], Image [7329/8158], Loss: 0.5633\n",
      "Epoch [2/10], Step [230/254], Image [7361/8158], Loss: 0.7029\n",
      "Epoch [2/10], Step [231/254], Image [7393/8158], Loss: 0.3978\n",
      "Epoch [2/10], Step [232/254], Image [7425/8158], Loss: 1.0742\n",
      "Epoch [2/10], Step [233/254], Image [7457/8158], Loss: 0.2798\n",
      "Epoch [2/10], Step [234/254], Image [7489/8158], Loss: 0.5412\n",
      "Epoch [2/10], Step [235/254], Image [7521/8158], Loss: 0.4451\n",
      "Epoch [2/10], Step [236/254], Image [7553/8158], Loss: 0.7183\n",
      "Epoch [2/10], Step [237/254], Image [7585/8158], Loss: 0.6470\n",
      "Epoch [2/10], Step [238/254], Image [7617/8158], Loss: 0.5176\n",
      "Epoch [2/10], Step [239/254], Image [7649/8158], Loss: 0.9149\n",
      "Epoch [2/10], Step [240/254], Image [7681/8158], Loss: 0.5620\n",
      "Epoch [2/10], Step [241/254], Image [7713/8158], Loss: 0.7082\n",
      "Epoch [2/10], Step [242/254], Image [7745/8158], Loss: 0.8966\n",
      "Epoch [2/10], Step [243/254], Image [7777/8158], Loss: 0.3886\n",
      "Epoch [2/10], Step [244/254], Image [7809/8158], Loss: 0.7157\n",
      "Epoch [2/10], Step [245/254], Image [7841/8158], Loss: 0.7540\n",
      "Epoch [2/10], Step [246/254], Image [7873/8158], Loss: 0.5591\n",
      "Epoch [2/10], Step [247/254], Image [7905/8158], Loss: 0.4175\n",
      "Epoch [2/10], Step [248/254], Image [7937/8158], Loss: 0.5242\n",
      "Epoch [2/10], Step [249/254], Image [7969/8158], Loss: 0.5505\n",
      "Epoch [2/10], Step [250/254], Image [8001/8158], Loss: 0.4549\n",
      "Epoch [2/10], Step [251/254], Image [8033/8158], Loss: 0.2875\n",
      "Epoch [2/10], Step [252/254], Image [8065/8158], Loss: 0.6311\n",
      "Epoch [2/10], Step [253/254], Image [8097/8158], Loss: 0.6711\n",
      "Epoch [2/10] completed. Average Loss: 0.6087\n",
      "Starting epoch 3 of 10...\n",
      "Epoch [3/10], Step [0/254], Image [1/8158], Loss: 0.5790\n",
      "Epoch [3/10], Step [1/254], Image [33/8158], Loss: 0.3489\n",
      "Epoch [3/10], Step [2/254], Image [65/8158], Loss: 0.6145\n",
      "Epoch [3/10], Step [3/254], Image [97/8158], Loss: 0.4688\n",
      "Epoch [3/10], Step [4/254], Image [129/8158], Loss: 0.5513\n",
      "Epoch [3/10], Step [5/254], Image [161/8158], Loss: 0.8689\n",
      "Epoch [3/10], Step [6/254], Image [193/8158], Loss: 0.5476\n",
      "Epoch [3/10], Step [7/254], Image [225/8158], Loss: 0.3765\n",
      "Epoch [3/10], Step [8/254], Image [257/8158], Loss: 0.3644\n",
      "Epoch [3/10], Step [9/254], Image [289/8158], Loss: 0.8804\n",
      "Epoch [3/10], Step [10/254], Image [321/8158], Loss: 0.3753\n",
      "Epoch [3/10], Step [11/254], Image [353/8158], Loss: 0.2464\n",
      "Epoch [3/10], Step [12/254], Image [385/8158], Loss: 0.5959\n",
      "Epoch [3/10], Step [13/254], Image [417/8158], Loss: 0.3727\n",
      "Epoch [3/10], Step [14/254], Image [449/8158], Loss: 0.3895\n",
      "Epoch [3/10], Step [15/254], Image [481/8158], Loss: 0.6858\n",
      "Epoch [3/10], Step [16/254], Image [513/8158], Loss: 0.5873\n",
      "Epoch [3/10], Step [17/254], Image [545/8158], Loss: 0.2429\n",
      "Epoch [3/10], Step [18/254], Image [577/8158], Loss: 0.4405\n",
      "Epoch [3/10], Step [19/254], Image [609/8158], Loss: 0.8272\n",
      "Epoch [3/10], Step [20/254], Image [641/8158], Loss: 0.4998\n",
      "Epoch [3/10], Step [21/254], Image [673/8158], Loss: 0.4956\n",
      "Epoch [3/10], Step [22/254], Image [705/8158], Loss: 0.3057\n",
      "Epoch [3/10], Step [23/254], Image [737/8158], Loss: 0.3776\n",
      "Epoch [3/10], Step [24/254], Image [769/8158], Loss: 0.3657\n",
      "Epoch [3/10], Step [25/254], Image [801/8158], Loss: 0.9097\n",
      "Epoch [3/10], Step [26/254], Image [833/8158], Loss: 0.4057\n",
      "Epoch [3/10], Step [27/254], Image [865/8158], Loss: 0.5452\n",
      "Epoch [3/10], Step [28/254], Image [897/8158], Loss: 0.4733\n",
      "Epoch [3/10], Step [29/254], Image [929/8158], Loss: 0.2045\n",
      "Epoch [3/10], Step [30/254], Image [961/8158], Loss: 0.4170\n",
      "Epoch [3/10], Step [31/254], Image [993/8158], Loss: 0.3548\n",
      "Epoch [3/10], Step [32/254], Image [1025/8158], Loss: 0.2112\n",
      "Epoch [3/10], Step [33/254], Image [1057/8158], Loss: 0.6267\n",
      "Epoch [3/10], Step [34/254], Image [1089/8158], Loss: 0.2380\n",
      "Epoch [3/10], Step [35/254], Image [1121/8158], Loss: 0.2465\n",
      "Epoch [3/10], Step [36/254], Image [1153/8158], Loss: 1.1518\n",
      "Epoch [3/10], Step [37/254], Image [1185/8158], Loss: 1.0357\n",
      "Epoch [3/10], Step [38/254], Image [1217/8158], Loss: 0.7598\n",
      "Epoch [3/10], Step [39/254], Image [1249/8158], Loss: 0.3218\n",
      "Epoch [3/10], Step [40/254], Image [1281/8158], Loss: 0.3982\n",
      "Epoch [3/10], Step [41/254], Image [1313/8158], Loss: 0.3236\n",
      "Epoch [3/10], Step [42/254], Image [1345/8158], Loss: 0.4499\n",
      "Epoch [3/10], Step [43/254], Image [1377/8158], Loss: 0.6970\n",
      "Epoch [3/10], Step [44/254], Image [1409/8158], Loss: 0.4910\n",
      "Epoch [3/10], Step [45/254], Image [1441/8158], Loss: 0.3114\n",
      "Epoch [3/10], Step [46/254], Image [1473/8158], Loss: 0.4430\n",
      "Epoch [3/10], Step [47/254], Image [1505/8158], Loss: 0.6330\n",
      "Epoch [3/10], Step [48/254], Image [1537/8158], Loss: 0.4915\n",
      "Epoch [3/10], Step [49/254], Image [1569/8158], Loss: 0.4617\n",
      "Epoch [3/10], Step [50/254], Image [1601/8158], Loss: 0.6480\n",
      "Epoch [3/10], Step [51/254], Image [1633/8158], Loss: 0.2821\n",
      "Epoch [3/10], Step [52/254], Image [1665/8158], Loss: 0.2764\n",
      "Epoch [3/10], Step [53/254], Image [1697/8158], Loss: 0.7548\n",
      "Epoch [3/10], Step [54/254], Image [1729/8158], Loss: 0.6664\n",
      "Epoch [3/10], Step [55/254], Image [1761/8158], Loss: 0.2427\n",
      "Epoch [3/10], Step [56/254], Image [1793/8158], Loss: 0.5561\n",
      "Epoch [3/10], Step [57/254], Image [1825/8158], Loss: 0.3503\n",
      "Epoch [3/10], Step [58/254], Image [1857/8158], Loss: 1.0151\n",
      "Epoch [3/10], Step [59/254], Image [1889/8158], Loss: 0.3470\n",
      "Epoch [3/10], Step [60/254], Image [1921/8158], Loss: 0.5504\n",
      "Epoch [3/10], Step [61/254], Image [1953/8158], Loss: 0.3639\n",
      "Epoch [3/10], Step [62/254], Image [1985/8158], Loss: 0.3510\n",
      "Epoch [3/10], Step [63/254], Image [2017/8158], Loss: 0.6619\n",
      "Epoch [3/10], Step [64/254], Image [2049/8158], Loss: 0.5232\n",
      "Epoch [3/10], Step [65/254], Image [2081/8158], Loss: 0.4544\n",
      "Epoch [3/10], Step [66/254], Image [2113/8158], Loss: 0.3630\n",
      "Epoch [3/10], Step [67/254], Image [2145/8158], Loss: 0.7497\n",
      "Epoch [3/10], Step [68/254], Image [2177/8158], Loss: 0.3045\n",
      "Epoch [3/10], Step [69/254], Image [2209/8158], Loss: 0.4068\n",
      "Epoch [3/10], Step [70/254], Image [2241/8158], Loss: 0.3346\n",
      "Epoch [3/10], Step [71/254], Image [2273/8158], Loss: 0.5342\n",
      "Epoch [3/10], Step [72/254], Image [2305/8158], Loss: 0.2504\n",
      "Epoch [3/10], Step [73/254], Image [2337/8158], Loss: 0.4989\n",
      "Epoch [3/10], Step [74/254], Image [2369/8158], Loss: 0.3097\n",
      "Epoch [3/10], Step [75/254], Image [2401/8158], Loss: 0.5605\n",
      "Epoch [3/10], Step [76/254], Image [2433/8158], Loss: 0.6655\n",
      "Epoch [3/10], Step [77/254], Image [2465/8158], Loss: 0.6187\n",
      "Epoch [3/10], Step [78/254], Image [2497/8158], Loss: 0.3319\n",
      "Epoch [3/10], Step [79/254], Image [2529/8158], Loss: 0.5420\n",
      "Epoch [3/10], Step [80/254], Image [2561/8158], Loss: 0.5251\n",
      "Epoch [3/10], Step [81/254], Image [2593/8158], Loss: 0.4121\n",
      "Epoch [3/10], Step [82/254], Image [2625/8158], Loss: 0.3715\n",
      "Epoch [3/10], Step [83/254], Image [2657/8158], Loss: 0.6009\n",
      "Epoch [3/10], Step [84/254], Image [2689/8158], Loss: 0.4591\n",
      "Epoch [3/10], Step [85/254], Image [2721/8158], Loss: 0.2043\n",
      "Epoch [3/10], Step [86/254], Image [2753/8158], Loss: 1.1012\n",
      "Epoch [3/10], Step [87/254], Image [2785/8158], Loss: 0.7387\n",
      "Epoch [3/10], Step [88/254], Image [2817/8158], Loss: 1.0088\n",
      "Epoch [3/10], Step [89/254], Image [2849/8158], Loss: 0.0746\n",
      "Epoch [3/10], Step [90/254], Image [2881/8158], Loss: 0.6272\n",
      "Epoch [3/10], Step [91/254], Image [2913/8158], Loss: 0.5695\n",
      "Epoch [3/10], Step [92/254], Image [2945/8158], Loss: 0.4751\n",
      "Epoch [3/10], Step [93/254], Image [2977/8158], Loss: 0.5012\n",
      "Epoch [3/10], Step [94/254], Image [3009/8158], Loss: 0.4722\n",
      "Epoch [3/10], Step [95/254], Image [3041/8158], Loss: 0.5687\n",
      "Epoch [3/10], Step [96/254], Image [3073/8158], Loss: 0.7278\n",
      "Epoch [3/10], Step [97/254], Image [3105/8158], Loss: 0.3624\n",
      "Epoch [3/10], Step [98/254], Image [3137/8158], Loss: 0.6045\n",
      "Epoch [3/10], Step [99/254], Image [3169/8158], Loss: 0.5158\n",
      "Epoch [3/10], Step [100/254], Image [3201/8158], Loss: 0.6442\n",
      "Epoch [3/10], Step [101/254], Image [3233/8158], Loss: 0.6159\n",
      "Epoch [3/10], Step [102/254], Image [3265/8158], Loss: 1.2527\n",
      "Epoch [3/10], Step [103/254], Image [3297/8158], Loss: 0.7955\n",
      "Epoch [3/10], Step [104/254], Image [3329/8158], Loss: 0.4407\n",
      "Epoch [3/10], Step [105/254], Image [3361/8158], Loss: 0.3436\n",
      "Epoch [3/10], Step [106/254], Image [3393/8158], Loss: 0.5689\n",
      "Epoch [3/10], Step [107/254], Image [3425/8158], Loss: 0.6986\n",
      "Epoch [3/10], Step [108/254], Image [3457/8158], Loss: 0.3640\n",
      "Epoch [3/10], Step [109/254], Image [3489/8158], Loss: 0.3676\n",
      "Epoch [3/10], Step [110/254], Image [3521/8158], Loss: 0.4962\n",
      "Epoch [3/10], Step [111/254], Image [3553/8158], Loss: 0.3465\n",
      "Epoch [3/10], Step [112/254], Image [3585/8158], Loss: 0.4214\n",
      "Epoch [3/10], Step [113/254], Image [3617/8158], Loss: 0.4611\n",
      "Epoch [3/10], Step [114/254], Image [3649/8158], Loss: 0.6650\n",
      "Epoch [3/10], Step [115/254], Image [3681/8158], Loss: 0.4208\n",
      "Epoch [3/10], Step [116/254], Image [3713/8158], Loss: 0.3573\n",
      "Epoch [3/10], Step [117/254], Image [3745/8158], Loss: 0.7661\n",
      "Epoch [3/10], Step [118/254], Image [3777/8158], Loss: 0.5324\n",
      "Epoch [3/10], Step [119/254], Image [3809/8158], Loss: 0.2093\n",
      "Epoch [3/10], Step [120/254], Image [3841/8158], Loss: 0.5688\n",
      "Epoch [3/10], Step [121/254], Image [3873/8158], Loss: 0.5626\n",
      "Epoch [3/10], Step [122/254], Image [3905/8158], Loss: 0.5243\n",
      "Epoch [3/10], Step [123/254], Image [3937/8158], Loss: 0.8953\n",
      "Epoch [3/10], Step [124/254], Image [3969/8158], Loss: 0.5181\n",
      "Epoch [3/10], Step [125/254], Image [4001/8158], Loss: 0.4884\n",
      "Epoch [3/10], Step [126/254], Image [4033/8158], Loss: 0.2051\n",
      "Epoch [3/10], Step [127/254], Image [4065/8158], Loss: 0.3619\n",
      "Epoch [3/10], Step [128/254], Image [4097/8158], Loss: 0.6264\n",
      "Epoch [3/10], Step [129/254], Image [4129/8158], Loss: 0.2685\n",
      "Epoch [3/10], Step [130/254], Image [4161/8158], Loss: 0.1774\n",
      "Epoch [3/10], Step [131/254], Image [4193/8158], Loss: 0.6396\n",
      "Epoch [3/10], Step [132/254], Image [4225/8158], Loss: 0.4964\n",
      "Epoch [3/10], Step [133/254], Image [4257/8158], Loss: 0.2159\n",
      "Epoch [3/10], Step [134/254], Image [4289/8158], Loss: 0.1906\n",
      "Epoch [3/10], Step [135/254], Image [4321/8158], Loss: 0.2186\n",
      "Epoch [3/10], Step [136/254], Image [4353/8158], Loss: 0.6864\n",
      "Epoch [3/10], Step [137/254], Image [4385/8158], Loss: 0.3153\n",
      "Epoch [3/10], Step [138/254], Image [4417/8158], Loss: 0.3680\n",
      "Epoch [3/10], Step [139/254], Image [4449/8158], Loss: 0.2281\n",
      "Epoch [3/10], Step [140/254], Image [4481/8158], Loss: 0.3560\n",
      "Epoch [3/10], Step [141/254], Image [4513/8158], Loss: 0.4938\n",
      "Epoch [3/10], Step [142/254], Image [4545/8158], Loss: 0.6352\n",
      "Epoch [3/10], Step [143/254], Image [4577/8158], Loss: 0.2508\n",
      "Epoch [3/10], Step [144/254], Image [4609/8158], Loss: 0.3209\n",
      "Epoch [3/10], Step [145/254], Image [4641/8158], Loss: 0.2577\n",
      "Epoch [3/10], Step [146/254], Image [4673/8158], Loss: 0.5152\n",
      "Epoch [3/10], Step [147/254], Image [4705/8158], Loss: 0.5436\n",
      "Epoch [3/10], Step [148/254], Image [4737/8158], Loss: 0.5123\n",
      "Epoch [3/10], Step [149/254], Image [4769/8158], Loss: 0.5529\n",
      "Epoch [3/10], Step [150/254], Image [4801/8158], Loss: 0.4254\n",
      "Epoch [3/10], Step [151/254], Image [4833/8158], Loss: 0.3176\n",
      "Epoch [3/10], Step [152/254], Image [4865/8158], Loss: 0.3954\n",
      "Epoch [3/10], Step [153/254], Image [4897/8158], Loss: 0.1868\n",
      "Epoch [3/10], Step [154/254], Image [4929/8158], Loss: 0.2559\n",
      "Epoch [3/10], Step [155/254], Image [4961/8158], Loss: 0.6424\n",
      "Epoch [3/10], Step [156/254], Image [4993/8158], Loss: 0.5968\n",
      "Epoch [3/10], Step [157/254], Image [5025/8158], Loss: 0.9460\n",
      "Epoch [3/10], Step [158/254], Image [5057/8158], Loss: 1.1142\n",
      "Epoch [3/10], Step [159/254], Image [5089/8158], Loss: 0.2097\n",
      "Epoch [3/10], Step [160/254], Image [5121/8158], Loss: 0.2305\n",
      "Epoch [3/10], Step [161/254], Image [5153/8158], Loss: 0.7343\n",
      "Epoch [3/10], Step [162/254], Image [5185/8158], Loss: 0.3417\n",
      "Epoch [3/10], Step [163/254], Image [5217/8158], Loss: 0.4159\n",
      "Epoch [3/10], Step [164/254], Image [5249/8158], Loss: 0.3771\n",
      "Epoch [3/10], Step [165/254], Image [5281/8158], Loss: 0.4723\n",
      "Epoch [3/10], Step [166/254], Image [5313/8158], Loss: 0.7316\n",
      "Epoch [3/10], Step [167/254], Image [5345/8158], Loss: 0.2633\n",
      "Epoch [3/10], Step [168/254], Image [5377/8158], Loss: 0.3365\n",
      "Epoch [3/10], Step [169/254], Image [5409/8158], Loss: 0.3693\n",
      "Epoch [3/10], Step [170/254], Image [5441/8158], Loss: 0.3618\n",
      "Epoch [3/10], Step [171/254], Image [5473/8158], Loss: 0.3397\n",
      "Epoch [3/10], Step [172/254], Image [5505/8158], Loss: 0.7680\n",
      "Epoch [3/10], Step [173/254], Image [5537/8158], Loss: 0.1532\n",
      "Epoch [3/10], Step [174/254], Image [5569/8158], Loss: 0.3000\n",
      "Epoch [3/10], Step [175/254], Image [5601/8158], Loss: 0.2761\n",
      "Epoch [3/10], Step [176/254], Image [5633/8158], Loss: 1.1685\n",
      "Epoch [3/10], Step [177/254], Image [5665/8158], Loss: 0.4658\n",
      "Epoch [3/10], Step [178/254], Image [5697/8158], Loss: 0.7045\n",
      "Epoch [3/10], Step [179/254], Image [5729/8158], Loss: 0.2200\n",
      "Epoch [3/10], Step [180/254], Image [5761/8158], Loss: 0.7740\n",
      "Epoch [3/10], Step [181/254], Image [5793/8158], Loss: 0.3021\n",
      "Epoch [3/10], Step [182/254], Image [5825/8158], Loss: 0.5826\n",
      "Epoch [3/10], Step [183/254], Image [5857/8158], Loss: 0.2599\n",
      "Epoch [3/10], Step [184/254], Image [5889/8158], Loss: 0.2825\n",
      "Epoch [3/10], Step [185/254], Image [5921/8158], Loss: 0.6217\n",
      "Epoch [3/10], Step [186/254], Image [5953/8158], Loss: 0.5817\n",
      "Epoch [3/10], Step [187/254], Image [5985/8158], Loss: 0.4772\n",
      "Epoch [3/10], Step [188/254], Image [6017/8158], Loss: 0.4773\n",
      "Epoch [3/10], Step [189/254], Image [6049/8158], Loss: 0.4777\n",
      "Epoch [3/10], Step [190/254], Image [6081/8158], Loss: 0.4281\n",
      "Epoch [3/10], Step [191/254], Image [6113/8158], Loss: 0.5017\n",
      "Epoch [3/10], Step [192/254], Image [6145/8158], Loss: 0.5930\n",
      "Epoch [3/10], Step [193/254], Image [6177/8158], Loss: 0.7102\n",
      "Epoch [3/10], Step [194/254], Image [6209/8158], Loss: 0.7467\n",
      "Epoch [3/10], Step [195/254], Image [6241/8158], Loss: 0.2529\n",
      "Epoch [3/10], Step [196/254], Image [6273/8158], Loss: 0.7152\n",
      "Epoch [3/10], Step [197/254], Image [6305/8158], Loss: 0.6659\n",
      "Epoch [3/10], Step [198/254], Image [6337/8158], Loss: 0.3652\n",
      "Epoch [3/10], Step [199/254], Image [6369/8158], Loss: 0.9116\n",
      "Epoch [3/10], Step [200/254], Image [6401/8158], Loss: 0.3804\n",
      "Epoch [3/10], Step [201/254], Image [6433/8158], Loss: 0.6512\n",
      "Epoch [3/10], Step [202/254], Image [6465/8158], Loss: 0.4944\n",
      "Epoch [3/10], Step [203/254], Image [6497/8158], Loss: 0.3446\n",
      "Epoch [3/10], Step [204/254], Image [6529/8158], Loss: 0.9397\n",
      "Epoch [3/10], Step [205/254], Image [6561/8158], Loss: 0.2051\n",
      "Epoch [3/10], Step [206/254], Image [6593/8158], Loss: 0.3763\n",
      "Epoch [3/10], Step [207/254], Image [6625/8158], Loss: 0.3092\n",
      "Epoch [3/10], Step [208/254], Image [6657/8158], Loss: 0.5236\n",
      "Epoch [3/10], Step [209/254], Image [6689/8158], Loss: 0.6063\n",
      "Epoch [3/10], Step [210/254], Image [6721/8158], Loss: 0.4488\n",
      "Epoch [3/10], Step [211/254], Image [6753/8158], Loss: 0.0766\n",
      "Epoch [3/10], Step [212/254], Image [6785/8158], Loss: 1.1161\n",
      "Epoch [3/10], Step [213/254], Image [6817/8158], Loss: 0.6618\n",
      "Epoch [3/10], Step [214/254], Image [6849/8158], Loss: 0.4610\n",
      "Epoch [3/10], Step [215/254], Image [6881/8158], Loss: 0.2554\n",
      "Epoch [3/10], Step [216/254], Image [6913/8158], Loss: 0.2718\n",
      "Epoch [3/10], Step [217/254], Image [6945/8158], Loss: 0.2665\n",
      "Epoch [3/10], Step [218/254], Image [6977/8158], Loss: 0.5221\n",
      "Epoch [3/10], Step [219/254], Image [7009/8158], Loss: 0.6097\n",
      "Epoch [3/10], Step [220/254], Image [7041/8158], Loss: 0.2075\n",
      "Epoch [3/10], Step [221/254], Image [7073/8158], Loss: 0.8956\n",
      "Epoch [3/10], Step [222/254], Image [7105/8158], Loss: 0.3517\n",
      "Epoch [3/10], Step [223/254], Image [7137/8158], Loss: 0.4495\n",
      "Epoch [3/10], Step [224/254], Image [7169/8158], Loss: 0.4284\n",
      "Epoch [3/10], Step [225/254], Image [7201/8158], Loss: 0.2116\n",
      "Epoch [3/10], Step [226/254], Image [7233/8158], Loss: 0.1419\n",
      "Epoch [3/10], Step [227/254], Image [7265/8158], Loss: 0.4081\n",
      "Epoch [3/10], Step [228/254], Image [7297/8158], Loss: 0.5696\n",
      "Epoch [3/10], Step [229/254], Image [7329/8158], Loss: 0.3152\n",
      "Epoch [3/10], Step [230/254], Image [7361/8158], Loss: 0.2997\n",
      "Epoch [3/10], Step [231/254], Image [7393/8158], Loss: 0.4931\n",
      "Epoch [3/10], Step [232/254], Image [7425/8158], Loss: 0.3836\n",
      "Epoch [3/10], Step [233/254], Image [7457/8158], Loss: 0.8667\n",
      "Epoch [3/10], Step [234/254], Image [7489/8158], Loss: 0.8846\n",
      "Epoch [3/10], Step [235/254], Image [7521/8158], Loss: 0.9000\n",
      "Epoch [3/10], Step [236/254], Image [7553/8158], Loss: 0.5761\n",
      "Epoch [3/10], Step [237/254], Image [7585/8158], Loss: 0.4444\n",
      "Epoch [3/10], Step [238/254], Image [7617/8158], Loss: 0.3065\n",
      "Epoch [3/10], Step [239/254], Image [7649/8158], Loss: 0.1994\n",
      "Epoch [3/10], Step [240/254], Image [7681/8158], Loss: 0.4019\n",
      "Epoch [3/10], Step [241/254], Image [7713/8158], Loss: 0.4119\n",
      "Epoch [3/10], Step [242/254], Image [7745/8158], Loss: 0.1610\n",
      "Epoch [3/10], Step [243/254], Image [7777/8158], Loss: 0.4406\n",
      "Epoch [3/10], Step [244/254], Image [7809/8158], Loss: 0.4286\n",
      "Epoch [3/10], Step [245/254], Image [7841/8158], Loss: 0.3539\n",
      "Epoch [3/10], Step [246/254], Image [7873/8158], Loss: 0.6148\n",
      "Epoch [3/10], Step [247/254], Image [7905/8158], Loss: 0.3745\n",
      "Epoch [3/10], Step [248/254], Image [7937/8158], Loss: 0.6068\n",
      "Epoch [3/10], Step [249/254], Image [7969/8158], Loss: 0.6705\n",
      "Epoch [3/10], Step [250/254], Image [8001/8158], Loss: 0.6571\n",
      "Epoch [3/10], Step [251/254], Image [8033/8158], Loss: 0.3298\n",
      "Epoch [3/10], Step [252/254], Image [8065/8158], Loss: 0.4944\n",
      "Epoch [3/10], Step [253/254], Image [8097/8158], Loss: 0.3960\n",
      "Epoch [3/10] completed. Average Loss: 0.4892\n",
      "Starting epoch 4 of 10...\n",
      "Epoch [4/10], Step [0/254], Image [1/8158], Loss: 0.4030\n",
      "Epoch [4/10], Step [1/254], Image [33/8158], Loss: 0.4518\n",
      "Epoch [4/10], Step [2/254], Image [65/8158], Loss: 0.5437\n",
      "Epoch [4/10], Step [3/254], Image [97/8158], Loss: 0.3380\n",
      "Epoch [4/10], Step [4/254], Image [129/8158], Loss: 0.9665\n",
      "Epoch [4/10], Step [5/254], Image [161/8158], Loss: 0.3309\n",
      "Epoch [4/10], Step [6/254], Image [193/8158], Loss: 0.5963\n",
      "Epoch [4/10], Step [7/254], Image [225/8158], Loss: 0.3022\n",
      "Epoch [4/10], Step [8/254], Image [257/8158], Loss: 0.3657\n",
      "Epoch [4/10], Step [9/254], Image [289/8158], Loss: 0.6929\n",
      "Epoch [4/10], Step [10/254], Image [321/8158], Loss: 0.1986\n",
      "Epoch [4/10], Step [11/254], Image [353/8158], Loss: 0.1787\n",
      "Epoch [4/10], Step [12/254], Image [385/8158], Loss: 0.5283\n",
      "Epoch [4/10], Step [13/254], Image [417/8158], Loss: 0.4038\n",
      "Epoch [4/10], Step [14/254], Image [449/8158], Loss: 0.5172\n",
      "Epoch [4/10], Step [15/254], Image [481/8158], Loss: 0.1926\n",
      "Epoch [4/10], Step [16/254], Image [513/8158], Loss: 0.4019\n",
      "Epoch [4/10], Step [17/254], Image [545/8158], Loss: 0.1682\n",
      "Epoch [4/10], Step [18/254], Image [577/8158], Loss: 0.6604\n",
      "Epoch [4/10], Step [19/254], Image [609/8158], Loss: 0.3781\n",
      "Epoch [4/10], Step [20/254], Image [641/8158], Loss: 0.2181\n",
      "Epoch [4/10], Step [21/254], Image [673/8158], Loss: 0.6218\n",
      "Epoch [4/10], Step [22/254], Image [705/8158], Loss: 0.7436\n",
      "Epoch [4/10], Step [23/254], Image [737/8158], Loss: 0.5376\n",
      "Epoch [4/10], Step [24/254], Image [769/8158], Loss: 0.3253\n",
      "Epoch [4/10], Step [25/254], Image [801/8158], Loss: 0.3684\n",
      "Epoch [4/10], Step [26/254], Image [833/8158], Loss: 0.4823\n",
      "Epoch [4/10], Step [27/254], Image [865/8158], Loss: 0.2351\n",
      "Epoch [4/10], Step [28/254], Image [897/8158], Loss: 0.1511\n",
      "Epoch [4/10], Step [29/254], Image [929/8158], Loss: 0.3861\n",
      "Epoch [4/10], Step [30/254], Image [961/8158], Loss: 0.3538\n",
      "Epoch [4/10], Step [31/254], Image [993/8158], Loss: 0.6248\n",
      "Epoch [4/10], Step [32/254], Image [1025/8158], Loss: 0.5803\n",
      "Epoch [4/10], Step [33/254], Image [1057/8158], Loss: 0.4157\n",
      "Epoch [4/10], Step [34/254], Image [1089/8158], Loss: 0.5979\n",
      "Epoch [4/10], Step [35/254], Image [1121/8158], Loss: 0.2300\n",
      "Epoch [4/10], Step [36/254], Image [1153/8158], Loss: 0.2437\n",
      "Epoch [4/10], Step [37/254], Image [1185/8158], Loss: 0.3664\n",
      "Epoch [4/10], Step [38/254], Image [1217/8158], Loss: 0.2060\n",
      "Epoch [4/10], Step [39/254], Image [1249/8158], Loss: 0.2654\n",
      "Epoch [4/10], Step [40/254], Image [1281/8158], Loss: 0.5313\n",
      "Epoch [4/10], Step [41/254], Image [1313/8158], Loss: 0.4090\n",
      "Epoch [4/10], Step [42/254], Image [1345/8158], Loss: 0.1594\n",
      "Epoch [4/10], Step [43/254], Image [1377/8158], Loss: 0.4109\n",
      "Epoch [4/10], Step [44/254], Image [1409/8158], Loss: 0.1545\n",
      "Epoch [4/10], Step [45/254], Image [1441/8158], Loss: 0.7436\n",
      "Epoch [4/10], Step [46/254], Image [1473/8158], Loss: 0.3105\n",
      "Epoch [4/10], Step [47/254], Image [1505/8158], Loss: 0.4528\n",
      "Epoch [4/10], Step [48/254], Image [1537/8158], Loss: 0.5870\n",
      "Epoch [4/10], Step [49/254], Image [1569/8158], Loss: 0.1493\n",
      "Epoch [4/10], Step [50/254], Image [1601/8158], Loss: 0.4963\n",
      "Epoch [4/10], Step [51/254], Image [1633/8158], Loss: 0.0666\n",
      "Epoch [4/10], Step [52/254], Image [1665/8158], Loss: 0.6173\n",
      "Epoch [4/10], Step [53/254], Image [1697/8158], Loss: 0.1009\n",
      "Epoch [4/10], Step [54/254], Image [1729/8158], Loss: 0.3958\n",
      "Epoch [4/10], Step [55/254], Image [1761/8158], Loss: 0.5238\n",
      "Epoch [4/10], Step [56/254], Image [1793/8158], Loss: 0.2500\n",
      "Epoch [4/10], Step [57/254], Image [1825/8158], Loss: 0.8105\n",
      "Epoch [4/10], Step [58/254], Image [1857/8158], Loss: 0.5333\n",
      "Epoch [4/10], Step [59/254], Image [1889/8158], Loss: 0.1953\n",
      "Epoch [4/10], Step [60/254], Image [1921/8158], Loss: 0.7327\n",
      "Epoch [4/10], Step [61/254], Image [1953/8158], Loss: 0.3061\n",
      "Epoch [4/10], Step [62/254], Image [1985/8158], Loss: 0.2822\n",
      "Epoch [4/10], Step [63/254], Image [2017/8158], Loss: 0.5605\n",
      "Epoch [4/10], Step [64/254], Image [2049/8158], Loss: 0.2916\n",
      "Epoch [4/10], Step [65/254], Image [2081/8158], Loss: 0.2271\n",
      "Epoch [4/10], Step [66/254], Image [2113/8158], Loss: 0.4281\n",
      "Epoch [4/10], Step [67/254], Image [2145/8158], Loss: 0.3932\n",
      "Epoch [4/10], Step [68/254], Image [2177/8158], Loss: 0.6202\n",
      "Epoch [4/10], Step [69/254], Image [2209/8158], Loss: 0.4068\n",
      "Epoch [4/10], Step [70/254], Image [2241/8158], Loss: 1.0398\n",
      "Epoch [4/10], Step [71/254], Image [2273/8158], Loss: 0.1879\n",
      "Epoch [4/10], Step [72/254], Image [2305/8158], Loss: 0.5526\n",
      "Epoch [4/10], Step [73/254], Image [2337/8158], Loss: 0.5878\n",
      "Epoch [4/10], Step [74/254], Image [2369/8158], Loss: 0.3601\n",
      "Epoch [4/10], Step [75/254], Image [2401/8158], Loss: 0.3498\n",
      "Epoch [4/10], Step [76/254], Image [2433/8158], Loss: 0.3930\n",
      "Epoch [4/10], Step [77/254], Image [2465/8158], Loss: 0.5800\n",
      "Epoch [4/10], Step [78/254], Image [2497/8158], Loss: 0.3194\n",
      "Epoch [4/10], Step [79/254], Image [2529/8158], Loss: 0.4144\n",
      "Epoch [4/10], Step [80/254], Image [2561/8158], Loss: 0.4484\n",
      "Epoch [4/10], Step [81/254], Image [2593/8158], Loss: 0.6318\n",
      "Epoch [4/10], Step [82/254], Image [2625/8158], Loss: 0.5790\n",
      "Epoch [4/10], Step [83/254], Image [2657/8158], Loss: 0.4487\n",
      "Epoch [4/10], Step [84/254], Image [2689/8158], Loss: 0.5874\n",
      "Epoch [4/10], Step [85/254], Image [2721/8158], Loss: 0.2269\n",
      "Epoch [4/10], Step [86/254], Image [2753/8158], Loss: 0.2961\n",
      "Epoch [4/10], Step [87/254], Image [2785/8158], Loss: 0.3786\n",
      "Epoch [4/10], Step [88/254], Image [2817/8158], Loss: 0.4620\n",
      "Epoch [4/10], Step [89/254], Image [2849/8158], Loss: 0.3002\n",
      "Epoch [4/10], Step [90/254], Image [2881/8158], Loss: 0.6130\n",
      "Epoch [4/10], Step [91/254], Image [2913/8158], Loss: 0.5724\n",
      "Epoch [4/10], Step [92/254], Image [2945/8158], Loss: 0.3351\n",
      "Epoch [4/10], Step [93/254], Image [2977/8158], Loss: 0.7407\n",
      "Epoch [4/10], Step [94/254], Image [3009/8158], Loss: 0.3588\n",
      "Epoch [4/10], Step [95/254], Image [3041/8158], Loss: 0.3666\n",
      "Epoch [4/10], Step [96/254], Image [3073/8158], Loss: 0.5921\n",
      "Epoch [4/10], Step [97/254], Image [3105/8158], Loss: 0.1293\n",
      "Epoch [4/10], Step [98/254], Image [3137/8158], Loss: 0.2626\n",
      "Epoch [4/10], Step [99/254], Image [3169/8158], Loss: 0.9191\n",
      "Epoch [4/10], Step [100/254], Image [3201/8158], Loss: 0.1585\n",
      "Epoch [4/10], Step [101/254], Image [3233/8158], Loss: 0.2199\n",
      "Epoch [4/10], Step [102/254], Image [3265/8158], Loss: 0.2920\n",
      "Epoch [4/10], Step [103/254], Image [3297/8158], Loss: 0.2613\n",
      "Epoch [4/10], Step [104/254], Image [3329/8158], Loss: 0.5469\n",
      "Epoch [4/10], Step [105/254], Image [3361/8158], Loss: 0.4093\n",
      "Epoch [4/10], Step [106/254], Image [3393/8158], Loss: 0.7015\n",
      "Epoch [4/10], Step [107/254], Image [3425/8158], Loss: 0.3719\n",
      "Epoch [4/10], Step [108/254], Image [3457/8158], Loss: 0.6422\n",
      "Epoch [4/10], Step [109/254], Image [3489/8158], Loss: 0.4068\n",
      "Epoch [4/10], Step [110/254], Image [3521/8158], Loss: 0.1627\n",
      "Epoch [4/10], Step [111/254], Image [3553/8158], Loss: 0.4033\n",
      "Epoch [4/10], Step [112/254], Image [3585/8158], Loss: 0.1895\n",
      "Epoch [4/10], Step [113/254], Image [3617/8158], Loss: 0.3029\n",
      "Epoch [4/10], Step [114/254], Image [3649/8158], Loss: 0.1375\n",
      "Epoch [4/10], Step [115/254], Image [3681/8158], Loss: 0.6596\n",
      "Epoch [4/10], Step [116/254], Image [3713/8158], Loss: 0.1449\n",
      "Epoch [4/10], Step [117/254], Image [3745/8158], Loss: 0.4207\n",
      "Epoch [4/10], Step [118/254], Image [3777/8158], Loss: 0.2377\n",
      "Epoch [4/10], Step [119/254], Image [3809/8158], Loss: 0.5338\n",
      "Epoch [4/10], Step [120/254], Image [3841/8158], Loss: 0.3540\n",
      "Epoch [4/10], Step [121/254], Image [3873/8158], Loss: 0.2291\n",
      "Epoch [4/10], Step [122/254], Image [3905/8158], Loss: 0.2279\n",
      "Epoch [4/10], Step [123/254], Image [3937/8158], Loss: 0.9747\n",
      "Epoch [4/10], Step [124/254], Image [3969/8158], Loss: 0.2114\n",
      "Epoch [4/10], Step [125/254], Image [4001/8158], Loss: 0.7830\n",
      "Epoch [4/10], Step [126/254], Image [4033/8158], Loss: 0.2889\n",
      "Epoch [4/10], Step [127/254], Image [4065/8158], Loss: 0.4237\n",
      "Epoch [4/10], Step [128/254], Image [4097/8158], Loss: 0.5892\n",
      "Epoch [4/10], Step [129/254], Image [4129/8158], Loss: 0.2685\n",
      "Epoch [4/10], Step [130/254], Image [4161/8158], Loss: 0.8369\n",
      "Epoch [4/10], Step [131/254], Image [4193/8158], Loss: 0.2185\n",
      "Epoch [4/10], Step [132/254], Image [4225/8158], Loss: 0.7575\n",
      "Epoch [4/10], Step [133/254], Image [4257/8158], Loss: 0.1216\n",
      "Epoch [4/10], Step [134/254], Image [4289/8158], Loss: 0.0982\n",
      "Epoch [4/10], Step [135/254], Image [4321/8158], Loss: 0.4926\n",
      "Epoch [4/10], Step [136/254], Image [4353/8158], Loss: 0.1532\n",
      "Epoch [4/10], Step [137/254], Image [4385/8158], Loss: 0.3382\n",
      "Epoch [4/10], Step [138/254], Image [4417/8158], Loss: 0.2938\n",
      "Epoch [4/10], Step [139/254], Image [4449/8158], Loss: 0.4297\n",
      "Epoch [4/10], Step [140/254], Image [4481/8158], Loss: 0.1194\n",
      "Epoch [4/10], Step [141/254], Image [4513/8158], Loss: 0.3053\n",
      "Epoch [4/10], Step [142/254], Image [4545/8158], Loss: 0.7542\n",
      "Epoch [4/10], Step [143/254], Image [4577/8158], Loss: 0.2988\n",
      "Epoch [4/10], Step [144/254], Image [4609/8158], Loss: 0.4723\n",
      "Epoch [4/10], Step [145/254], Image [4641/8158], Loss: 0.4009\n",
      "Epoch [4/10], Step [146/254], Image [4673/8158], Loss: 0.8774\n",
      "Epoch [4/10], Step [147/254], Image [4705/8158], Loss: 0.3774\n",
      "Epoch [4/10], Step [148/254], Image [4737/8158], Loss: 0.4232\n",
      "Epoch [4/10], Step [149/254], Image [4769/8158], Loss: 0.3350\n",
      "Epoch [4/10], Step [150/254], Image [4801/8158], Loss: 0.4350\n",
      "Epoch [4/10], Step [151/254], Image [4833/8158], Loss: 0.4382\n",
      "Epoch [4/10], Step [152/254], Image [4865/8158], Loss: 0.2656\n",
      "Epoch [4/10], Step [153/254], Image [4897/8158], Loss: 0.1925\n",
      "Epoch [4/10], Step [154/254], Image [4929/8158], Loss: 0.1643\n",
      "Epoch [4/10], Step [155/254], Image [4961/8158], Loss: 0.4703\n",
      "Epoch [4/10], Step [156/254], Image [4993/8158], Loss: 0.4487\n",
      "Epoch [4/10], Step [157/254], Image [5025/8158], Loss: 0.3162\n",
      "Epoch [4/10], Step [158/254], Image [5057/8158], Loss: 0.6890\n",
      "Epoch [4/10], Step [159/254], Image [5089/8158], Loss: 0.8192\n",
      "Epoch [4/10], Step [160/254], Image [5121/8158], Loss: 0.3795\n",
      "Epoch [4/10], Step [161/254], Image [5153/8158], Loss: 0.4880\n",
      "Epoch [4/10], Step [162/254], Image [5185/8158], Loss: 0.5666\n",
      "Epoch [4/10], Step [163/254], Image [5217/8158], Loss: 0.1506\n",
      "Epoch [4/10], Step [164/254], Image [5249/8158], Loss: 0.5424\n",
      "Epoch [4/10], Step [165/254], Image [5281/8158], Loss: 0.2289\n",
      "Epoch [4/10], Step [166/254], Image [5313/8158], Loss: 0.2911\n",
      "Epoch [4/10], Step [167/254], Image [5345/8158], Loss: 0.3941\n",
      "Epoch [4/10], Step [168/254], Image [5377/8158], Loss: 0.6433\n",
      "Epoch [4/10], Step [169/254], Image [5409/8158], Loss: 0.4746\n",
      "Epoch [4/10], Step [170/254], Image [5441/8158], Loss: 0.6730\n",
      "Epoch [4/10], Step [171/254], Image [5473/8158], Loss: 0.4010\n",
      "Epoch [4/10], Step [172/254], Image [5505/8158], Loss: 0.2783\n",
      "Epoch [4/10], Step [173/254], Image [5537/8158], Loss: 0.2366\n",
      "Epoch [4/10], Step [174/254], Image [5569/8158], Loss: 0.5868\n",
      "Epoch [4/10], Step [175/254], Image [5601/8158], Loss: 0.5084\n",
      "Epoch [4/10], Step [176/254], Image [5633/8158], Loss: 0.3219\n",
      "Epoch [4/10], Step [177/254], Image [5665/8158], Loss: 0.7714\n",
      "Epoch [4/10], Step [178/254], Image [5697/8158], Loss: 0.4822\n",
      "Epoch [4/10], Step [179/254], Image [5729/8158], Loss: 0.2614\n",
      "Epoch [4/10], Step [180/254], Image [5761/8158], Loss: 0.2332\n",
      "Epoch [4/10], Step [181/254], Image [5793/8158], Loss: 0.5153\n",
      "Epoch [4/10], Step [182/254], Image [5825/8158], Loss: 0.7111\n",
      "Epoch [4/10], Step [183/254], Image [5857/8158], Loss: 0.5385\n",
      "Epoch [4/10], Step [184/254], Image [5889/8158], Loss: 0.0609\n",
      "Epoch [4/10], Step [185/254], Image [5921/8158], Loss: 0.3602\n",
      "Epoch [4/10], Step [186/254], Image [5953/8158], Loss: 0.0997\n",
      "Epoch [4/10], Step [187/254], Image [5985/8158], Loss: 0.3052\n",
      "Epoch [4/10], Step [188/254], Image [6017/8158], Loss: 0.6288\n",
      "Epoch [4/10], Step [189/254], Image [6049/8158], Loss: 0.4703\n",
      "Epoch [4/10], Step [190/254], Image [6081/8158], Loss: 0.2778\n",
      "Epoch [4/10], Step [191/254], Image [6113/8158], Loss: 0.5799\n",
      "Epoch [4/10], Step [192/254], Image [6145/8158], Loss: 0.1751\n",
      "Epoch [4/10], Step [193/254], Image [6177/8158], Loss: 0.4985\n",
      "Epoch [4/10], Step [194/254], Image [6209/8158], Loss: 0.1479\n",
      "Epoch [4/10], Step [195/254], Image [6241/8158], Loss: 0.3102\n",
      "Epoch [4/10], Step [196/254], Image [6273/8158], Loss: 0.3279\n",
      "Epoch [4/10], Step [197/254], Image [6305/8158], Loss: 0.1609\n",
      "Epoch [4/10], Step [198/254], Image [6337/8158], Loss: 0.2057\n",
      "Epoch [4/10], Step [199/254], Image [6369/8158], Loss: 0.4376\n",
      "Epoch [4/10], Step [200/254], Image [6401/8158], Loss: 0.8717\n",
      "Epoch [4/10], Step [201/254], Image [6433/8158], Loss: 0.8429\n",
      "Epoch [4/10], Step [202/254], Image [6465/8158], Loss: 0.3856\n",
      "Epoch [4/10], Step [203/254], Image [6497/8158], Loss: 0.1117\n",
      "Epoch [4/10], Step [204/254], Image [6529/8158], Loss: 0.1983\n",
      "Epoch [4/10], Step [205/254], Image [6561/8158], Loss: 0.2131\n",
      "Epoch [4/10], Step [206/254], Image [6593/8158], Loss: 0.4736\n",
      "Epoch [4/10], Step [207/254], Image [6625/8158], Loss: 0.6870\n",
      "Epoch [4/10], Step [208/254], Image [6657/8158], Loss: 1.0937\n",
      "Epoch [4/10], Step [209/254], Image [6689/8158], Loss: 0.5287\n",
      "Epoch [4/10], Step [210/254], Image [6721/8158], Loss: 0.5192\n",
      "Epoch [4/10], Step [211/254], Image [6753/8158], Loss: 0.4444\n",
      "Epoch [4/10], Step [212/254], Image [6785/8158], Loss: 0.2431\n",
      "Epoch [4/10], Step [213/254], Image [6817/8158], Loss: 0.2003\n",
      "Epoch [4/10], Step [214/254], Image [6849/8158], Loss: 0.4928\n",
      "Epoch [4/10], Step [215/254], Image [6881/8158], Loss: 0.2464\n",
      "Epoch [4/10], Step [216/254], Image [6913/8158], Loss: 0.4224\n",
      "Epoch [4/10], Step [217/254], Image [6945/8158], Loss: 0.3009\n",
      "Epoch [4/10], Step [218/254], Image [6977/8158], Loss: 0.6771\n",
      "Epoch [4/10], Step [219/254], Image [7009/8158], Loss: 0.3014\n",
      "Epoch [4/10], Step [220/254], Image [7041/8158], Loss: 0.3045\n",
      "Epoch [4/10], Step [221/254], Image [7073/8158], Loss: 0.7420\n",
      "Epoch [4/10], Step [222/254], Image [7105/8158], Loss: 0.3922\n",
      "Epoch [4/10], Step [223/254], Image [7137/8158], Loss: 0.7941\n",
      "Epoch [4/10], Step [224/254], Image [7169/8158], Loss: 0.2919\n",
      "Epoch [4/10], Step [225/254], Image [7201/8158], Loss: 0.6654\n",
      "Epoch [4/10], Step [226/254], Image [7233/8158], Loss: 0.3454\n",
      "Epoch [4/10], Step [227/254], Image [7265/8158], Loss: 0.4865\n",
      "Epoch [4/10], Step [228/254], Image [7297/8158], Loss: 0.7769\n",
      "Epoch [4/10], Step [229/254], Image [7329/8158], Loss: 0.1960\n",
      "Epoch [4/10], Step [230/254], Image [7361/8158], Loss: 0.6961\n",
      "Epoch [4/10], Step [231/254], Image [7393/8158], Loss: 0.4482\n",
      "Epoch [4/10], Step [232/254], Image [7425/8158], Loss: 0.3623\n",
      "Epoch [4/10], Step [233/254], Image [7457/8158], Loss: 0.4686\n",
      "Epoch [4/10], Step [234/254], Image [7489/8158], Loss: 0.5491\n",
      "Epoch [4/10], Step [235/254], Image [7521/8158], Loss: 0.3108\n",
      "Epoch [4/10], Step [236/254], Image [7553/8158], Loss: 0.6080\n",
      "Epoch [4/10], Step [237/254], Image [7585/8158], Loss: 0.2315\n",
      "Epoch [4/10], Step [238/254], Image [7617/8158], Loss: 0.5949\n",
      "Epoch [4/10], Step [239/254], Image [7649/8158], Loss: 0.2272\n",
      "Epoch [4/10], Step [240/254], Image [7681/8158], Loss: 0.7248\n",
      "Epoch [4/10], Step [241/254], Image [7713/8158], Loss: 0.1862\n",
      "Epoch [4/10], Step [242/254], Image [7745/8158], Loss: 0.8803\n",
      "Epoch [4/10], Step [243/254], Image [7777/8158], Loss: 0.3067\n",
      "Epoch [4/10], Step [244/254], Image [7809/8158], Loss: 0.1139\n",
      "Epoch [4/10], Step [245/254], Image [7841/8158], Loss: 0.4612\n",
      "Epoch [4/10], Step [246/254], Image [7873/8158], Loss: 0.3756\n",
      "Epoch [4/10], Step [247/254], Image [7905/8158], Loss: 0.7597\n",
      "Epoch [4/10], Step [248/254], Image [7937/8158], Loss: 0.4330\n",
      "Epoch [4/10], Step [249/254], Image [7969/8158], Loss: 0.2895\n",
      "Epoch [4/10], Step [250/254], Image [8001/8158], Loss: 0.7153\n",
      "Epoch [4/10], Step [251/254], Image [8033/8158], Loss: 0.6174\n",
      "Epoch [4/10], Step [252/254], Image [8065/8158], Loss: 0.4395\n",
      "Epoch [4/10], Step [253/254], Image [8097/8158], Loss: 0.4824\n",
      "Epoch [4/10] completed. Average Loss: 0.4248\n",
      "Starting epoch 5 of 10...\n",
      "Epoch [5/10], Step [0/254], Image [1/8158], Loss: 0.1339\n",
      "Epoch [5/10], Step [1/254], Image [33/8158], Loss: 0.3271\n",
      "Epoch [5/10], Step [2/254], Image [65/8158], Loss: 0.4170\n",
      "Epoch [5/10], Step [3/254], Image [97/8158], Loss: 0.3687\n",
      "Epoch [5/10], Step [4/254], Image [129/8158], Loss: 0.3850\n",
      "Epoch [5/10], Step [5/254], Image [161/8158], Loss: 0.1313\n",
      "Epoch [5/10], Step [6/254], Image [193/8158], Loss: 0.4070\n",
      "Epoch [5/10], Step [7/254], Image [225/8158], Loss: 0.1832\n",
      "Epoch [5/10], Step [8/254], Image [257/8158], Loss: 0.6260\n",
      "Epoch [5/10], Step [9/254], Image [289/8158], Loss: 0.4727\n",
      "Epoch [5/10], Step [10/254], Image [321/8158], Loss: 0.2271\n",
      "Epoch [5/10], Step [11/254], Image [353/8158], Loss: 0.6251\n",
      "Epoch [5/10], Step [12/254], Image [385/8158], Loss: 0.7534\n",
      "Epoch [5/10], Step [13/254], Image [417/8158], Loss: 0.2754\n",
      "Epoch [5/10], Step [14/254], Image [449/8158], Loss: 0.1732\n",
      "Epoch [5/10], Step [15/254], Image [481/8158], Loss: 0.2349\n",
      "Epoch [5/10], Step [16/254], Image [513/8158], Loss: 0.1891\n",
      "Epoch [5/10], Step [17/254], Image [545/8158], Loss: 0.5660\n",
      "Epoch [5/10], Step [18/254], Image [577/8158], Loss: 0.6771\n",
      "Epoch [5/10], Step [19/254], Image [609/8158], Loss: 0.3446\n",
      "Epoch [5/10], Step [20/254], Image [641/8158], Loss: 0.3447\n",
      "Epoch [5/10], Step [21/254], Image [673/8158], Loss: 0.3287\n",
      "Epoch [5/10], Step [22/254], Image [705/8158], Loss: 0.5374\n",
      "Epoch [5/10], Step [23/254], Image [737/8158], Loss: 0.1843\n",
      "Epoch [5/10], Step [24/254], Image [769/8158], Loss: 0.5723\n",
      "Epoch [5/10], Step [25/254], Image [801/8158], Loss: 0.3764\n",
      "Epoch [5/10], Step [26/254], Image [833/8158], Loss: 0.3562\n",
      "Epoch [5/10], Step [27/254], Image [865/8158], Loss: 0.7417\n",
      "Epoch [5/10], Step [28/254], Image [897/8158], Loss: 0.4423\n",
      "Epoch [5/10], Step [29/254], Image [929/8158], Loss: 0.3744\n",
      "Epoch [5/10], Step [30/254], Image [961/8158], Loss: 0.3779\n",
      "Epoch [5/10], Step [31/254], Image [993/8158], Loss: 0.4655\n",
      "Epoch [5/10], Step [32/254], Image [1025/8158], Loss: 0.0713\n",
      "Epoch [5/10], Step [33/254], Image [1057/8158], Loss: 0.7066\n",
      "Epoch [5/10], Step [34/254], Image [1089/8158], Loss: 0.3189\n",
      "Epoch [5/10], Step [35/254], Image [1121/8158], Loss: 0.4207\n",
      "Epoch [5/10], Step [36/254], Image [1153/8158], Loss: 0.4811\n",
      "Epoch [5/10], Step [37/254], Image [1185/8158], Loss: 0.3099\n",
      "Epoch [5/10], Step [38/254], Image [1217/8158], Loss: 0.4724\n",
      "Epoch [5/10], Step [39/254], Image [1249/8158], Loss: 0.3976\n",
      "Epoch [5/10], Step [40/254], Image [1281/8158], Loss: 0.1263\n",
      "Epoch [5/10], Step [41/254], Image [1313/8158], Loss: 0.8176\n",
      "Epoch [5/10], Step [42/254], Image [1345/8158], Loss: 0.3664\n",
      "Epoch [5/10], Step [43/254], Image [1377/8158], Loss: 0.0552\n",
      "Epoch [5/10], Step [44/254], Image [1409/8158], Loss: 0.2348\n",
      "Epoch [5/10], Step [45/254], Image [1441/8158], Loss: 0.6871\n",
      "Epoch [5/10], Step [46/254], Image [1473/8158], Loss: 0.1648\n",
      "Epoch [5/10], Step [47/254], Image [1505/8158], Loss: 0.3758\n",
      "Epoch [5/10], Step [48/254], Image [1537/8158], Loss: 0.1634\n",
      "Epoch [5/10], Step [49/254], Image [1569/8158], Loss: 0.3206\n",
      "Epoch [5/10], Step [50/254], Image [1601/8158], Loss: 0.1801\n",
      "Epoch [5/10], Step [51/254], Image [1633/8158], Loss: 0.5679\n",
      "Epoch [5/10], Step [52/254], Image [1665/8158], Loss: 0.3300\n",
      "Epoch [5/10], Step [53/254], Image [1697/8158], Loss: 0.2697\n",
      "Epoch [5/10], Step [54/254], Image [1729/8158], Loss: 0.4642\n",
      "Epoch [5/10], Step [55/254], Image [1761/8158], Loss: 0.6014\n",
      "Epoch [5/10], Step [56/254], Image [1793/8158], Loss: 0.3865\n",
      "Epoch [5/10], Step [57/254], Image [1825/8158], Loss: 0.1929\n",
      "Epoch [5/10], Step [58/254], Image [1857/8158], Loss: 0.6948\n",
      "Epoch [5/10], Step [59/254], Image [1889/8158], Loss: 0.1867\n",
      "Epoch [5/10], Step [60/254], Image [1921/8158], Loss: 0.2112\n",
      "Epoch [5/10], Step [61/254], Image [1953/8158], Loss: 0.3134\n",
      "Epoch [5/10], Step [62/254], Image [1985/8158], Loss: 0.3483\n",
      "Epoch [5/10], Step [63/254], Image [2017/8158], Loss: 0.0789\n",
      "Epoch [5/10], Step [64/254], Image [2049/8158], Loss: 0.1957\n",
      "Epoch [5/10], Step [65/254], Image [2081/8158], Loss: 0.2959\n",
      "Epoch [5/10], Step [66/254], Image [2113/8158], Loss: 0.2256\n",
      "Epoch [5/10], Step [67/254], Image [2145/8158], Loss: 0.2916\n",
      "Epoch [5/10], Step [68/254], Image [2177/8158], Loss: 0.4082\n",
      "Epoch [5/10], Step [69/254], Image [2209/8158], Loss: 0.6239\n",
      "Epoch [5/10], Step [70/254], Image [2241/8158], Loss: 0.7204\n",
      "Epoch [5/10], Step [71/254], Image [2273/8158], Loss: 0.3726\n",
      "Epoch [5/10], Step [72/254], Image [2305/8158], Loss: 0.3382\n",
      "Epoch [5/10], Step [73/254], Image [2337/8158], Loss: 0.2297\n",
      "Epoch [5/10], Step [74/254], Image [2369/8158], Loss: 0.4843\n",
      "Epoch [5/10], Step [75/254], Image [2401/8158], Loss: 0.3595\n",
      "Epoch [5/10], Step [76/254], Image [2433/8158], Loss: 0.3337\n",
      "Epoch [5/10], Step [77/254], Image [2465/8158], Loss: 0.3384\n",
      "Epoch [5/10], Step [78/254], Image [2497/8158], Loss: 0.0914\n",
      "Epoch [5/10], Step [79/254], Image [2529/8158], Loss: 0.3572\n",
      "Epoch [5/10], Step [80/254], Image [2561/8158], Loss: 0.4360\n",
      "Epoch [5/10], Step [81/254], Image [2593/8158], Loss: 0.4725\n",
      "Epoch [5/10], Step [82/254], Image [2625/8158], Loss: 0.3692\n",
      "Epoch [5/10], Step [83/254], Image [2657/8158], Loss: 0.3045\n",
      "Epoch [5/10], Step [84/254], Image [2689/8158], Loss: 0.2500\n",
      "Epoch [5/10], Step [85/254], Image [2721/8158], Loss: 0.1965\n",
      "Epoch [5/10], Step [86/254], Image [2753/8158], Loss: 0.2995\n",
      "Epoch [5/10], Step [87/254], Image [2785/8158], Loss: 0.2862\n",
      "Epoch [5/10], Step [88/254], Image [2817/8158], Loss: 0.2607\n",
      "Epoch [5/10], Step [89/254], Image [2849/8158], Loss: 0.2613\n",
      "Epoch [5/10], Step [90/254], Image [2881/8158], Loss: 0.3729\n",
      "Epoch [5/10], Step [91/254], Image [2913/8158], Loss: 0.2923\n",
      "Epoch [5/10], Step [92/254], Image [2945/8158], Loss: 0.3483\n",
      "Epoch [5/10], Step [93/254], Image [2977/8158], Loss: 0.0868\n",
      "Epoch [5/10], Step [94/254], Image [3009/8158], Loss: 0.5950\n",
      "Epoch [5/10], Step [95/254], Image [3041/8158], Loss: 0.0865\n",
      "Epoch [5/10], Step [96/254], Image [3073/8158], Loss: 0.3221\n",
      "Epoch [5/10], Step [97/254], Image [3105/8158], Loss: 0.6665\n",
      "Epoch [5/10], Step [98/254], Image [3137/8158], Loss: 0.2107\n",
      "Epoch [5/10], Step [99/254], Image [3169/8158], Loss: 0.3379\n",
      "Epoch [5/10], Step [100/254], Image [3201/8158], Loss: 0.4162\n",
      "Epoch [5/10], Step [101/254], Image [3233/8158], Loss: 0.5955\n",
      "Epoch [5/10], Step [102/254], Image [3265/8158], Loss: 0.3225\n",
      "Epoch [5/10], Step [103/254], Image [3297/8158], Loss: 0.3668\n",
      "Epoch [5/10], Step [104/254], Image [3329/8158], Loss: 0.0459\n",
      "Epoch [5/10], Step [105/254], Image [3361/8158], Loss: 0.5373\n",
      "Epoch [5/10], Step [106/254], Image [3393/8158], Loss: 0.5885\n",
      "Epoch [5/10], Step [107/254], Image [3425/8158], Loss: 0.2811\n",
      "Epoch [5/10], Step [108/254], Image [3457/8158], Loss: 0.3688\n",
      "Epoch [5/10], Step [109/254], Image [3489/8158], Loss: 0.7996\n",
      "Epoch [5/10], Step [110/254], Image [3521/8158], Loss: 0.3742\n",
      "Epoch [5/10], Step [111/254], Image [3553/8158], Loss: 0.3132\n",
      "Epoch [5/10], Step [112/254], Image [3585/8158], Loss: 0.3169\n",
      "Epoch [5/10], Step [113/254], Image [3617/8158], Loss: 0.4070\n",
      "Epoch [5/10], Step [114/254], Image [3649/8158], Loss: 0.7634\n",
      "Epoch [5/10], Step [115/254], Image [3681/8158], Loss: 0.6656\n",
      "Epoch [5/10], Step [116/254], Image [3713/8158], Loss: 0.1126\n",
      "Epoch [5/10], Step [117/254], Image [3745/8158], Loss: 0.4760\n",
      "Epoch [5/10], Step [118/254], Image [3777/8158], Loss: 0.2280\n",
      "Epoch [5/10], Step [119/254], Image [3809/8158], Loss: 0.4029\n",
      "Epoch [5/10], Step [120/254], Image [3841/8158], Loss: 0.4665\n",
      "Epoch [5/10], Step [121/254], Image [3873/8158], Loss: 0.2442\n",
      "Epoch [5/10], Step [122/254], Image [3905/8158], Loss: 0.4533\n",
      "Epoch [5/10], Step [123/254], Image [3937/8158], Loss: 0.2842\n",
      "Epoch [5/10], Step [124/254], Image [3969/8158], Loss: 0.3259\n",
      "Epoch [5/10], Step [125/254], Image [4001/8158], Loss: 0.3515\n",
      "Epoch [5/10], Step [126/254], Image [4033/8158], Loss: 0.2817\n",
      "Epoch [5/10], Step [127/254], Image [4065/8158], Loss: 0.3896\n",
      "Epoch [5/10], Step [128/254], Image [4097/8158], Loss: 0.4782\n",
      "Epoch [5/10], Step [129/254], Image [4129/8158], Loss: 0.4982\n",
      "Epoch [5/10], Step [130/254], Image [4161/8158], Loss: 0.4857\n",
      "Epoch [5/10], Step [131/254], Image [4193/8158], Loss: 0.5824\n",
      "Epoch [5/10], Step [132/254], Image [4225/8158], Loss: 0.2989\n",
      "Epoch [5/10], Step [133/254], Image [4257/8158], Loss: 0.4315\n",
      "Epoch [5/10], Step [134/254], Image [4289/8158], Loss: 0.6427\n",
      "Epoch [5/10], Step [135/254], Image [4321/8158], Loss: 0.4847\n",
      "Epoch [5/10], Step [136/254], Image [4353/8158], Loss: 0.5973\n",
      "Epoch [5/10], Step [137/254], Image [4385/8158], Loss: 0.6415\n",
      "Epoch [5/10], Step [138/254], Image [4417/8158], Loss: 0.1557\n",
      "Epoch [5/10], Step [139/254], Image [4449/8158], Loss: 0.4188\n",
      "Epoch [5/10], Step [140/254], Image [4481/8158], Loss: 0.4235\n",
      "Epoch [5/10], Step [141/254], Image [4513/8158], Loss: 0.6819\n",
      "Epoch [5/10], Step [142/254], Image [4545/8158], Loss: 0.3702\n",
      "Epoch [5/10], Step [143/254], Image [4577/8158], Loss: 0.2085\n",
      "Epoch [5/10], Step [144/254], Image [4609/8158], Loss: 0.3788\n",
      "Epoch [5/10], Step [145/254], Image [4641/8158], Loss: 0.3926\n",
      "Epoch [5/10], Step [146/254], Image [4673/8158], Loss: 0.5234\n",
      "Epoch [5/10], Step [147/254], Image [4705/8158], Loss: 0.4255\n",
      "Epoch [5/10], Step [148/254], Image [4737/8158], Loss: 0.4141\n",
      "Epoch [5/10], Step [149/254], Image [4769/8158], Loss: 0.2738\n",
      "Epoch [5/10], Step [150/254], Image [4801/8158], Loss: 0.3562\n",
      "Epoch [5/10], Step [151/254], Image [4833/8158], Loss: 0.1906\n",
      "Epoch [5/10], Step [152/254], Image [4865/8158], Loss: 0.4930\n",
      "Epoch [5/10], Step [153/254], Image [4897/8158], Loss: 0.2964\n",
      "Epoch [5/10], Step [154/254], Image [4929/8158], Loss: 0.2457\n",
      "Epoch [5/10], Step [155/254], Image [4961/8158], Loss: 0.4539\n",
      "Epoch [5/10], Step [156/254], Image [4993/8158], Loss: 0.4297\n",
      "Epoch [5/10], Step [157/254], Image [5025/8158], Loss: 0.5237\n",
      "Epoch [5/10], Step [158/254], Image [5057/8158], Loss: 0.3070\n",
      "Epoch [5/10], Step [159/254], Image [5089/8158], Loss: 0.4079\n",
      "Epoch [5/10], Step [160/254], Image [5121/8158], Loss: 0.2461\n",
      "Epoch [5/10], Step [161/254], Image [5153/8158], Loss: 0.3856\n",
      "Epoch [5/10], Step [162/254], Image [5185/8158], Loss: 0.2632\n",
      "Epoch [5/10], Step [163/254], Image [5217/8158], Loss: 0.1533\n",
      "Epoch [5/10], Step [164/254], Image [5249/8158], Loss: 0.6054\n",
      "Epoch [5/10], Step [165/254], Image [5281/8158], Loss: 0.7071\n",
      "Epoch [5/10], Step [166/254], Image [5313/8158], Loss: 0.3310\n",
      "Epoch [5/10], Step [167/254], Image [5345/8158], Loss: 0.3684\n",
      "Epoch [5/10], Step [168/254], Image [5377/8158], Loss: 0.2055\n",
      "Epoch [5/10], Step [169/254], Image [5409/8158], Loss: 0.3109\n",
      "Epoch [5/10], Step [170/254], Image [5441/8158], Loss: 0.5391\n",
      "Epoch [5/10], Step [171/254], Image [5473/8158], Loss: 0.2795\n",
      "Epoch [5/10], Step [172/254], Image [5505/8158], Loss: 0.3857\n",
      "Epoch [5/10], Step [173/254], Image [5537/8158], Loss: 0.5054\n",
      "Epoch [5/10], Step [174/254], Image [5569/8158], Loss: 0.4101\n",
      "Epoch [5/10], Step [175/254], Image [5601/8158], Loss: 0.4204\n",
      "Epoch [5/10], Step [176/254], Image [5633/8158], Loss: 0.1774\n",
      "Epoch [5/10], Step [177/254], Image [5665/8158], Loss: 0.2306\n",
      "Epoch [5/10], Step [178/254], Image [5697/8158], Loss: 0.5044\n",
      "Epoch [5/10], Step [179/254], Image [5729/8158], Loss: 0.3581\n",
      "Epoch [5/10], Step [180/254], Image [5761/8158], Loss: 0.1041\n",
      "Epoch [5/10], Step [181/254], Image [5793/8158], Loss: 0.1378\n",
      "Epoch [5/10], Step [182/254], Image [5825/8158], Loss: 0.4371\n",
      "Epoch [5/10], Step [183/254], Image [5857/8158], Loss: 0.3693\n",
      "Epoch [5/10], Step [184/254], Image [5889/8158], Loss: 0.4370\n",
      "Epoch [5/10], Step [185/254], Image [5921/8158], Loss: 0.2917\n",
      "Epoch [5/10], Step [186/254], Image [5953/8158], Loss: 0.3171\n",
      "Epoch [5/10], Step [187/254], Image [5985/8158], Loss: 0.2972\n",
      "Epoch [5/10], Step [188/254], Image [6017/8158], Loss: 0.2925\n",
      "Epoch [5/10], Step [189/254], Image [6049/8158], Loss: 0.5346\n",
      "Epoch [5/10], Step [190/254], Image [6081/8158], Loss: 0.3229\n",
      "Epoch [5/10], Step [191/254], Image [6113/8158], Loss: 0.6074\n",
      "Epoch [5/10], Step [192/254], Image [6145/8158], Loss: 0.2229\n",
      "Epoch [5/10], Step [193/254], Image [6177/8158], Loss: 0.0601\n",
      "Epoch [5/10], Step [194/254], Image [6209/8158], Loss: 0.5681\n",
      "Epoch [5/10], Step [195/254], Image [6241/8158], Loss: 0.2630\n",
      "Epoch [5/10], Step [196/254], Image [6273/8158], Loss: 0.2155\n",
      "Epoch [5/10], Step [197/254], Image [6305/8158], Loss: 0.0577\n",
      "Epoch [5/10], Step [198/254], Image [6337/8158], Loss: 0.4269\n",
      "Epoch [5/10], Step [199/254], Image [6369/8158], Loss: 0.1296\n",
      "Epoch [5/10], Step [200/254], Image [6401/8158], Loss: 0.2056\n",
      "Epoch [5/10], Step [201/254], Image [6433/8158], Loss: 0.5295\n",
      "Epoch [5/10], Step [202/254], Image [6465/8158], Loss: 0.4034\n",
      "Epoch [5/10], Step [203/254], Image [6497/8158], Loss: 0.2977\n",
      "Epoch [5/10], Step [204/254], Image [6529/8158], Loss: 0.4638\n",
      "Epoch [5/10], Step [205/254], Image [6561/8158], Loss: 0.4716\n",
      "Epoch [5/10], Step [206/254], Image [6593/8158], Loss: 0.4140\n",
      "Epoch [5/10], Step [207/254], Image [6625/8158], Loss: 0.1904\n",
      "Epoch [5/10], Step [208/254], Image [6657/8158], Loss: 0.1422\n",
      "Epoch [5/10], Step [209/254], Image [6689/8158], Loss: 0.2590\n",
      "Epoch [5/10], Step [210/254], Image [6721/8158], Loss: 0.4104\n",
      "Epoch [5/10], Step [211/254], Image [6753/8158], Loss: 0.6525\n",
      "Epoch [5/10], Step [212/254], Image [6785/8158], Loss: 0.8623\n",
      "Epoch [5/10], Step [213/254], Image [6817/8158], Loss: 0.4117\n",
      "Epoch [5/10], Step [214/254], Image [6849/8158], Loss: 0.2404\n",
      "Epoch [5/10], Step [215/254], Image [6881/8158], Loss: 0.4519\n",
      "Epoch [5/10], Step [216/254], Image [6913/8158], Loss: 0.5310\n",
      "Epoch [5/10], Step [217/254], Image [6945/8158], Loss: 0.3374\n",
      "Epoch [5/10], Step [218/254], Image [6977/8158], Loss: 0.3364\n",
      "Epoch [5/10], Step [219/254], Image [7009/8158], Loss: 0.4125\n",
      "Epoch [5/10], Step [220/254], Image [7041/8158], Loss: 0.2879\n",
      "Epoch [5/10], Step [221/254], Image [7073/8158], Loss: 0.5274\n",
      "Epoch [5/10], Step [222/254], Image [7105/8158], Loss: 0.2572\n",
      "Epoch [5/10], Step [223/254], Image [7137/8158], Loss: 0.7761\n",
      "Epoch [5/10], Step [224/254], Image [7169/8158], Loss: 0.1094\n",
      "Epoch [5/10], Step [225/254], Image [7201/8158], Loss: 0.2690\n",
      "Epoch [5/10], Step [226/254], Image [7233/8158], Loss: 0.2008\n",
      "Epoch [5/10], Step [227/254], Image [7265/8158], Loss: 0.5651\n",
      "Epoch [5/10], Step [228/254], Image [7297/8158], Loss: 0.6287\n",
      "Epoch [5/10], Step [229/254], Image [7329/8158], Loss: 0.4926\n",
      "Epoch [5/10], Step [230/254], Image [7361/8158], Loss: 0.4084\n",
      "Epoch [5/10], Step [231/254], Image [7393/8158], Loss: 0.2960\n",
      "Epoch [5/10], Step [232/254], Image [7425/8158], Loss: 0.1457\n",
      "Epoch [5/10], Step [233/254], Image [7457/8158], Loss: 0.3611\n",
      "Epoch [5/10], Step [234/254], Image [7489/8158], Loss: 0.5377\n",
      "Epoch [5/10], Step [235/254], Image [7521/8158], Loss: 0.3858\n",
      "Epoch [5/10], Step [236/254], Image [7553/8158], Loss: 0.4800\n",
      "Epoch [5/10], Step [237/254], Image [7585/8158], Loss: 0.2710\n",
      "Epoch [5/10], Step [238/254], Image [7617/8158], Loss: 0.1707\n",
      "Epoch [5/10], Step [239/254], Image [7649/8158], Loss: 0.4428\n",
      "Epoch [5/10], Step [240/254], Image [7681/8158], Loss: 0.5090\n",
      "Epoch [5/10], Step [241/254], Image [7713/8158], Loss: 0.2801\n",
      "Epoch [5/10], Step [242/254], Image [7745/8158], Loss: 0.3141\n",
      "Epoch [5/10], Step [243/254], Image [7777/8158], Loss: 0.0967\n",
      "Epoch [5/10], Step [244/254], Image [7809/8158], Loss: 0.2942\n",
      "Epoch [5/10], Step [245/254], Image [7841/8158], Loss: 0.3169\n",
      "Epoch [5/10], Step [246/254], Image [7873/8158], Loss: 0.4595\n",
      "Epoch [5/10], Step [247/254], Image [7905/8158], Loss: 0.4422\n",
      "Epoch [5/10], Step [248/254], Image [7937/8158], Loss: 0.6163\n",
      "Epoch [5/10], Step [249/254], Image [7969/8158], Loss: 0.5277\n",
      "Epoch [5/10], Step [250/254], Image [8001/8158], Loss: 0.5521\n",
      "Epoch [5/10], Step [251/254], Image [8033/8158], Loss: 0.3374\n",
      "Epoch [5/10], Step [252/254], Image [8065/8158], Loss: 0.1455\n",
      "Epoch [5/10], Step [253/254], Image [8097/8158], Loss: 0.3669\n",
      "Epoch [5/10] completed. Average Loss: 0.3745\n",
      "Starting epoch 6 of 10...\n",
      "Epoch [6/10], Step [0/254], Image [1/8158], Loss: 0.2166\n",
      "Epoch [6/10], Step [1/254], Image [33/8158], Loss: 0.3697\n",
      "Epoch [6/10], Step [2/254], Image [65/8158], Loss: 0.7383\n",
      "Epoch [6/10], Step [3/254], Image [97/8158], Loss: 0.3789\n",
      "Epoch [6/10], Step [4/254], Image [129/8158], Loss: 0.4029\n",
      "Epoch [6/10], Step [5/254], Image [161/8158], Loss: 0.7444\n",
      "Epoch [6/10], Step [6/254], Image [193/8158], Loss: 0.2408\n",
      "Epoch [6/10], Step [7/254], Image [225/8158], Loss: 0.2454\n",
      "Epoch [6/10], Step [8/254], Image [257/8158], Loss: 0.3175\n",
      "Epoch [6/10], Step [9/254], Image [289/8158], Loss: 0.5668\n",
      "Epoch [6/10], Step [10/254], Image [321/8158], Loss: 0.2900\n",
      "Epoch [6/10], Step [11/254], Image [353/8158], Loss: 0.2748\n",
      "Epoch [6/10], Step [12/254], Image [385/8158], Loss: 0.2939\n",
      "Epoch [6/10], Step [13/254], Image [417/8158], Loss: 0.3196\n",
      "Epoch [6/10], Step [14/254], Image [449/8158], Loss: 0.4656\n",
      "Epoch [6/10], Step [15/254], Image [481/8158], Loss: 0.2135\n",
      "Epoch [6/10], Step [16/254], Image [513/8158], Loss: 0.7352\n",
      "Epoch [6/10], Step [17/254], Image [545/8158], Loss: 0.4732\n",
      "Epoch [6/10], Step [18/254], Image [577/8158], Loss: 0.2369\n",
      "Epoch [6/10], Step [19/254], Image [609/8158], Loss: 0.2042\n",
      "Epoch [6/10], Step [20/254], Image [641/8158], Loss: 0.1726\n",
      "Epoch [6/10], Step [21/254], Image [673/8158], Loss: 0.4110\n",
      "Epoch [6/10], Step [22/254], Image [705/8158], Loss: 0.2868\n",
      "Epoch [6/10], Step [23/254], Image [737/8158], Loss: 0.5953\n",
      "Epoch [6/10], Step [24/254], Image [769/8158], Loss: 0.3564\n",
      "Epoch [6/10], Step [25/254], Image [801/8158], Loss: 0.5248\n",
      "Epoch [6/10], Step [26/254], Image [833/8158], Loss: 0.3101\n",
      "Epoch [6/10], Step [27/254], Image [865/8158], Loss: 0.1012\n",
      "Epoch [6/10], Step [28/254], Image [897/8158], Loss: 0.5700\n",
      "Epoch [6/10], Step [29/254], Image [929/8158], Loss: 0.4072\n",
      "Epoch [6/10], Step [30/254], Image [961/8158], Loss: 0.2766\n",
      "Epoch [6/10], Step [31/254], Image [993/8158], Loss: 1.0187\n",
      "Epoch [6/10], Step [32/254], Image [1025/8158], Loss: 0.2955\n",
      "Epoch [6/10], Step [33/254], Image [1057/8158], Loss: 0.1747\n",
      "Epoch [6/10], Step [34/254], Image [1089/8158], Loss: 0.2927\n",
      "Epoch [6/10], Step [35/254], Image [1121/8158], Loss: 0.1565\n",
      "Epoch [6/10], Step [36/254], Image [1153/8158], Loss: 0.4286\n",
      "Epoch [6/10], Step [37/254], Image [1185/8158], Loss: 0.2668\n",
      "Epoch [6/10], Step [38/254], Image [1217/8158], Loss: 0.3718\n",
      "Epoch [6/10], Step [39/254], Image [1249/8158], Loss: 0.3571\n",
      "Epoch [6/10], Step [40/254], Image [1281/8158], Loss: 0.0897\n",
      "Epoch [6/10], Step [41/254], Image [1313/8158], Loss: 0.1184\n",
      "Epoch [6/10], Step [42/254], Image [1345/8158], Loss: 0.6666\n",
      "Epoch [6/10], Step [43/254], Image [1377/8158], Loss: 0.5890\n",
      "Epoch [6/10], Step [44/254], Image [1409/8158], Loss: 0.2671\n",
      "Epoch [6/10], Step [45/254], Image [1441/8158], Loss: 0.7810\n",
      "Epoch [6/10], Step [46/254], Image [1473/8158], Loss: 0.1546\n",
      "Epoch [6/10], Step [47/254], Image [1505/8158], Loss: 0.2428\n",
      "Epoch [6/10], Step [48/254], Image [1537/8158], Loss: 0.4909\n",
      "Epoch [6/10], Step [49/254], Image [1569/8158], Loss: 0.2445\n",
      "Epoch [6/10], Step [50/254], Image [1601/8158], Loss: 0.4745\n",
      "Epoch [6/10], Step [51/254], Image [1633/8158], Loss: 0.3844\n",
      "Epoch [6/10], Step [52/254], Image [1665/8158], Loss: 0.0804\n",
      "Epoch [6/10], Step [53/254], Image [1697/8158], Loss: 0.5839\n",
      "Epoch [6/10], Step [54/254], Image [1729/8158], Loss: 0.3013\n",
      "Epoch [6/10], Step [55/254], Image [1761/8158], Loss: 0.3904\n",
      "Epoch [6/10], Step [56/254], Image [1793/8158], Loss: 0.4565\n",
      "Epoch [6/10], Step [57/254], Image [1825/8158], Loss: 0.3173\n",
      "Epoch [6/10], Step [58/254], Image [1857/8158], Loss: 0.2089\n",
      "Epoch [6/10], Step [59/254], Image [1889/8158], Loss: 0.3291\n",
      "Epoch [6/10], Step [60/254], Image [1921/8158], Loss: 0.3017\n",
      "Epoch [6/10], Step [61/254], Image [1953/8158], Loss: 0.5128\n",
      "Epoch [6/10], Step [62/254], Image [1985/8158], Loss: 0.9224\n",
      "Epoch [6/10], Step [63/254], Image [2017/8158], Loss: 0.2505\n",
      "Epoch [6/10], Step [64/254], Image [2049/8158], Loss: 0.4993\n",
      "Epoch [6/10], Step [65/254], Image [2081/8158], Loss: 0.6107\n",
      "Epoch [6/10], Step [66/254], Image [2113/8158], Loss: 0.2214\n",
      "Epoch [6/10], Step [67/254], Image [2145/8158], Loss: 0.3495\n",
      "Epoch [6/10], Step [68/254], Image [2177/8158], Loss: 0.1231\n",
      "Epoch [6/10], Step [69/254], Image [2209/8158], Loss: 0.4633\n",
      "Epoch [6/10], Step [70/254], Image [2241/8158], Loss: 0.3873\n",
      "Epoch [6/10], Step [71/254], Image [2273/8158], Loss: 0.3050\n",
      "Epoch [6/10], Step [72/254], Image [2305/8158], Loss: 0.4126\n",
      "Epoch [6/10], Step [73/254], Image [2337/8158], Loss: 0.1855\n",
      "Epoch [6/10], Step [74/254], Image [2369/8158], Loss: 0.2239\n",
      "Epoch [6/10], Step [75/254], Image [2401/8158], Loss: 0.5373\n",
      "Epoch [6/10], Step [76/254], Image [2433/8158], Loss: 0.4002\n",
      "Epoch [6/10], Step [77/254], Image [2465/8158], Loss: 0.8239\n",
      "Epoch [6/10], Step [78/254], Image [2497/8158], Loss: 0.1020\n",
      "Epoch [6/10], Step [79/254], Image [2529/8158], Loss: 0.9422\n",
      "Epoch [6/10], Step [80/254], Image [2561/8158], Loss: 0.2732\n",
      "Epoch [6/10], Step [81/254], Image [2593/8158], Loss: 0.5467\n",
      "Epoch [6/10], Step [82/254], Image [2625/8158], Loss: 0.3018\n",
      "Epoch [6/10], Step [83/254], Image [2657/8158], Loss: 0.1749\n",
      "Epoch [6/10], Step [84/254], Image [2689/8158], Loss: 0.3582\n",
      "Epoch [6/10], Step [85/254], Image [2721/8158], Loss: 0.5245\n",
      "Epoch [6/10], Step [86/254], Image [2753/8158], Loss: 0.4060\n",
      "Epoch [6/10], Step [87/254], Image [2785/8158], Loss: 0.7595\n",
      "Epoch [6/10], Step [88/254], Image [2817/8158], Loss: 0.1735\n",
      "Epoch [6/10], Step [89/254], Image [2849/8158], Loss: 0.6546\n",
      "Epoch [6/10], Step [90/254], Image [2881/8158], Loss: 0.4913\n",
      "Epoch [6/10], Step [91/254], Image [2913/8158], Loss: 0.2330\n",
      "Epoch [6/10], Step [92/254], Image [2945/8158], Loss: 0.3639\n",
      "Epoch [6/10], Step [93/254], Image [2977/8158], Loss: 0.4484\n",
      "Epoch [6/10], Step [94/254], Image [3009/8158], Loss: 0.2399\n",
      "Epoch [6/10], Step [95/254], Image [3041/8158], Loss: 0.1605\n",
      "Epoch [6/10], Step [96/254], Image [3073/8158], Loss: 0.3451\n",
      "Epoch [6/10], Step [97/254], Image [3105/8158], Loss: 0.3538\n",
      "Epoch [6/10], Step [98/254], Image [3137/8158], Loss: 0.2143\n",
      "Epoch [6/10], Step [99/254], Image [3169/8158], Loss: 0.2482\n",
      "Epoch [6/10], Step [100/254], Image [3201/8158], Loss: 0.2370\n",
      "Epoch [6/10], Step [101/254], Image [3233/8158], Loss: 0.1875\n",
      "Epoch [6/10], Step [102/254], Image [3265/8158], Loss: 0.1778\n",
      "Epoch [6/10], Step [103/254], Image [3297/8158], Loss: 0.4055\n",
      "Epoch [6/10], Step [104/254], Image [3329/8158], Loss: 0.4952\n",
      "Epoch [6/10], Step [105/254], Image [3361/8158], Loss: 0.1201\n",
      "Epoch [6/10], Step [106/254], Image [3393/8158], Loss: 0.2185\n",
      "Epoch [6/10], Step [107/254], Image [3425/8158], Loss: 0.3103\n",
      "Epoch [6/10], Step [108/254], Image [3457/8158], Loss: 0.2138\n",
      "Epoch [6/10], Step [109/254], Image [3489/8158], Loss: 0.7232\n",
      "Epoch [6/10], Step [110/254], Image [3521/8158], Loss: 0.1155\n",
      "Epoch [6/10], Step [111/254], Image [3553/8158], Loss: 0.1976\n",
      "Epoch [6/10], Step [112/254], Image [3585/8158], Loss: 0.3653\n",
      "Epoch [6/10], Step [113/254], Image [3617/8158], Loss: 0.0903\n",
      "Epoch [6/10], Step [114/254], Image [3649/8158], Loss: 0.4265\n",
      "Epoch [6/10], Step [115/254], Image [3681/8158], Loss: 0.4225\n",
      "Epoch [6/10], Step [116/254], Image [3713/8158], Loss: 0.1515\n",
      "Epoch [6/10], Step [117/254], Image [3745/8158], Loss: 0.4653\n",
      "Epoch [6/10], Step [118/254], Image [3777/8158], Loss: 0.2954\n",
      "Epoch [6/10], Step [119/254], Image [3809/8158], Loss: 0.2109\n",
      "Epoch [6/10], Step [120/254], Image [3841/8158], Loss: 0.1619\n",
      "Epoch [6/10], Step [121/254], Image [3873/8158], Loss: 0.3588\n",
      "Epoch [6/10], Step [122/254], Image [3905/8158], Loss: 0.3007\n",
      "Epoch [6/10], Step [123/254], Image [3937/8158], Loss: 0.5570\n",
      "Epoch [6/10], Step [124/254], Image [3969/8158], Loss: 0.3510\n",
      "Epoch [6/10], Step [125/254], Image [4001/8158], Loss: 0.3182\n",
      "Epoch [6/10], Step [126/254], Image [4033/8158], Loss: 0.1914\n",
      "Epoch [6/10], Step [127/254], Image [4065/8158], Loss: 0.5841\n",
      "Epoch [6/10], Step [128/254], Image [4097/8158], Loss: 0.1735\n",
      "Epoch [6/10], Step [129/254], Image [4129/8158], Loss: 0.0956\n",
      "Epoch [6/10], Step [130/254], Image [4161/8158], Loss: 0.5453\n",
      "Epoch [6/10], Step [131/254], Image [4193/8158], Loss: 0.1210\n",
      "Epoch [6/10], Step [132/254], Image [4225/8158], Loss: 0.1568\n",
      "Epoch [6/10], Step [133/254], Image [4257/8158], Loss: 0.1651\n",
      "Epoch [6/10], Step [134/254], Image [4289/8158], Loss: 0.6338\n",
      "Epoch [6/10], Step [135/254], Image [4321/8158], Loss: 0.3878\n",
      "Epoch [6/10], Step [136/254], Image [4353/8158], Loss: 0.1426\n",
      "Epoch [6/10], Step [137/254], Image [4385/8158], Loss: 0.4698\n",
      "Epoch [6/10], Step [138/254], Image [4417/8158], Loss: 0.4055\n",
      "Epoch [6/10], Step [139/254], Image [4449/8158], Loss: 0.5148\n",
      "Epoch [6/10], Step [140/254], Image [4481/8158], Loss: 0.2663\n",
      "Epoch [6/10], Step [141/254], Image [4513/8158], Loss: 0.1834\n",
      "Epoch [6/10], Step [142/254], Image [4545/8158], Loss: 0.1263\n",
      "Epoch [6/10], Step [143/254], Image [4577/8158], Loss: 0.3039\n",
      "Epoch [6/10], Step [144/254], Image [4609/8158], Loss: 1.0101\n",
      "Epoch [6/10], Step [145/254], Image [4641/8158], Loss: 0.2255\n",
      "Epoch [6/10], Step [146/254], Image [4673/8158], Loss: 0.1272\n",
      "Epoch [6/10], Step [147/254], Image [4705/8158], Loss: 0.3282\n",
      "Epoch [6/10], Step [148/254], Image [4737/8158], Loss: 0.5145\n",
      "Epoch [6/10], Step [149/254], Image [4769/8158], Loss: 0.5592\n",
      "Epoch [6/10], Step [150/254], Image [4801/8158], Loss: 0.7316\n",
      "Epoch [6/10], Step [151/254], Image [4833/8158], Loss: 0.5872\n",
      "Epoch [6/10], Step [152/254], Image [4865/8158], Loss: 0.1791\n",
      "Epoch [6/10], Step [153/254], Image [4897/8158], Loss: 0.3125\n",
      "Epoch [6/10], Step [154/254], Image [4929/8158], Loss: 0.1301\n",
      "Epoch [6/10], Step [155/254], Image [4961/8158], Loss: 0.3588\n",
      "Epoch [6/10], Step [156/254], Image [4993/8158], Loss: 0.2171\n",
      "Epoch [6/10], Step [157/254], Image [5025/8158], Loss: 0.5725\n",
      "Epoch [6/10], Step [158/254], Image [5057/8158], Loss: 0.2771\n",
      "Epoch [6/10], Step [159/254], Image [5089/8158], Loss: 0.4709\n",
      "Epoch [6/10], Step [160/254], Image [5121/8158], Loss: 0.1858\n",
      "Epoch [6/10], Step [161/254], Image [5153/8158], Loss: 0.1446\n",
      "Epoch [6/10], Step [162/254], Image [5185/8158], Loss: 0.2474\n",
      "Epoch [6/10], Step [163/254], Image [5217/8158], Loss: 0.3851\n",
      "Epoch [6/10], Step [164/254], Image [5249/8158], Loss: 0.3160\n",
      "Epoch [6/10], Step [165/254], Image [5281/8158], Loss: 0.6926\n",
      "Epoch [6/10], Step [166/254], Image [5313/8158], Loss: 0.3977\n",
      "Epoch [6/10], Step [167/254], Image [5345/8158], Loss: 0.1034\n",
      "Epoch [6/10], Step [168/254], Image [5377/8158], Loss: 0.6967\n",
      "Epoch [6/10], Step [169/254], Image [5409/8158], Loss: 0.5650\n",
      "Epoch [6/10], Step [170/254], Image [5441/8158], Loss: 0.3889\n",
      "Epoch [6/10], Step [171/254], Image [5473/8158], Loss: 0.4434\n",
      "Epoch [6/10], Step [172/254], Image [5505/8158], Loss: 0.2542\n",
      "Epoch [6/10], Step [173/254], Image [5537/8158], Loss: 0.1571\n",
      "Epoch [6/10], Step [174/254], Image [5569/8158], Loss: 0.3521\n",
      "Epoch [6/10], Step [175/254], Image [5601/8158], Loss: 0.3860\n",
      "Epoch [6/10], Step [176/254], Image [5633/8158], Loss: 0.5496\n",
      "Epoch [6/10], Step [177/254], Image [5665/8158], Loss: 0.5801\n",
      "Epoch [6/10], Step [178/254], Image [5697/8158], Loss: 0.5105\n",
      "Epoch [6/10], Step [179/254], Image [5729/8158], Loss: 0.2765\n",
      "Epoch [6/10], Step [180/254], Image [5761/8158], Loss: 0.4768\n",
      "Epoch [6/10], Step [181/254], Image [5793/8158], Loss: 0.1008\n",
      "Epoch [6/10], Step [182/254], Image [5825/8158], Loss: 0.2508\n",
      "Epoch [6/10], Step [183/254], Image [5857/8158], Loss: 0.2676\n",
      "Epoch [6/10], Step [184/254], Image [5889/8158], Loss: 0.3899\n",
      "Epoch [6/10], Step [185/254], Image [5921/8158], Loss: 0.6685\n",
      "Epoch [6/10], Step [186/254], Image [5953/8158], Loss: 0.2860\n",
      "Epoch [6/10], Step [187/254], Image [5985/8158], Loss: 0.4448\n",
      "Epoch [6/10], Step [188/254], Image [6017/8158], Loss: 0.2781\n",
      "Epoch [6/10], Step [189/254], Image [6049/8158], Loss: 0.3162\n",
      "Epoch [6/10], Step [190/254], Image [6081/8158], Loss: 0.1399\n",
      "Epoch [6/10], Step [191/254], Image [6113/8158], Loss: 0.2523\n",
      "Epoch [6/10], Step [192/254], Image [6145/8158], Loss: 0.3866\n",
      "Epoch [6/10], Step [193/254], Image [6177/8158], Loss: 0.3552\n",
      "Epoch [6/10], Step [194/254], Image [6209/8158], Loss: 0.3444\n",
      "Epoch [6/10], Step [195/254], Image [6241/8158], Loss: 0.4135\n",
      "Epoch [6/10], Step [196/254], Image [6273/8158], Loss: 0.4856\n",
      "Epoch [6/10], Step [197/254], Image [6305/8158], Loss: 0.3680\n",
      "Epoch [6/10], Step [198/254], Image [6337/8158], Loss: 0.3390\n",
      "Epoch [6/10], Step [199/254], Image [6369/8158], Loss: 0.4265\n",
      "Epoch [6/10], Step [200/254], Image [6401/8158], Loss: 0.2990\n",
      "Epoch [6/10], Step [201/254], Image [6433/8158], Loss: 0.4952\n",
      "Epoch [6/10], Step [202/254], Image [6465/8158], Loss: 0.2534\n",
      "Epoch [6/10], Step [203/254], Image [6497/8158], Loss: 0.1851\n",
      "Epoch [6/10], Step [204/254], Image [6529/8158], Loss: 0.3157\n",
      "Epoch [6/10], Step [205/254], Image [6561/8158], Loss: 0.8177\n",
      "Epoch [6/10], Step [206/254], Image [6593/8158], Loss: 0.2329\n",
      "Epoch [6/10], Step [207/254], Image [6625/8158], Loss: 0.3059\n",
      "Epoch [6/10], Step [208/254], Image [6657/8158], Loss: 0.2677\n",
      "Epoch [6/10], Step [209/254], Image [6689/8158], Loss: 0.3707\n",
      "Epoch [6/10], Step [210/254], Image [6721/8158], Loss: 0.1687\n",
      "Epoch [6/10], Step [211/254], Image [6753/8158], Loss: 0.4652\n",
      "Epoch [6/10], Step [212/254], Image [6785/8158], Loss: 0.0830\n",
      "Epoch [6/10], Step [213/254], Image [6817/8158], Loss: 0.4229\n",
      "Epoch [6/10], Step [214/254], Image [6849/8158], Loss: 0.1012\n",
      "Epoch [6/10], Step [215/254], Image [6881/8158], Loss: 0.1136\n",
      "Epoch [6/10], Step [216/254], Image [6913/8158], Loss: 0.6983\n",
      "Epoch [6/10], Step [217/254], Image [6945/8158], Loss: 0.5712\n",
      "Epoch [6/10], Step [218/254], Image [6977/8158], Loss: 0.2731\n",
      "Epoch [6/10], Step [219/254], Image [7009/8158], Loss: 0.2781\n",
      "Epoch [6/10], Step [220/254], Image [7041/8158], Loss: 0.4391\n",
      "Epoch [6/10], Step [221/254], Image [7073/8158], Loss: 0.6617\n",
      "Epoch [6/10], Step [222/254], Image [7105/8158], Loss: 0.6159\n",
      "Epoch [6/10], Step [223/254], Image [7137/8158], Loss: 0.3327\n",
      "Epoch [6/10], Step [224/254], Image [7169/8158], Loss: 0.3229\n",
      "Epoch [6/10], Step [225/254], Image [7201/8158], Loss: 0.3935\n",
      "Epoch [6/10], Step [226/254], Image [7233/8158], Loss: 0.3713\n",
      "Epoch [6/10], Step [227/254], Image [7265/8158], Loss: 0.2357\n",
      "Epoch [6/10], Step [228/254], Image [7297/8158], Loss: 0.4480\n",
      "Epoch [6/10], Step [229/254], Image [7329/8158], Loss: 0.3663\n",
      "Epoch [6/10], Step [230/254], Image [7361/8158], Loss: 0.2017\n",
      "Epoch [6/10], Step [231/254], Image [7393/8158], Loss: 0.2077\n",
      "Epoch [6/10], Step [232/254], Image [7425/8158], Loss: 0.4340\n",
      "Epoch [6/10], Step [233/254], Image [7457/8158], Loss: 0.3266\n",
      "Epoch [6/10], Step [234/254], Image [7489/8158], Loss: 0.2563\n",
      "Epoch [6/10], Step [235/254], Image [7521/8158], Loss: 0.6201\n",
      "Epoch [6/10], Step [236/254], Image [7553/8158], Loss: 0.3206\n",
      "Epoch [6/10], Step [237/254], Image [7585/8158], Loss: 0.2008\n",
      "Epoch [6/10], Step [238/254], Image [7617/8158], Loss: 0.3128\n",
      "Epoch [6/10], Step [239/254], Image [7649/8158], Loss: 0.3297\n",
      "Epoch [6/10], Step [240/254], Image [7681/8158], Loss: 0.2260\n",
      "Epoch [6/10], Step [241/254], Image [7713/8158], Loss: 0.2379\n",
      "Epoch [6/10], Step [242/254], Image [7745/8158], Loss: 0.2607\n",
      "Epoch [6/10], Step [243/254], Image [7777/8158], Loss: 0.3995\n",
      "Epoch [6/10], Step [244/254], Image [7809/8158], Loss: 0.2794\n",
      "Epoch [6/10], Step [245/254], Image [7841/8158], Loss: 0.4565\n",
      "Epoch [6/10], Step [246/254], Image [7873/8158], Loss: 0.3228\n",
      "Epoch [6/10], Step [247/254], Image [7905/8158], Loss: 0.2096\n",
      "Epoch [6/10], Step [248/254], Image [7937/8158], Loss: 0.1380\n",
      "Epoch [6/10], Step [249/254], Image [7969/8158], Loss: 0.3533\n",
      "Epoch [6/10], Step [250/254], Image [8001/8158], Loss: 0.2514\n",
      "Epoch [6/10], Step [251/254], Image [8033/8158], Loss: 0.3976\n",
      "Epoch [6/10], Step [252/254], Image [8065/8158], Loss: 0.2074\n",
      "Epoch [6/10], Step [253/254], Image [8097/8158], Loss: 0.6225\n",
      "Epoch [6/10] completed. Average Loss: 0.3589\n",
      "Starting epoch 7 of 10...\n",
      "Epoch [7/10], Step [0/254], Image [1/8158], Loss: 0.2456\n",
      "Epoch [7/10], Step [1/254], Image [33/8158], Loss: 0.4950\n",
      "Epoch [7/10], Step [2/254], Image [65/8158], Loss: 0.3971\n",
      "Epoch [7/10], Step [3/254], Image [97/8158], Loss: 0.3088\n",
      "Epoch [7/10], Step [4/254], Image [129/8158], Loss: 0.3148\n",
      "Epoch [7/10], Step [5/254], Image [161/8158], Loss: 0.3181\n",
      "Epoch [7/10], Step [6/254], Image [193/8158], Loss: 0.2488\n",
      "Epoch [7/10], Step [7/254], Image [225/8158], Loss: 0.2920\n",
      "Epoch [7/10], Step [8/254], Image [257/8158], Loss: 0.2863\n",
      "Epoch [7/10], Step [9/254], Image [289/8158], Loss: 0.3166\n",
      "Epoch [7/10], Step [10/254], Image [321/8158], Loss: 0.2427\n",
      "Epoch [7/10], Step [11/254], Image [353/8158], Loss: 0.2423\n",
      "Epoch [7/10], Step [12/254], Image [385/8158], Loss: 0.3991\n",
      "Epoch [7/10], Step [13/254], Image [417/8158], Loss: 0.2988\n",
      "Epoch [7/10], Step [14/254], Image [449/8158], Loss: 0.0873\n",
      "Epoch [7/10], Step [15/254], Image [481/8158], Loss: 0.5281\n",
      "Epoch [7/10], Step [16/254], Image [513/8158], Loss: 0.2333\n",
      "Epoch [7/10], Step [17/254], Image [545/8158], Loss: 0.3420\n",
      "Epoch [7/10], Step [18/254], Image [577/8158], Loss: 0.2246\n",
      "Epoch [7/10], Step [19/254], Image [609/8158], Loss: 0.4977\n",
      "Epoch [7/10], Step [20/254], Image [641/8158], Loss: 0.5782\n",
      "Epoch [7/10], Step [21/254], Image [673/8158], Loss: 0.4077\n",
      "Epoch [7/10], Step [22/254], Image [705/8158], Loss: 0.1287\n",
      "Epoch [7/10], Step [23/254], Image [737/8158], Loss: 0.6432\n",
      "Epoch [7/10], Step [24/254], Image [769/8158], Loss: 0.2444\n",
      "Epoch [7/10], Step [25/254], Image [801/8158], Loss: 0.4482\n",
      "Epoch [7/10], Step [26/254], Image [833/8158], Loss: 0.1636\n",
      "Epoch [7/10], Step [27/254], Image [865/8158], Loss: 0.4737\n",
      "Epoch [7/10], Step [28/254], Image [897/8158], Loss: 0.5591\n",
      "Epoch [7/10], Step [29/254], Image [929/8158], Loss: 0.0723\n",
      "Epoch [7/10], Step [30/254], Image [961/8158], Loss: 0.5778\n",
      "Epoch [7/10], Step [31/254], Image [993/8158], Loss: 0.3290\n",
      "Epoch [7/10], Step [32/254], Image [1025/8158], Loss: 0.3494\n",
      "Epoch [7/10], Step [33/254], Image [1057/8158], Loss: 0.2028\n",
      "Epoch [7/10], Step [34/254], Image [1089/8158], Loss: 0.3524\n",
      "Epoch [7/10], Step [35/254], Image [1121/8158], Loss: 0.5391\n",
      "Epoch [7/10], Step [36/254], Image [1153/8158], Loss: 0.5635\n",
      "Epoch [7/10], Step [37/254], Image [1185/8158], Loss: 0.1821\n",
      "Epoch [7/10], Step [38/254], Image [1217/8158], Loss: 0.6012\n",
      "Epoch [7/10], Step [39/254], Image [1249/8158], Loss: 0.2278\n",
      "Epoch [7/10], Step [40/254], Image [1281/8158], Loss: 0.1395\n",
      "Epoch [7/10], Step [41/254], Image [1313/8158], Loss: 0.4255\n",
      "Epoch [7/10], Step [42/254], Image [1345/8158], Loss: 0.6190\n",
      "Epoch [7/10], Step [43/254], Image [1377/8158], Loss: 0.3849\n",
      "Epoch [7/10], Step [44/254], Image [1409/8158], Loss: 0.4549\n",
      "Epoch [7/10], Step [45/254], Image [1441/8158], Loss: 0.3457\n",
      "Epoch [7/10], Step [46/254], Image [1473/8158], Loss: 0.1954\n",
      "Epoch [7/10], Step [47/254], Image [1505/8158], Loss: 0.3807\n",
      "Epoch [7/10], Step [48/254], Image [1537/8158], Loss: 0.4134\n",
      "Epoch [7/10], Step [49/254], Image [1569/8158], Loss: 0.4830\n",
      "Epoch [7/10], Step [50/254], Image [1601/8158], Loss: 0.5432\n",
      "Epoch [7/10], Step [51/254], Image [1633/8158], Loss: 0.0476\n",
      "Epoch [7/10], Step [52/254], Image [1665/8158], Loss: 0.3695\n",
      "Epoch [7/10], Step [53/254], Image [1697/8158], Loss: 0.3323\n",
      "Epoch [7/10], Step [54/254], Image [1729/8158], Loss: 0.8601\n",
      "Epoch [7/10], Step [55/254], Image [1761/8158], Loss: 0.4647\n",
      "Epoch [7/10], Step [56/254], Image [1793/8158], Loss: 0.1600\n",
      "Epoch [7/10], Step [57/254], Image [1825/8158], Loss: 0.2687\n",
      "Epoch [7/10], Step [58/254], Image [1857/8158], Loss: 0.1780\n",
      "Epoch [7/10], Step [59/254], Image [1889/8158], Loss: 0.0986\n",
      "Epoch [7/10], Step [60/254], Image [1921/8158], Loss: 0.3743\n",
      "Epoch [7/10], Step [61/254], Image [1953/8158], Loss: 0.4221\n",
      "Epoch [7/10], Step [62/254], Image [1985/8158], Loss: 0.4912\n",
      "Epoch [7/10], Step [63/254], Image [2017/8158], Loss: 0.4565\n",
      "Epoch [7/10], Step [64/254], Image [2049/8158], Loss: 0.1718\n",
      "Epoch [7/10], Step [65/254], Image [2081/8158], Loss: 0.3341\n",
      "Epoch [7/10], Step [66/254], Image [2113/8158], Loss: 0.2413\n",
      "Epoch [7/10], Step [67/254], Image [2145/8158], Loss: 0.6948\n",
      "Epoch [7/10], Step [68/254], Image [2177/8158], Loss: 0.1178\n",
      "Epoch [7/10], Step [69/254], Image [2209/8158], Loss: 0.5461\n",
      "Epoch [7/10], Step [70/254], Image [2241/8158], Loss: 0.1208\n",
      "Epoch [7/10], Step [71/254], Image [2273/8158], Loss: 0.1870\n",
      "Epoch [7/10], Step [72/254], Image [2305/8158], Loss: 0.3870\n",
      "Epoch [7/10], Step [73/254], Image [2337/8158], Loss: 0.4295\n",
      "Epoch [7/10], Step [74/254], Image [2369/8158], Loss: 0.0522\n",
      "Epoch [7/10], Step [75/254], Image [2401/8158], Loss: 0.1543\n",
      "Epoch [7/10], Step [76/254], Image [2433/8158], Loss: 0.3063\n",
      "Epoch [7/10], Step [77/254], Image [2465/8158], Loss: 0.5458\n",
      "Epoch [7/10], Step [78/254], Image [2497/8158], Loss: 0.2088\n",
      "Epoch [7/10], Step [79/254], Image [2529/8158], Loss: 0.0505\n",
      "Epoch [7/10], Step [80/254], Image [2561/8158], Loss: 0.2591\n",
      "Epoch [7/10], Step [81/254], Image [2593/8158], Loss: 0.5928\n",
      "Epoch [7/10], Step [82/254], Image [2625/8158], Loss: 0.1486\n",
      "Epoch [7/10], Step [83/254], Image [2657/8158], Loss: 0.4335\n",
      "Epoch [7/10], Step [84/254], Image [2689/8158], Loss: 0.2776\n",
      "Epoch [7/10], Step [85/254], Image [2721/8158], Loss: 0.3237\n",
      "Epoch [7/10], Step [86/254], Image [2753/8158], Loss: 0.3661\n",
      "Epoch [7/10], Step [87/254], Image [2785/8158], Loss: 0.3278\n",
      "Epoch [7/10], Step [88/254], Image [2817/8158], Loss: 0.1112\n",
      "Epoch [7/10], Step [89/254], Image [2849/8158], Loss: 0.3725\n",
      "Epoch [7/10], Step [90/254], Image [2881/8158], Loss: 0.4917\n",
      "Epoch [7/10], Step [91/254], Image [2913/8158], Loss: 0.2448\n",
      "Epoch [7/10], Step [92/254], Image [2945/8158], Loss: 0.2595\n",
      "Epoch [7/10], Step [93/254], Image [2977/8158], Loss: 0.3622\n",
      "Epoch [7/10], Step [94/254], Image [3009/8158], Loss: 0.8588\n",
      "Epoch [7/10], Step [95/254], Image [3041/8158], Loss: 0.5946\n",
      "Epoch [7/10], Step [96/254], Image [3073/8158], Loss: 0.4284\n",
      "Epoch [7/10], Step [97/254], Image [3105/8158], Loss: 0.1723\n",
      "Epoch [7/10], Step [98/254], Image [3137/8158], Loss: 0.1697\n",
      "Epoch [7/10], Step [99/254], Image [3169/8158], Loss: 0.5539\n",
      "Epoch [7/10], Step [100/254], Image [3201/8158], Loss: 0.5577\n",
      "Epoch [7/10], Step [101/254], Image [3233/8158], Loss: 0.2624\n",
      "Epoch [7/10], Step [102/254], Image [3265/8158], Loss: 0.5174\n",
      "Epoch [7/10], Step [103/254], Image [3297/8158], Loss: 0.1414\n",
      "Epoch [7/10], Step [104/254], Image [3329/8158], Loss: 0.3949\n",
      "Epoch [7/10], Step [105/254], Image [3361/8158], Loss: 0.3624\n",
      "Epoch [7/10], Step [106/254], Image [3393/8158], Loss: 0.7182\n",
      "Epoch [7/10], Step [107/254], Image [3425/8158], Loss: 0.3202\n",
      "Epoch [7/10], Step [108/254], Image [3457/8158], Loss: 0.2056\n",
      "Epoch [7/10], Step [109/254], Image [3489/8158], Loss: 0.1735\n",
      "Epoch [7/10], Step [110/254], Image [3521/8158], Loss: 0.6277\n",
      "Epoch [7/10], Step [111/254], Image [3553/8158], Loss: 0.1998\n",
      "Epoch [7/10], Step [112/254], Image [3585/8158], Loss: 0.2415\n",
      "Epoch [7/10], Step [113/254], Image [3617/8158], Loss: 0.5070\n",
      "Epoch [7/10], Step [114/254], Image [3649/8158], Loss: 0.5052\n",
      "Epoch [7/10], Step [115/254], Image [3681/8158], Loss: 0.6810\n",
      "Epoch [7/10], Step [116/254], Image [3713/8158], Loss: 0.2634\n",
      "Epoch [7/10], Step [117/254], Image [3745/8158], Loss: 0.2292\n",
      "Epoch [7/10], Step [118/254], Image [3777/8158], Loss: 0.4509\n",
      "Epoch [7/10], Step [119/254], Image [3809/8158], Loss: 0.4332\n",
      "Epoch [7/10], Step [120/254], Image [3841/8158], Loss: 0.8341\n",
      "Epoch [7/10], Step [121/254], Image [3873/8158], Loss: 0.2804\n",
      "Epoch [7/10], Step [122/254], Image [3905/8158], Loss: 0.3710\n",
      "Epoch [7/10], Step [123/254], Image [3937/8158], Loss: 0.5860\n",
      "Epoch [7/10], Step [124/254], Image [3969/8158], Loss: 0.5750\n",
      "Epoch [7/10], Step [125/254], Image [4001/8158], Loss: 0.3643\n",
      "Epoch [7/10], Step [126/254], Image [4033/8158], Loss: 0.1853\n",
      "Epoch [7/10], Step [127/254], Image [4065/8158], Loss: 0.2768\n",
      "Epoch [7/10], Step [128/254], Image [4097/8158], Loss: 0.0531\n",
      "Epoch [7/10], Step [129/254], Image [4129/8158], Loss: 0.4164\n",
      "Epoch [7/10], Step [130/254], Image [4161/8158], Loss: 0.3667\n",
      "Epoch [7/10], Step [131/254], Image [4193/8158], Loss: 0.2513\n",
      "Epoch [7/10], Step [132/254], Image [4225/8158], Loss: 0.4688\n",
      "Epoch [7/10], Step [133/254], Image [4257/8158], Loss: 0.2221\n",
      "Epoch [7/10], Step [134/254], Image [4289/8158], Loss: 0.1767\n",
      "Epoch [7/10], Step [135/254], Image [4321/8158], Loss: 0.4242\n",
      "Epoch [7/10], Step [136/254], Image [4353/8158], Loss: 0.5422\n",
      "Epoch [7/10], Step [137/254], Image [4385/8158], Loss: 0.4193\n",
      "Epoch [7/10], Step [138/254], Image [4417/8158], Loss: 0.1407\n",
      "Epoch [7/10], Step [139/254], Image [4449/8158], Loss: 0.2252\n",
      "Epoch [7/10], Step [140/254], Image [4481/8158], Loss: 0.3272\n",
      "Epoch [7/10], Step [141/254], Image [4513/8158], Loss: 0.4202\n",
      "Epoch [7/10], Step [142/254], Image [4545/8158], Loss: 0.3180\n",
      "Epoch [7/10], Step [143/254], Image [4577/8158], Loss: 0.2561\n",
      "Epoch [7/10], Step [144/254], Image [4609/8158], Loss: 0.5050\n",
      "Epoch [7/10], Step [145/254], Image [4641/8158], Loss: 0.1852\n",
      "Epoch [7/10], Step [146/254], Image [4673/8158], Loss: 0.1682\n",
      "Epoch [7/10], Step [147/254], Image [4705/8158], Loss: 0.7634\n",
      "Epoch [7/10], Step [148/254], Image [4737/8158], Loss: 0.2124\n",
      "Epoch [7/10], Step [149/254], Image [4769/8158], Loss: 0.3084\n",
      "Epoch [7/10], Step [150/254], Image [4801/8158], Loss: 0.2747\n",
      "Epoch [7/10], Step [151/254], Image [4833/8158], Loss: 0.2865\n",
      "Epoch [7/10], Step [152/254], Image [4865/8158], Loss: 0.8149\n",
      "Epoch [7/10], Step [153/254], Image [4897/8158], Loss: 0.4222\n",
      "Epoch [7/10], Step [154/254], Image [4929/8158], Loss: 0.1700\n",
      "Epoch [7/10], Step [155/254], Image [4961/8158], Loss: 0.5831\n",
      "Epoch [7/10], Step [156/254], Image [4993/8158], Loss: 0.4935\n",
      "Epoch [7/10], Step [157/254], Image [5025/8158], Loss: 0.0764\n",
      "Epoch [7/10], Step [158/254], Image [5057/8158], Loss: 0.2434\n",
      "Epoch [7/10], Step [159/254], Image [5089/8158], Loss: 0.1799\n",
      "Epoch [7/10], Step [160/254], Image [5121/8158], Loss: 0.3507\n",
      "Epoch [7/10], Step [161/254], Image [5153/8158], Loss: 0.3701\n",
      "Epoch [7/10], Step [162/254], Image [5185/8158], Loss: 0.4797\n",
      "Epoch [7/10], Step [163/254], Image [5217/8158], Loss: 0.2145\n",
      "Epoch [7/10], Step [164/254], Image [5249/8158], Loss: 0.3351\n",
      "Epoch [7/10], Step [165/254], Image [5281/8158], Loss: 0.5842\n",
      "Epoch [7/10], Step [166/254], Image [5313/8158], Loss: 0.6072\n",
      "Epoch [7/10], Step [167/254], Image [5345/8158], Loss: 0.5287\n",
      "Epoch [7/10], Step [168/254], Image [5377/8158], Loss: 0.2844\n",
      "Epoch [7/10], Step [169/254], Image [5409/8158], Loss: 0.3757\n",
      "Epoch [7/10], Step [170/254], Image [5441/8158], Loss: 0.4217\n",
      "Epoch [7/10], Step [171/254], Image [5473/8158], Loss: 0.1993\n",
      "Epoch [7/10], Step [172/254], Image [5505/8158], Loss: 0.4705\n",
      "Epoch [7/10], Step [173/254], Image [5537/8158], Loss: 0.2725\n",
      "Epoch [7/10], Step [174/254], Image [5569/8158], Loss: 0.3947\n",
      "Epoch [7/10], Step [175/254], Image [5601/8158], Loss: 0.3144\n",
      "Epoch [7/10], Step [176/254], Image [5633/8158], Loss: 0.4436\n",
      "Epoch [7/10], Step [177/254], Image [5665/8158], Loss: 0.9486\n",
      "Epoch [7/10], Step [178/254], Image [5697/8158], Loss: 0.1352\n",
      "Epoch [7/10], Step [179/254], Image [5729/8158], Loss: 0.2519\n",
      "Epoch [7/10], Step [180/254], Image [5761/8158], Loss: 0.0873\n",
      "Epoch [7/10], Step [181/254], Image [5793/8158], Loss: 0.3466\n",
      "Epoch [7/10], Step [182/254], Image [5825/8158], Loss: 0.3501\n",
      "Epoch [7/10], Step [183/254], Image [5857/8158], Loss: 0.2290\n",
      "Epoch [7/10], Step [184/254], Image [5889/8158], Loss: 0.3397\n",
      "Epoch [7/10], Step [185/254], Image [5921/8158], Loss: 0.4467\n",
      "Epoch [7/10], Step [186/254], Image [5953/8158], Loss: 0.3337\n",
      "Epoch [7/10], Step [187/254], Image [5985/8158], Loss: 0.2293\n",
      "Epoch [7/10], Step [188/254], Image [6017/8158], Loss: 0.1815\n",
      "Epoch [7/10], Step [189/254], Image [6049/8158], Loss: 0.6128\n",
      "Epoch [7/10], Step [190/254], Image [6081/8158], Loss: 0.1674\n",
      "Epoch [7/10], Step [191/254], Image [6113/8158], Loss: 0.5797\n",
      "Epoch [7/10], Step [192/254], Image [6145/8158], Loss: 0.1293\n",
      "Epoch [7/10], Step [193/254], Image [6177/8158], Loss: 0.4494\n",
      "Epoch [7/10], Step [194/254], Image [6209/8158], Loss: 0.3981\n",
      "Epoch [7/10], Step [195/254], Image [6241/8158], Loss: 0.4237\n",
      "Epoch [7/10], Step [196/254], Image [6273/8158], Loss: 0.4928\n",
      "Epoch [7/10], Step [197/254], Image [6305/8158], Loss: 0.2539\n",
      "Epoch [7/10], Step [198/254], Image [6337/8158], Loss: 0.5063\n",
      "Epoch [7/10], Step [199/254], Image [6369/8158], Loss: 0.4351\n",
      "Epoch [7/10], Step [200/254], Image [6401/8158], Loss: 0.5008\n",
      "Epoch [7/10], Step [201/254], Image [6433/8158], Loss: 0.1682\n",
      "Epoch [7/10], Step [202/254], Image [6465/8158], Loss: 0.2856\n",
      "Epoch [7/10], Step [203/254], Image [6497/8158], Loss: 0.1430\n",
      "Epoch [7/10], Step [204/254], Image [6529/8158], Loss: 0.5310\n",
      "Epoch [7/10], Step [205/254], Image [6561/8158], Loss: 0.5382\n",
      "Epoch [7/10], Step [206/254], Image [6593/8158], Loss: 0.2410\n",
      "Epoch [7/10], Step [207/254], Image [6625/8158], Loss: 0.1654\n",
      "Epoch [7/10], Step [208/254], Image [6657/8158], Loss: 0.1132\n",
      "Epoch [7/10], Step [209/254], Image [6689/8158], Loss: 0.1429\n",
      "Epoch [7/10], Step [210/254], Image [6721/8158], Loss: 0.7076\n",
      "Epoch [7/10], Step [211/254], Image [6753/8158], Loss: 0.5026\n",
      "Epoch [7/10], Step [212/254], Image [6785/8158], Loss: 0.4778\n",
      "Epoch [7/10], Step [213/254], Image [6817/8158], Loss: 0.4030\n",
      "Epoch [7/10], Step [214/254], Image [6849/8158], Loss: 0.2214\n",
      "Epoch [7/10], Step [215/254], Image [6881/8158], Loss: 0.6341\n",
      "Epoch [7/10], Step [216/254], Image [6913/8158], Loss: 0.3360\n",
      "Epoch [7/10], Step [217/254], Image [6945/8158], Loss: 0.3166\n",
      "Epoch [7/10], Step [218/254], Image [6977/8158], Loss: 0.4232\n",
      "Epoch [7/10], Step [219/254], Image [7009/8158], Loss: 0.2768\n",
      "Epoch [7/10], Step [220/254], Image [7041/8158], Loss: 0.5444\n",
      "Epoch [7/10], Step [221/254], Image [7073/8158], Loss: 0.2902\n",
      "Epoch [7/10], Step [222/254], Image [7105/8158], Loss: 0.6251\n",
      "Epoch [7/10], Step [223/254], Image [7137/8158], Loss: 0.2148\n",
      "Epoch [7/10], Step [224/254], Image [7169/8158], Loss: 0.1160\n",
      "Epoch [7/10], Step [225/254], Image [7201/8158], Loss: 0.3293\n",
      "Epoch [7/10], Step [226/254], Image [7233/8158], Loss: 0.3790\n",
      "Epoch [7/10], Step [227/254], Image [7265/8158], Loss: 0.5624\n",
      "Epoch [7/10], Step [228/254], Image [7297/8158], Loss: 0.3206\n",
      "Epoch [7/10], Step [229/254], Image [7329/8158], Loss: 0.3482\n",
      "Epoch [7/10], Step [230/254], Image [7361/8158], Loss: 0.3660\n",
      "Epoch [7/10], Step [231/254], Image [7393/8158], Loss: 0.4129\n",
      "Epoch [7/10], Step [232/254], Image [7425/8158], Loss: 0.4574\n",
      "Epoch [7/10], Step [233/254], Image [7457/8158], Loss: 0.3623\n",
      "Epoch [7/10], Step [234/254], Image [7489/8158], Loss: 0.1643\n",
      "Epoch [7/10], Step [235/254], Image [7521/8158], Loss: 0.2712\n",
      "Epoch [7/10], Step [236/254], Image [7553/8158], Loss: 0.3899\n",
      "Epoch [7/10], Step [237/254], Image [7585/8158], Loss: 0.5161\n",
      "Epoch [7/10], Step [238/254], Image [7617/8158], Loss: 0.1825\n",
      "Epoch [7/10], Step [239/254], Image [7649/8158], Loss: 0.2959\n",
      "Epoch [7/10], Step [240/254], Image [7681/8158], Loss: 0.2826\n",
      "Epoch [7/10], Step [241/254], Image [7713/8158], Loss: 0.8346\n",
      "Epoch [7/10], Step [242/254], Image [7745/8158], Loss: 0.4627\n",
      "Epoch [7/10], Step [243/254], Image [7777/8158], Loss: 0.3809\n",
      "Epoch [7/10], Step [244/254], Image [7809/8158], Loss: 0.0802\n",
      "Epoch [7/10], Step [245/254], Image [7841/8158], Loss: 0.3963\n",
      "Epoch [7/10], Step [246/254], Image [7873/8158], Loss: 0.2376\n",
      "Epoch [7/10], Step [247/254], Image [7905/8158], Loss: 0.3922\n",
      "Epoch [7/10], Step [248/254], Image [7937/8158], Loss: 0.2285\n",
      "Epoch [7/10], Step [249/254], Image [7969/8158], Loss: 0.1921\n",
      "Epoch [7/10], Step [250/254], Image [8001/8158], Loss: 0.4117\n",
      "Epoch [7/10], Step [251/254], Image [8033/8158], Loss: 0.6497\n",
      "Epoch [7/10], Step [252/254], Image [8065/8158], Loss: 0.5313\n",
      "Epoch [7/10], Step [253/254], Image [8097/8158], Loss: 0.6260\n",
      "Epoch [7/10] completed. Average Loss: 0.3611\n",
      "Starting epoch 8 of 10...\n",
      "Epoch [8/10], Step [0/254], Image [1/8158], Loss: 0.2117\n",
      "Epoch [8/10], Step [1/254], Image [33/8158], Loss: 0.5933\n",
      "Epoch [8/10], Step [2/254], Image [65/8158], Loss: 0.4064\n",
      "Epoch [8/10], Step [3/254], Image [97/8158], Loss: 0.6640\n",
      "Epoch [8/10], Step [4/254], Image [129/8158], Loss: 0.3954\n",
      "Epoch [8/10], Step [5/254], Image [161/8158], Loss: 0.7453\n",
      "Epoch [8/10], Step [6/254], Image [193/8158], Loss: 0.4575\n",
      "Epoch [8/10], Step [7/254], Image [225/8158], Loss: 0.3769\n",
      "Epoch [8/10], Step [8/254], Image [257/8158], Loss: 0.0861\n",
      "Epoch [8/10], Step [9/254], Image [289/8158], Loss: 0.3116\n",
      "Epoch [8/10], Step [10/254], Image [321/8158], Loss: 0.3719\n",
      "Epoch [8/10], Step [11/254], Image [353/8158], Loss: 0.5879\n",
      "Epoch [8/10], Step [12/254], Image [385/8158], Loss: 0.3467\n",
      "Epoch [8/10], Step [13/254], Image [417/8158], Loss: 0.2358\n",
      "Epoch [8/10], Step [14/254], Image [449/8158], Loss: 0.4278\n",
      "Epoch [8/10], Step [15/254], Image [481/8158], Loss: 0.2706\n",
      "Epoch [8/10], Step [16/254], Image [513/8158], Loss: 0.6288\n",
      "Epoch [8/10], Step [17/254], Image [545/8158], Loss: 0.1950\n",
      "Epoch [8/10], Step [18/254], Image [577/8158], Loss: 0.4098\n",
      "Epoch [8/10], Step [19/254], Image [609/8158], Loss: 0.4182\n",
      "Epoch [8/10], Step [20/254], Image [641/8158], Loss: 0.4040\n",
      "Epoch [8/10], Step [21/254], Image [673/8158], Loss: 0.1040\n",
      "Epoch [8/10], Step [22/254], Image [705/8158], Loss: 0.3631\n",
      "Epoch [8/10], Step [23/254], Image [737/8158], Loss: 0.5450\n",
      "Epoch [8/10], Step [24/254], Image [769/8158], Loss: 0.1326\n",
      "Epoch [8/10], Step [25/254], Image [801/8158], Loss: 0.5369\n",
      "Epoch [8/10], Step [26/254], Image [833/8158], Loss: 0.5285\n",
      "Epoch [8/10], Step [27/254], Image [865/8158], Loss: 0.4133\n",
      "Epoch [8/10], Step [28/254], Image [897/8158], Loss: 0.0667\n",
      "Epoch [8/10], Step [29/254], Image [929/8158], Loss: 0.4041\n",
      "Epoch [8/10], Step [30/254], Image [961/8158], Loss: 0.3769\n",
      "Epoch [8/10], Step [31/254], Image [993/8158], Loss: 0.2468\n",
      "Epoch [8/10], Step [32/254], Image [1025/8158], Loss: 0.2818\n",
      "Epoch [8/10], Step [33/254], Image [1057/8158], Loss: 0.4584\n",
      "Epoch [8/10], Step [34/254], Image [1089/8158], Loss: 0.4159\n",
      "Epoch [8/10], Step [35/254], Image [1121/8158], Loss: 0.4819\n",
      "Epoch [8/10], Step [36/254], Image [1153/8158], Loss: 0.3478\n",
      "Epoch [8/10], Step [37/254], Image [1185/8158], Loss: 0.2365\n",
      "Epoch [8/10], Step [38/254], Image [1217/8158], Loss: 0.3591\n",
      "Epoch [8/10], Step [39/254], Image [1249/8158], Loss: 0.1764\n",
      "Epoch [8/10], Step [40/254], Image [1281/8158], Loss: 0.4378\n",
      "Epoch [8/10], Step [41/254], Image [1313/8158], Loss: 0.2538\n",
      "Epoch [8/10], Step [42/254], Image [1345/8158], Loss: 0.3567\n",
      "Epoch [8/10], Step [43/254], Image [1377/8158], Loss: 0.1574\n",
      "Epoch [8/10], Step [44/254], Image [1409/8158], Loss: 0.3431\n",
      "Epoch [8/10], Step [45/254], Image [1441/8158], Loss: 0.2730\n",
      "Epoch [8/10], Step [46/254], Image [1473/8158], Loss: 0.2877\n",
      "Epoch [8/10], Step [47/254], Image [1505/8158], Loss: 0.2000\n",
      "Epoch [8/10], Step [48/254], Image [1537/8158], Loss: 0.0488\n",
      "Epoch [8/10], Step [49/254], Image [1569/8158], Loss: 0.4901\n",
      "Epoch [8/10], Step [50/254], Image [1601/8158], Loss: 0.4726\n",
      "Epoch [8/10], Step [51/254], Image [1633/8158], Loss: 0.1271\n",
      "Epoch [8/10], Step [52/254], Image [1665/8158], Loss: 0.8863\n",
      "Epoch [8/10], Step [53/254], Image [1697/8158], Loss: 0.2874\n",
      "Epoch [8/10], Step [54/254], Image [1729/8158], Loss: 0.1952\n",
      "Epoch [8/10], Step [55/254], Image [1761/8158], Loss: 0.1472\n",
      "Epoch [8/10], Step [56/254], Image [1793/8158], Loss: 0.2755\n",
      "Epoch [8/10], Step [57/254], Image [1825/8158], Loss: 0.5059\n",
      "Epoch [8/10], Step [58/254], Image [1857/8158], Loss: 0.4138\n",
      "Epoch [8/10], Step [59/254], Image [1889/8158], Loss: 0.1343\n",
      "Epoch [8/10], Step [60/254], Image [1921/8158], Loss: 0.5556\n",
      "Epoch [8/10], Step [61/254], Image [1953/8158], Loss: 0.1619\n",
      "Epoch [8/10], Step [62/254], Image [1985/8158], Loss: 0.2594\n",
      "Epoch [8/10], Step [63/254], Image [2017/8158], Loss: 0.2467\n",
      "Epoch [8/10], Step [64/254], Image [2049/8158], Loss: 0.3300\n",
      "Epoch [8/10], Step [65/254], Image [2081/8158], Loss: 0.4616\n",
      "Epoch [8/10], Step [66/254], Image [2113/8158], Loss: 0.1190\n",
      "Epoch [8/10], Step [67/254], Image [2145/8158], Loss: 0.5802\n",
      "Epoch [8/10], Step [68/254], Image [2177/8158], Loss: 0.3208\n",
      "Epoch [8/10], Step [69/254], Image [2209/8158], Loss: 0.5428\n",
      "Epoch [8/10], Step [70/254], Image [2241/8158], Loss: 0.5956\n",
      "Epoch [8/10], Step [71/254], Image [2273/8158], Loss: 0.2657\n",
      "Epoch [8/10], Step [72/254], Image [2305/8158], Loss: 0.2253\n",
      "Epoch [8/10], Step [73/254], Image [2337/8158], Loss: 0.2488\n",
      "Epoch [8/10], Step [74/254], Image [2369/8158], Loss: 0.4332\n",
      "Epoch [8/10], Step [75/254], Image [2401/8158], Loss: 0.3362\n",
      "Epoch [8/10], Step [76/254], Image [2433/8158], Loss: 0.4128\n",
      "Epoch [8/10], Step [77/254], Image [2465/8158], Loss: 0.2402\n",
      "Epoch [8/10], Step [78/254], Image [2497/8158], Loss: 0.2055\n",
      "Epoch [8/10], Step [79/254], Image [2529/8158], Loss: 0.1565\n",
      "Epoch [8/10], Step [80/254], Image [2561/8158], Loss: 0.3820\n",
      "Epoch [8/10], Step [81/254], Image [2593/8158], Loss: 0.1677\n",
      "Epoch [8/10], Step [82/254], Image [2625/8158], Loss: 0.2033\n",
      "Epoch [8/10], Step [83/254], Image [2657/8158], Loss: 0.2734\n",
      "Epoch [8/10], Step [84/254], Image [2689/8158], Loss: 0.1903\n",
      "Epoch [8/10], Step [85/254], Image [2721/8158], Loss: 0.1948\n",
      "Epoch [8/10], Step [86/254], Image [2753/8158], Loss: 0.1868\n",
      "Epoch [8/10], Step [87/254], Image [2785/8158], Loss: 0.3780\n",
      "Epoch [8/10], Step [88/254], Image [2817/8158], Loss: 0.0460\n",
      "Epoch [8/10], Step [89/254], Image [2849/8158], Loss: 0.2786\n",
      "Epoch [8/10], Step [90/254], Image [2881/8158], Loss: 0.6696\n",
      "Epoch [8/10], Step [91/254], Image [2913/8158], Loss: 0.2587\n",
      "Epoch [8/10], Step [92/254], Image [2945/8158], Loss: 0.1544\n",
      "Epoch [8/10], Step [93/254], Image [2977/8158], Loss: 0.2323\n",
      "Epoch [8/10], Step [94/254], Image [3009/8158], Loss: 0.4981\n",
      "Epoch [8/10], Step [95/254], Image [3041/8158], Loss: 0.1614\n",
      "Epoch [8/10], Step [96/254], Image [3073/8158], Loss: 0.1940\n",
      "Epoch [8/10], Step [97/254], Image [3105/8158], Loss: 0.0820\n",
      "Epoch [8/10], Step [98/254], Image [3137/8158], Loss: 0.2598\n",
      "Epoch [8/10], Step [99/254], Image [3169/8158], Loss: 0.2096\n",
      "Epoch [8/10], Step [100/254], Image [3201/8158], Loss: 0.7533\n",
      "Epoch [8/10], Step [101/254], Image [3233/8158], Loss: 0.1755\n",
      "Epoch [8/10], Step [102/254], Image [3265/8158], Loss: 0.5502\n",
      "Epoch [8/10], Step [103/254], Image [3297/8158], Loss: 0.2503\n",
      "Epoch [8/10], Step [104/254], Image [3329/8158], Loss: 0.2679\n",
      "Epoch [8/10], Step [105/254], Image [3361/8158], Loss: 0.3992\n",
      "Epoch [8/10], Step [106/254], Image [3393/8158], Loss: 0.4608\n",
      "Epoch [8/10], Step [107/254], Image [3425/8158], Loss: 0.4860\n",
      "Epoch [8/10], Step [108/254], Image [3457/8158], Loss: 0.3408\n",
      "Epoch [8/10], Step [109/254], Image [3489/8158], Loss: 0.2180\n",
      "Epoch [8/10], Step [110/254], Image [3521/8158], Loss: 0.5279\n",
      "Epoch [8/10], Step [111/254], Image [3553/8158], Loss: 0.0571\n",
      "Epoch [8/10], Step [112/254], Image [3585/8158], Loss: 0.2291\n",
      "Epoch [8/10], Step [113/254], Image [3617/8158], Loss: 0.2649\n",
      "Epoch [8/10], Step [114/254], Image [3649/8158], Loss: 0.2998\n",
      "Epoch [8/10], Step [115/254], Image [3681/8158], Loss: 0.4777\n",
      "Epoch [8/10], Step [116/254], Image [3713/8158], Loss: 0.2480\n",
      "Epoch [8/10], Step [117/254], Image [3745/8158], Loss: 0.8495\n",
      "Epoch [8/10], Step [118/254], Image [3777/8158], Loss: 0.4259\n",
      "Epoch [8/10], Step [119/254], Image [3809/8158], Loss: 0.3611\n",
      "Epoch [8/10], Step [120/254], Image [3841/8158], Loss: 0.2905\n",
      "Epoch [8/10], Step [121/254], Image [3873/8158], Loss: 0.3066\n",
      "Epoch [8/10], Step [122/254], Image [3905/8158], Loss: 0.2691\n",
      "Epoch [8/10], Step [123/254], Image [3937/8158], Loss: 0.7365\n",
      "Epoch [8/10], Step [124/254], Image [3969/8158], Loss: 0.3108\n",
      "Epoch [8/10], Step [125/254], Image [4001/8158], Loss: 0.1235\n",
      "Epoch [8/10], Step [126/254], Image [4033/8158], Loss: 0.1140\n",
      "Epoch [8/10], Step [127/254], Image [4065/8158], Loss: 0.1969\n",
      "Epoch [8/10], Step [128/254], Image [4097/8158], Loss: 0.0719\n",
      "Epoch [8/10], Step [129/254], Image [4129/8158], Loss: 0.3354\n",
      "Epoch [8/10], Step [130/254], Image [4161/8158], Loss: 0.3650\n",
      "Epoch [8/10], Step [131/254], Image [4193/8158], Loss: 0.1953\n",
      "Epoch [8/10], Step [132/254], Image [4225/8158], Loss: 0.1641\n",
      "Epoch [8/10], Step [133/254], Image [4257/8158], Loss: 0.1555\n",
      "Epoch [8/10], Step [134/254], Image [4289/8158], Loss: 0.1338\n",
      "Epoch [8/10], Step [135/254], Image [4321/8158], Loss: 0.4980\n",
      "Epoch [8/10], Step [136/254], Image [4353/8158], Loss: 0.3638\n",
      "Epoch [8/10], Step [137/254], Image [4385/8158], Loss: 0.9759\n",
      "Epoch [8/10], Step [138/254], Image [4417/8158], Loss: 0.3787\n",
      "Epoch [8/10], Step [139/254], Image [4449/8158], Loss: 0.2321\n",
      "Epoch [8/10], Step [140/254], Image [4481/8158], Loss: 0.1751\n",
      "Epoch [8/10], Step [141/254], Image [4513/8158], Loss: 0.3179\n",
      "Epoch [8/10], Step [142/254], Image [4545/8158], Loss: 0.1473\n",
      "Epoch [8/10], Step [143/254], Image [4577/8158], Loss: 0.3931\n",
      "Epoch [8/10], Step [144/254], Image [4609/8158], Loss: 0.2265\n",
      "Epoch [8/10], Step [145/254], Image [4641/8158], Loss: 0.8409\n",
      "Epoch [8/10], Step [146/254], Image [4673/8158], Loss: 0.4670\n",
      "Epoch [8/10], Step [147/254], Image [4705/8158], Loss: 0.5293\n",
      "Epoch [8/10], Step [148/254], Image [4737/8158], Loss: 0.1855\n",
      "Epoch [8/10], Step [149/254], Image [4769/8158], Loss: 0.2134\n",
      "Epoch [8/10], Step [150/254], Image [4801/8158], Loss: 0.3751\n",
      "Epoch [8/10], Step [151/254], Image [4833/8158], Loss: 0.2837\n",
      "Epoch [8/10], Step [152/254], Image [4865/8158], Loss: 0.7223\n",
      "Epoch [8/10], Step [153/254], Image [4897/8158], Loss: 0.1595\n",
      "Epoch [8/10], Step [154/254], Image [4929/8158], Loss: 0.2368\n",
      "Epoch [8/10], Step [155/254], Image [4961/8158], Loss: 0.5742\n",
      "Epoch [8/10], Step [156/254], Image [4993/8158], Loss: 0.6595\n",
      "Epoch [8/10], Step [157/254], Image [5025/8158], Loss: 0.3387\n",
      "Epoch [8/10], Step [158/254], Image [5057/8158], Loss: 0.2221\n",
      "Epoch [8/10], Step [159/254], Image [5089/8158], Loss: 0.2715\n",
      "Epoch [8/10], Step [160/254], Image [5121/8158], Loss: 0.0653\n",
      "Epoch [8/10], Step [161/254], Image [5153/8158], Loss: 0.3461\n",
      "Epoch [8/10], Step [162/254], Image [5185/8158], Loss: 0.1307\n",
      "Epoch [8/10], Step [163/254], Image [5217/8158], Loss: 0.1319\n",
      "Epoch [8/10], Step [164/254], Image [5249/8158], Loss: 0.1618\n",
      "Epoch [8/10], Step [165/254], Image [5281/8158], Loss: 0.5290\n",
      "Epoch [8/10], Step [166/254], Image [5313/8158], Loss: 0.3156\n",
      "Epoch [8/10], Step [167/254], Image [5345/8158], Loss: 0.2727\n",
      "Epoch [8/10], Step [168/254], Image [5377/8158], Loss: 0.2129\n",
      "Epoch [8/10], Step [169/254], Image [5409/8158], Loss: 0.1266\n",
      "Epoch [8/10], Step [170/254], Image [5441/8158], Loss: 0.4571\n",
      "Epoch [8/10], Step [171/254], Image [5473/8158], Loss: 0.3568\n",
      "Epoch [8/10], Step [172/254], Image [5505/8158], Loss: 0.4491\n",
      "Epoch [8/10], Step [173/254], Image [5537/8158], Loss: 0.1690\n",
      "Epoch [8/10], Step [174/254], Image [5569/8158], Loss: 0.3367\n",
      "Epoch [8/10], Step [175/254], Image [5601/8158], Loss: 0.4946\n",
      "Epoch [8/10], Step [176/254], Image [5633/8158], Loss: 0.4699\n",
      "Epoch [8/10], Step [177/254], Image [5665/8158], Loss: 0.4034\n",
      "Epoch [8/10], Step [178/254], Image [5697/8158], Loss: 0.3997\n",
      "Epoch [8/10], Step [179/254], Image [5729/8158], Loss: 0.2011\n",
      "Epoch [8/10], Step [180/254], Image [5761/8158], Loss: 0.3666\n",
      "Epoch [8/10], Step [181/254], Image [5793/8158], Loss: 0.5985\n",
      "Epoch [8/10], Step [182/254], Image [5825/8158], Loss: 0.3135\n",
      "Epoch [8/10], Step [183/254], Image [5857/8158], Loss: 0.1817\n",
      "Epoch [8/10], Step [184/254], Image [5889/8158], Loss: 0.3316\n",
      "Epoch [8/10], Step [185/254], Image [5921/8158], Loss: 0.4417\n",
      "Epoch [8/10], Step [186/254], Image [5953/8158], Loss: 0.3451\n",
      "Epoch [8/10], Step [187/254], Image [5985/8158], Loss: 0.3277\n",
      "Epoch [8/10], Step [188/254], Image [6017/8158], Loss: 0.1279\n",
      "Epoch [8/10], Step [189/254], Image [6049/8158], Loss: 0.3591\n",
      "Epoch [8/10], Step [190/254], Image [6081/8158], Loss: 0.5858\n",
      "Epoch [8/10], Step [191/254], Image [6113/8158], Loss: 0.2610\n",
      "Epoch [8/10], Step [192/254], Image [6145/8158], Loss: 0.1679\n",
      "Epoch [8/10], Step [193/254], Image [6177/8158], Loss: 0.6555\n",
      "Epoch [8/10], Step [194/254], Image [6209/8158], Loss: 0.1259\n",
      "Epoch [8/10], Step [195/254], Image [6241/8158], Loss: 0.5639\n",
      "Epoch [8/10], Step [196/254], Image [6273/8158], Loss: 0.4973\n",
      "Epoch [8/10], Step [197/254], Image [6305/8158], Loss: 0.3898\n",
      "Epoch [8/10], Step [198/254], Image [6337/8158], Loss: 0.2748\n",
      "Epoch [8/10], Step [199/254], Image [6369/8158], Loss: 0.4041\n",
      "Epoch [8/10], Step [200/254], Image [6401/8158], Loss: 0.8701\n",
      "Epoch [8/10], Step [201/254], Image [6433/8158], Loss: 0.8371\n",
      "Epoch [8/10], Step [202/254], Image [6465/8158], Loss: 0.2102\n",
      "Epoch [8/10], Step [203/254], Image [6497/8158], Loss: 0.3759\n",
      "Epoch [8/10], Step [204/254], Image [6529/8158], Loss: 0.3304\n",
      "Epoch [8/10], Step [205/254], Image [6561/8158], Loss: 0.2445\n",
      "Epoch [8/10], Step [206/254], Image [6593/8158], Loss: 0.4825\n",
      "Epoch [8/10], Step [207/254], Image [6625/8158], Loss: 0.3603\n",
      "Epoch [8/10], Step [208/254], Image [6657/8158], Loss: 0.2904\n",
      "Epoch [8/10], Step [209/254], Image [6689/8158], Loss: 0.5574\n",
      "Epoch [8/10], Step [210/254], Image [6721/8158], Loss: 0.5824\n",
      "Epoch [8/10], Step [211/254], Image [6753/8158], Loss: 0.7214\n",
      "Epoch [8/10], Step [212/254], Image [6785/8158], Loss: 0.5798\n",
      "Epoch [8/10], Step [213/254], Image [6817/8158], Loss: 0.8691\n",
      "Epoch [8/10], Step [214/254], Image [6849/8158], Loss: 0.1166\n",
      "Epoch [8/10], Step [215/254], Image [6881/8158], Loss: 0.2064\n",
      "Epoch [8/10], Step [216/254], Image [6913/8158], Loss: 0.1609\n",
      "Epoch [8/10], Step [217/254], Image [6945/8158], Loss: 0.4892\n",
      "Epoch [8/10], Step [218/254], Image [6977/8158], Loss: 0.2359\n",
      "Epoch [8/10], Step [219/254], Image [7009/8158], Loss: 0.7382\n",
      "Epoch [8/10], Step [220/254], Image [7041/8158], Loss: 0.7018\n",
      "Epoch [8/10], Step [221/254], Image [7073/8158], Loss: 0.2060\n",
      "Epoch [8/10], Step [222/254], Image [7105/8158], Loss: 0.1668\n",
      "Epoch [8/10], Step [223/254], Image [7137/8158], Loss: 0.2406\n",
      "Epoch [8/10], Step [224/254], Image [7169/8158], Loss: 0.1789\n",
      "Epoch [8/10], Step [225/254], Image [7201/8158], Loss: 0.2164\n",
      "Epoch [8/10], Step [226/254], Image [7233/8158], Loss: 0.3962\n",
      "Epoch [8/10], Step [227/254], Image [7265/8158], Loss: 0.3255\n",
      "Epoch [8/10], Step [228/254], Image [7297/8158], Loss: 0.1252\n",
      "Epoch [8/10], Step [229/254], Image [7329/8158], Loss: 0.3016\n",
      "Epoch [8/10], Step [230/254], Image [7361/8158], Loss: 0.3871\n",
      "Epoch [8/10], Step [231/254], Image [7393/8158], Loss: 0.6862\n",
      "Epoch [8/10], Step [232/254], Image [7425/8158], Loss: 0.4867\n",
      "Epoch [8/10], Step [233/254], Image [7457/8158], Loss: 0.4216\n",
      "Epoch [8/10], Step [234/254], Image [7489/8158], Loss: 0.3508\n",
      "Epoch [8/10], Step [235/254], Image [7521/8158], Loss: 0.3005\n",
      "Epoch [8/10], Step [236/254], Image [7553/8158], Loss: 0.1006\n",
      "Epoch [8/10], Step [237/254], Image [7585/8158], Loss: 0.3731\n",
      "Epoch [8/10], Step [238/254], Image [7617/8158], Loss: 0.4294\n",
      "Epoch [8/10], Step [239/254], Image [7649/8158], Loss: 0.0710\n",
      "Epoch [8/10], Step [240/254], Image [7681/8158], Loss: 0.4629\n",
      "Epoch [8/10], Step [241/254], Image [7713/8158], Loss: 0.2411\n",
      "Epoch [8/10], Step [242/254], Image [7745/8158], Loss: 0.6249\n",
      "Epoch [8/10], Step [243/254], Image [7777/8158], Loss: 0.2342\n",
      "Epoch [8/10], Step [244/254], Image [7809/8158], Loss: 0.0602\n",
      "Epoch [8/10], Step [245/254], Image [7841/8158], Loss: 0.3043\n",
      "Epoch [8/10], Step [246/254], Image [7873/8158], Loss: 0.2828\n",
      "Epoch [8/10], Step [247/254], Image [7905/8158], Loss: 0.1370\n",
      "Epoch [8/10], Step [248/254], Image [7937/8158], Loss: 0.6024\n",
      "Epoch [8/10], Step [249/254], Image [7969/8158], Loss: 0.2482\n",
      "Epoch [8/10], Step [250/254], Image [8001/8158], Loss: 0.0767\n",
      "Epoch [8/10], Step [251/254], Image [8033/8158], Loss: 0.7508\n",
      "Epoch [8/10], Step [252/254], Image [8065/8158], Loss: 0.4390\n",
      "Epoch [8/10], Step [253/254], Image [8097/8158], Loss: 0.1628\n",
      "Epoch [8/10] completed. Average Loss: 0.3462\n",
      "Starting epoch 9 of 10...\n",
      "Epoch [9/10], Step [0/254], Image [1/8158], Loss: 0.3467\n",
      "Epoch [9/10], Step [1/254], Image [33/8158], Loss: 0.2798\n",
      "Epoch [9/10], Step [2/254], Image [65/8158], Loss: 0.3781\n",
      "Epoch [9/10], Step [3/254], Image [97/8158], Loss: 0.2190\n",
      "Epoch [9/10], Step [4/254], Image [129/8158], Loss: 0.4671\n",
      "Epoch [9/10], Step [5/254], Image [161/8158], Loss: 0.6545\n",
      "Epoch [9/10], Step [6/254], Image [193/8158], Loss: 0.7003\n",
      "Epoch [9/10], Step [7/254], Image [225/8158], Loss: 0.3913\n",
      "Epoch [9/10], Step [8/254], Image [257/8158], Loss: 0.4351\n",
      "Epoch [9/10], Step [9/254], Image [289/8158], Loss: 0.6220\n",
      "Epoch [9/10], Step [10/254], Image [321/8158], Loss: 0.5321\n",
      "Epoch [9/10], Step [11/254], Image [353/8158], Loss: 0.3603\n",
      "Epoch [9/10], Step [12/254], Image [385/8158], Loss: 0.1079\n",
      "Epoch [9/10], Step [13/254], Image [417/8158], Loss: 0.3390\n",
      "Epoch [9/10], Step [14/254], Image [449/8158], Loss: 0.1513\n",
      "Epoch [9/10], Step [15/254], Image [481/8158], Loss: 0.0633\n",
      "Epoch [9/10], Step [16/254], Image [513/8158], Loss: 0.3505\n",
      "Epoch [9/10], Step [17/254], Image [545/8158], Loss: 0.6821\n",
      "Epoch [9/10], Step [18/254], Image [577/8158], Loss: 0.3210\n",
      "Epoch [9/10], Step [19/254], Image [609/8158], Loss: 0.1609\n",
      "Epoch [9/10], Step [20/254], Image [641/8158], Loss: 0.3614\n",
      "Epoch [9/10], Step [21/254], Image [673/8158], Loss: 0.3768\n",
      "Epoch [9/10], Step [22/254], Image [705/8158], Loss: 0.5695\n",
      "Epoch [9/10], Step [23/254], Image [737/8158], Loss: 0.2596\n",
      "Epoch [9/10], Step [24/254], Image [769/8158], Loss: 0.4437\n",
      "Epoch [9/10], Step [25/254], Image [801/8158], Loss: 0.0696\n",
      "Epoch [9/10], Step [26/254], Image [833/8158], Loss: 0.4164\n",
      "Epoch [9/10], Step [27/254], Image [865/8158], Loss: 0.3898\n",
      "Epoch [9/10], Step [28/254], Image [897/8158], Loss: 0.4690\n",
      "Epoch [9/10], Step [29/254], Image [929/8158], Loss: 0.4396\n",
      "Epoch [9/10], Step [30/254], Image [961/8158], Loss: 0.2757\n",
      "Epoch [9/10], Step [31/254], Image [993/8158], Loss: 0.1829\n",
      "Epoch [9/10], Step [32/254], Image [1025/8158], Loss: 0.4780\n",
      "Epoch [9/10], Step [33/254], Image [1057/8158], Loss: 0.3890\n",
      "Epoch [9/10], Step [34/254], Image [1089/8158], Loss: 0.2939\n",
      "Epoch [9/10], Step [35/254], Image [1121/8158], Loss: 0.4851\n",
      "Epoch [9/10], Step [36/254], Image [1153/8158], Loss: 0.5702\n",
      "Epoch [9/10], Step [37/254], Image [1185/8158], Loss: 0.3440\n",
      "Epoch [9/10], Step [38/254], Image [1217/8158], Loss: 0.6960\n",
      "Epoch [9/10], Step [39/254], Image [1249/8158], Loss: 0.3197\n",
      "Epoch [9/10], Step [40/254], Image [1281/8158], Loss: 0.5840\n",
      "Epoch [9/10], Step [41/254], Image [1313/8158], Loss: 0.1688\n",
      "Epoch [9/10], Step [42/254], Image [1345/8158], Loss: 0.1530\n",
      "Epoch [9/10], Step [43/254], Image [1377/8158], Loss: 0.3103\n",
      "Epoch [9/10], Step [44/254], Image [1409/8158], Loss: 0.5925\n",
      "Epoch [9/10], Step [45/254], Image [1441/8158], Loss: 0.3331\n",
      "Epoch [9/10], Step [46/254], Image [1473/8158], Loss: 0.2876\n",
      "Epoch [9/10], Step [47/254], Image [1505/8158], Loss: 0.9123\n",
      "Epoch [9/10], Step [48/254], Image [1537/8158], Loss: 0.2269\n",
      "Epoch [9/10], Step [49/254], Image [1569/8158], Loss: 0.2213\n",
      "Epoch [9/10], Step [50/254], Image [1601/8158], Loss: 0.3684\n",
      "Epoch [9/10], Step [51/254], Image [1633/8158], Loss: 0.0885\n",
      "Epoch [9/10], Step [52/254], Image [1665/8158], Loss: 0.2911\n",
      "Epoch [9/10], Step [53/254], Image [1697/8158], Loss: 0.6047\n",
      "Epoch [9/10], Step [54/254], Image [1729/8158], Loss: 0.3948\n",
      "Epoch [9/10], Step [55/254], Image [1761/8158], Loss: 0.3378\n",
      "Epoch [9/10], Step [56/254], Image [1793/8158], Loss: 0.4671\n",
      "Epoch [9/10], Step [57/254], Image [1825/8158], Loss: 0.2610\n",
      "Epoch [9/10], Step [58/254], Image [1857/8158], Loss: 0.2536\n",
      "Epoch [9/10], Step [59/254], Image [1889/8158], Loss: 0.2031\n",
      "Epoch [9/10], Step [60/254], Image [1921/8158], Loss: 0.1393\n",
      "Epoch [9/10], Step [61/254], Image [1953/8158], Loss: 0.1383\n",
      "Epoch [9/10], Step [62/254], Image [1985/8158], Loss: 0.4819\n",
      "Epoch [9/10], Step [63/254], Image [2017/8158], Loss: 0.5780\n",
      "Epoch [9/10], Step [64/254], Image [2049/8158], Loss: 0.2720\n",
      "Epoch [9/10], Step [65/254], Image [2081/8158], Loss: 0.0707\n",
      "Epoch [9/10], Step [66/254], Image [2113/8158], Loss: 0.2796\n",
      "Epoch [9/10], Step [67/254], Image [2145/8158], Loss: 0.0972\n",
      "Epoch [9/10], Step [68/254], Image [2177/8158], Loss: 0.5912\n",
      "Epoch [9/10], Step [69/254], Image [2209/8158], Loss: 0.2029\n",
      "Epoch [9/10], Step [70/254], Image [2241/8158], Loss: 0.5870\n",
      "Epoch [9/10], Step [71/254], Image [2273/8158], Loss: 0.1295\n",
      "Epoch [9/10], Step [72/254], Image [2305/8158], Loss: 0.4155\n",
      "Epoch [9/10], Step [73/254], Image [2337/8158], Loss: 0.7754\n",
      "Epoch [9/10], Step [74/254], Image [2369/8158], Loss: 0.4437\n",
      "Epoch [9/10], Step [75/254], Image [2401/8158], Loss: 0.0394\n",
      "Epoch [9/10], Step [76/254], Image [2433/8158], Loss: 0.7875\n",
      "Epoch [9/10], Step [77/254], Image [2465/8158], Loss: 0.6057\n",
      "Epoch [9/10], Step [78/254], Image [2497/8158], Loss: 0.3030\n",
      "Epoch [9/10], Step [79/254], Image [2529/8158], Loss: 0.2491\n",
      "Epoch [9/10], Step [80/254], Image [2561/8158], Loss: 0.5363\n",
      "Epoch [9/10], Step [81/254], Image [2593/8158], Loss: 0.2631\n",
      "Epoch [9/10], Step [82/254], Image [2625/8158], Loss: 0.2610\n",
      "Epoch [9/10], Step [83/254], Image [2657/8158], Loss: 0.3764\n",
      "Epoch [9/10], Step [84/254], Image [2689/8158], Loss: 0.1822\n",
      "Epoch [9/10], Step [85/254], Image [2721/8158], Loss: 0.2390\n",
      "Epoch [9/10], Step [86/254], Image [2753/8158], Loss: 0.3620\n",
      "Epoch [9/10], Step [87/254], Image [2785/8158], Loss: 0.0262\n",
      "Epoch [9/10], Step [88/254], Image [2817/8158], Loss: 0.5998\n",
      "Epoch [9/10], Step [89/254], Image [2849/8158], Loss: 0.3489\n",
      "Epoch [9/10], Step [90/254], Image [2881/8158], Loss: 0.0832\n",
      "Epoch [9/10], Step [91/254], Image [2913/8158], Loss: 0.2662\n",
      "Epoch [9/10], Step [92/254], Image [2945/8158], Loss: 0.1866\n",
      "Epoch [9/10], Step [93/254], Image [2977/8158], Loss: 0.1889\n",
      "Epoch [9/10], Step [94/254], Image [3009/8158], Loss: 0.3011\n",
      "Epoch [9/10], Step [95/254], Image [3041/8158], Loss: 0.1033\n",
      "Epoch [9/10], Step [96/254], Image [3073/8158], Loss: 0.1768\n",
      "Epoch [9/10], Step [97/254], Image [3105/8158], Loss: 0.2232\n",
      "Epoch [9/10], Step [98/254], Image [3137/8158], Loss: 0.1509\n",
      "Epoch [9/10], Step [99/254], Image [3169/8158], Loss: 0.4511\n",
      "Epoch [9/10], Step [100/254], Image [3201/8158], Loss: 0.5905\n",
      "Epoch [9/10], Step [101/254], Image [3233/8158], Loss: 0.3497\n",
      "Epoch [9/10], Step [102/254], Image [3265/8158], Loss: 0.2702\n",
      "Epoch [9/10], Step [103/254], Image [3297/8158], Loss: 0.2754\n",
      "Epoch [9/10], Step [104/254], Image [3329/8158], Loss: 0.2034\n",
      "Epoch [9/10], Step [105/254], Image [3361/8158], Loss: 0.2048\n",
      "Epoch [9/10], Step [106/254], Image [3393/8158], Loss: 0.0939\n",
      "Epoch [9/10], Step [107/254], Image [3425/8158], Loss: 0.7405\n",
      "Epoch [9/10], Step [108/254], Image [3457/8158], Loss: 0.3602\n",
      "Epoch [9/10], Step [109/254], Image [3489/8158], Loss: 0.4328\n",
      "Epoch [9/10], Step [110/254], Image [3521/8158], Loss: 0.1239\n",
      "Epoch [9/10], Step [111/254], Image [3553/8158], Loss: 0.3240\n",
      "Epoch [9/10], Step [112/254], Image [3585/8158], Loss: 0.2216\n",
      "Epoch [9/10], Step [113/254], Image [3617/8158], Loss: 0.1076\n",
      "Epoch [9/10], Step [114/254], Image [3649/8158], Loss: 0.3108\n",
      "Epoch [9/10], Step [115/254], Image [3681/8158], Loss: 0.7851\n",
      "Epoch [9/10], Step [116/254], Image [3713/8158], Loss: 0.4450\n",
      "Epoch [9/10], Step [117/254], Image [3745/8158], Loss: 0.4408\n",
      "Epoch [9/10], Step [118/254], Image [3777/8158], Loss: 0.2224\n",
      "Epoch [9/10], Step [119/254], Image [3809/8158], Loss: 0.6307\n",
      "Epoch [9/10], Step [120/254], Image [3841/8158], Loss: 0.5825\n",
      "Epoch [9/10], Step [121/254], Image [3873/8158], Loss: 0.2471\n",
      "Epoch [9/10], Step [122/254], Image [3905/8158], Loss: 0.5317\n",
      "Epoch [9/10], Step [123/254], Image [3937/8158], Loss: 0.2970\n",
      "Epoch [9/10], Step [124/254], Image [3969/8158], Loss: 0.3825\n",
      "Epoch [9/10], Step [125/254], Image [4001/8158], Loss: 0.2227\n",
      "Epoch [9/10], Step [126/254], Image [4033/8158], Loss: 0.3247\n",
      "Epoch [9/10], Step [127/254], Image [4065/8158], Loss: 0.6667\n",
      "Epoch [9/10], Step [128/254], Image [4097/8158], Loss: 0.2335\n",
      "Epoch [9/10], Step [129/254], Image [4129/8158], Loss: 0.1562\n",
      "Epoch [9/10], Step [130/254], Image [4161/8158], Loss: 0.6909\n",
      "Epoch [9/10], Step [131/254], Image [4193/8158], Loss: 0.2305\n",
      "Epoch [9/10], Step [132/254], Image [4225/8158], Loss: 0.3404\n",
      "Epoch [9/10], Step [133/254], Image [4257/8158], Loss: 0.3030\n",
      "Epoch [9/10], Step [134/254], Image [4289/8158], Loss: 0.0993\n",
      "Epoch [9/10], Step [135/254], Image [4321/8158], Loss: 0.7466\n",
      "Epoch [9/10], Step [136/254], Image [4353/8158], Loss: 0.4437\n",
      "Epoch [9/10], Step [137/254], Image [4385/8158], Loss: 0.3459\n",
      "Epoch [9/10], Step [138/254], Image [4417/8158], Loss: 0.1845\n",
      "Epoch [9/10], Step [139/254], Image [4449/8158], Loss: 0.2008\n",
      "Epoch [9/10], Step [140/254], Image [4481/8158], Loss: 0.4327\n",
      "Epoch [9/10], Step [141/254], Image [4513/8158], Loss: 0.2061\n",
      "Epoch [9/10], Step [142/254], Image [4545/8158], Loss: 0.2344\n",
      "Epoch [9/10], Step [143/254], Image [4577/8158], Loss: 0.2948\n",
      "Epoch [9/10], Step [144/254], Image [4609/8158], Loss: 0.0519\n",
      "Epoch [9/10], Step [145/254], Image [4641/8158], Loss: 0.4518\n",
      "Epoch [9/10], Step [146/254], Image [4673/8158], Loss: 0.1908\n",
      "Epoch [9/10], Step [147/254], Image [4705/8158], Loss: 0.0853\n",
      "Epoch [9/10], Step [148/254], Image [4737/8158], Loss: 0.1400\n",
      "Epoch [9/10], Step [149/254], Image [4769/8158], Loss: 0.1360\n",
      "Epoch [9/10], Step [150/254], Image [4801/8158], Loss: 0.3750\n",
      "Epoch [9/10], Step [151/254], Image [4833/8158], Loss: 0.4160\n",
      "Epoch [9/10], Step [152/254], Image [4865/8158], Loss: 0.8444\n",
      "Epoch [9/10], Step [153/254], Image [4897/8158], Loss: 0.2384\n",
      "Epoch [9/10], Step [154/254], Image [4929/8158], Loss: 0.2132\n",
      "Epoch [9/10], Step [155/254], Image [4961/8158], Loss: 0.1713\n",
      "Epoch [9/10], Step [156/254], Image [4993/8158], Loss: 0.1549\n",
      "Epoch [9/10], Step [157/254], Image [5025/8158], Loss: 0.2576\n",
      "Epoch [9/10], Step [158/254], Image [5057/8158], Loss: 0.2339\n",
      "Epoch [9/10], Step [159/254], Image [5089/8158], Loss: 0.4959\n",
      "Epoch [9/10], Step [160/254], Image [5121/8158], Loss: 0.4130\n",
      "Epoch [9/10], Step [161/254], Image [5153/8158], Loss: 0.3681\n",
      "Epoch [9/10], Step [162/254], Image [5185/8158], Loss: 0.0980\n",
      "Epoch [9/10], Step [163/254], Image [5217/8158], Loss: 0.5697\n",
      "Epoch [9/10], Step [164/254], Image [5249/8158], Loss: 0.3621\n",
      "Epoch [9/10], Step [165/254], Image [5281/8158], Loss: 0.1318\n",
      "Epoch [9/10], Step [166/254], Image [5313/8158], Loss: 0.1774\n",
      "Epoch [9/10], Step [167/254], Image [5345/8158], Loss: 0.6054\n",
      "Epoch [9/10], Step [168/254], Image [5377/8158], Loss: 0.3881\n",
      "Epoch [9/10], Step [169/254], Image [5409/8158], Loss: 0.2171\n",
      "Epoch [9/10], Step [170/254], Image [5441/8158], Loss: 0.4639\n",
      "Epoch [9/10], Step [171/254], Image [5473/8158], Loss: 0.3681\n",
      "Epoch [9/10], Step [172/254], Image [5505/8158], Loss: 0.1441\n",
      "Epoch [9/10], Step [173/254], Image [5537/8158], Loss: 0.1587\n",
      "Epoch [9/10], Step [174/254], Image [5569/8158], Loss: 0.3460\n",
      "Epoch [9/10], Step [175/254], Image [5601/8158], Loss: 0.1986\n",
      "Epoch [9/10], Step [176/254], Image [5633/8158], Loss: 0.1790\n",
      "Epoch [9/10], Step [177/254], Image [5665/8158], Loss: 0.5759\n",
      "Epoch [9/10], Step [178/254], Image [5697/8158], Loss: 0.1631\n",
      "Epoch [9/10], Step [179/254], Image [5729/8158], Loss: 0.4163\n",
      "Epoch [9/10], Step [180/254], Image [5761/8158], Loss: 0.1049\n",
      "Epoch [9/10], Step [181/254], Image [5793/8158], Loss: 0.3550\n",
      "Epoch [9/10], Step [182/254], Image [5825/8158], Loss: 0.4424\n",
      "Epoch [9/10], Step [183/254], Image [5857/8158], Loss: 0.0710\n",
      "Epoch [9/10], Step [184/254], Image [5889/8158], Loss: 0.3020\n",
      "Epoch [9/10], Step [185/254], Image [5921/8158], Loss: 0.1656\n",
      "Epoch [9/10], Step [186/254], Image [5953/8158], Loss: 0.3925\n",
      "Epoch [9/10], Step [187/254], Image [5985/8158], Loss: 0.1295\n",
      "Epoch [9/10], Step [188/254], Image [6017/8158], Loss: 0.1667\n",
      "Epoch [9/10], Step [189/254], Image [6049/8158], Loss: 0.2814\n",
      "Epoch [9/10], Step [190/254], Image [6081/8158], Loss: 0.1854\n",
      "Epoch [9/10], Step [191/254], Image [6113/8158], Loss: 0.3629\n",
      "Epoch [9/10], Step [192/254], Image [6145/8158], Loss: 0.4082\n",
      "Epoch [9/10], Step [193/254], Image [6177/8158], Loss: 0.6086\n",
      "Epoch [9/10], Step [194/254], Image [6209/8158], Loss: 0.1658\n",
      "Epoch [9/10], Step [195/254], Image [6241/8158], Loss: 0.4838\n",
      "Epoch [9/10], Step [196/254], Image [6273/8158], Loss: 0.1509\n",
      "Epoch [9/10], Step [197/254], Image [6305/8158], Loss: 0.2157\n",
      "Epoch [9/10], Step [198/254], Image [6337/8158], Loss: 0.2320\n",
      "Epoch [9/10], Step [199/254], Image [6369/8158], Loss: 0.4475\n",
      "Epoch [9/10], Step [200/254], Image [6401/8158], Loss: 0.5608\n",
      "Epoch [9/10], Step [201/254], Image [6433/8158], Loss: 0.4051\n",
      "Epoch [9/10], Step [202/254], Image [6465/8158], Loss: 0.2577\n",
      "Epoch [9/10], Step [203/254], Image [6497/8158], Loss: 0.1989\n",
      "Epoch [9/10], Step [204/254], Image [6529/8158], Loss: 0.3584\n",
      "Epoch [9/10], Step [205/254], Image [6561/8158], Loss: 0.3550\n",
      "Epoch [9/10], Step [206/254], Image [6593/8158], Loss: 0.2445\n",
      "Epoch [9/10], Step [207/254], Image [6625/8158], Loss: 0.3295\n",
      "Epoch [9/10], Step [208/254], Image [6657/8158], Loss: 0.2019\n",
      "Epoch [9/10], Step [209/254], Image [6689/8158], Loss: 0.4012\n",
      "Epoch [9/10], Step [210/254], Image [6721/8158], Loss: 0.3541\n",
      "Epoch [9/10], Step [211/254], Image [6753/8158], Loss: 0.2790\n",
      "Epoch [9/10], Step [212/254], Image [6785/8158], Loss: 0.3511\n",
      "Epoch [9/10], Step [213/254], Image [6817/8158], Loss: 0.2345\n",
      "Epoch [9/10], Step [214/254], Image [6849/8158], Loss: 0.3626\n",
      "Epoch [9/10], Step [215/254], Image [6881/8158], Loss: 0.4713\n",
      "Epoch [9/10], Step [216/254], Image [6913/8158], Loss: 0.2437\n",
      "Epoch [9/10], Step [217/254], Image [6945/8158], Loss: 0.4364\n",
      "Epoch [9/10], Step [218/254], Image [6977/8158], Loss: 0.2380\n",
      "Epoch [9/10], Step [219/254], Image [7009/8158], Loss: 0.1820\n",
      "Epoch [9/10], Step [220/254], Image [7041/8158], Loss: 0.2441\n",
      "Epoch [9/10], Step [221/254], Image [7073/8158], Loss: 0.3702\n",
      "Epoch [9/10], Step [222/254], Image [7105/8158], Loss: 0.7822\n",
      "Epoch [9/10], Step [223/254], Image [7137/8158], Loss: 0.0531\n",
      "Epoch [9/10], Step [224/254], Image [7169/8158], Loss: 0.3905\n",
      "Epoch [9/10], Step [225/254], Image [7201/8158], Loss: 0.2363\n",
      "Epoch [9/10], Step [226/254], Image [7233/8158], Loss: 0.0716\n",
      "Epoch [9/10], Step [227/254], Image [7265/8158], Loss: 0.7384\n",
      "Epoch [9/10], Step [228/254], Image [7297/8158], Loss: 0.1668\n",
      "Epoch [9/10], Step [229/254], Image [7329/8158], Loss: 0.4272\n",
      "Epoch [9/10], Step [230/254], Image [7361/8158], Loss: 0.2080\n",
      "Epoch [9/10], Step [231/254], Image [7393/8158], Loss: 0.2332\n",
      "Epoch [9/10], Step [232/254], Image [7425/8158], Loss: 0.5884\n",
      "Epoch [9/10], Step [233/254], Image [7457/8158], Loss: 0.2490\n",
      "Epoch [9/10], Step [234/254], Image [7489/8158], Loss: 1.0383\n",
      "Epoch [9/10], Step [235/254], Image [7521/8158], Loss: 0.3067\n",
      "Epoch [9/10], Step [236/254], Image [7553/8158], Loss: 0.1907\n",
      "Epoch [9/10], Step [237/254], Image [7585/8158], Loss: 0.0619\n",
      "Epoch [9/10], Step [238/254], Image [7617/8158], Loss: 0.1311\n",
      "Epoch [9/10], Step [239/254], Image [7649/8158], Loss: 0.5598\n",
      "Epoch [9/10], Step [240/254], Image [7681/8158], Loss: 0.1602\n",
      "Epoch [9/10], Step [241/254], Image [7713/8158], Loss: 0.2808\n",
      "Epoch [9/10], Step [242/254], Image [7745/8158], Loss: 0.3014\n",
      "Epoch [9/10], Step [243/254], Image [7777/8158], Loss: 0.2834\n",
      "Epoch [9/10], Step [244/254], Image [7809/8158], Loss: 0.1824\n",
      "Epoch [9/10], Step [245/254], Image [7841/8158], Loss: 0.5274\n",
      "Epoch [9/10], Step [246/254], Image [7873/8158], Loss: 0.4853\n",
      "Epoch [9/10], Step [247/254], Image [7905/8158], Loss: 0.4921\n",
      "Epoch [9/10], Step [248/254], Image [7937/8158], Loss: 0.3304\n",
      "Epoch [9/10], Step [249/254], Image [7969/8158], Loss: 0.3673\n",
      "Epoch [9/10], Step [250/254], Image [8001/8158], Loss: 0.5872\n",
      "Epoch [9/10], Step [251/254], Image [8033/8158], Loss: 0.4775\n",
      "Epoch [9/10], Step [252/254], Image [8065/8158], Loss: 0.6214\n",
      "Epoch [9/10], Step [253/254], Image [8097/8158], Loss: 0.2310\n",
      "Epoch [9/10] completed. Average Loss: 0.3378\n",
      "Starting epoch 10 of 10...\n",
      "Epoch [10/10], Step [0/254], Image [1/8158], Loss: 0.1559\n",
      "Epoch [10/10], Step [1/254], Image [33/8158], Loss: 0.1892\n",
      "Epoch [10/10], Step [2/254], Image [65/8158], Loss: 0.5221\n",
      "Epoch [10/10], Step [3/254], Image [97/8158], Loss: 0.2428\n",
      "Epoch [10/10], Step [4/254], Image [129/8158], Loss: 0.1203\n",
      "Epoch [10/10], Step [5/254], Image [161/8158], Loss: 0.4663\n",
      "Epoch [10/10], Step [6/254], Image [193/8158], Loss: 0.5200\n",
      "Epoch [10/10], Step [7/254], Image [225/8158], Loss: 0.2023\n",
      "Epoch [10/10], Step [8/254], Image [257/8158], Loss: 0.4847\n",
      "Epoch [10/10], Step [9/254], Image [289/8158], Loss: 0.1717\n",
      "Epoch [10/10], Step [10/254], Image [321/8158], Loss: 0.2998\n",
      "Epoch [10/10], Step [11/254], Image [353/8158], Loss: 0.3097\n",
      "Epoch [10/10], Step [12/254], Image [385/8158], Loss: 0.2317\n",
      "Epoch [10/10], Step [13/254], Image [417/8158], Loss: 0.3719\n",
      "Epoch [10/10], Step [14/254], Image [449/8158], Loss: 0.6841\n",
      "Epoch [10/10], Step [15/254], Image [481/8158], Loss: 0.2285\n",
      "Epoch [10/10], Step [16/254], Image [513/8158], Loss: 0.2494\n",
      "Epoch [10/10], Step [17/254], Image [545/8158], Loss: 0.3436\n",
      "Epoch [10/10], Step [18/254], Image [577/8158], Loss: 0.3779\n",
      "Epoch [10/10], Step [19/254], Image [609/8158], Loss: 0.2295\n",
      "Epoch [10/10], Step [20/254], Image [641/8158], Loss: 0.6174\n",
      "Epoch [10/10], Step [21/254], Image [673/8158], Loss: 0.2262\n",
      "Epoch [10/10], Step [22/254], Image [705/8158], Loss: 0.2872\n",
      "Epoch [10/10], Step [23/254], Image [737/8158], Loss: 0.2971\n",
      "Epoch [10/10], Step [24/254], Image [769/8158], Loss: 0.1153\n",
      "Epoch [10/10], Step [25/254], Image [801/8158], Loss: 0.4373\n",
      "Epoch [10/10], Step [26/254], Image [833/8158], Loss: 0.2982\n",
      "Epoch [10/10], Step [27/254], Image [865/8158], Loss: 0.2236\n",
      "Epoch [10/10], Step [28/254], Image [897/8158], Loss: 0.2735\n",
      "Epoch [10/10], Step [29/254], Image [929/8158], Loss: 0.1706\n",
      "Epoch [10/10], Step [30/254], Image [961/8158], Loss: 0.4616\n",
      "Epoch [10/10], Step [31/254], Image [993/8158], Loss: 0.6208\n",
      "Epoch [10/10], Step [32/254], Image [1025/8158], Loss: 0.1582\n",
      "Epoch [10/10], Step [33/254], Image [1057/8158], Loss: 0.4904\n",
      "Epoch [10/10], Step [34/254], Image [1089/8158], Loss: 0.5579\n",
      "Epoch [10/10], Step [35/254], Image [1121/8158], Loss: 0.6812\n",
      "Epoch [10/10], Step [36/254], Image [1153/8158], Loss: 0.2804\n",
      "Epoch [10/10], Step [37/254], Image [1185/8158], Loss: 0.1992\n",
      "Epoch [10/10], Step [38/254], Image [1217/8158], Loss: 0.5291\n",
      "Epoch [10/10], Step [39/254], Image [1249/8158], Loss: 0.6223\n",
      "Epoch [10/10], Step [40/254], Image [1281/8158], Loss: 0.2484\n",
      "Epoch [10/10], Step [41/254], Image [1313/8158], Loss: 0.1581\n",
      "Epoch [10/10], Step [42/254], Image [1345/8158], Loss: 0.3253\n",
      "Epoch [10/10], Step [43/254], Image [1377/8158], Loss: 0.7114\n",
      "Epoch [10/10], Step [44/254], Image [1409/8158], Loss: 0.4368\n",
      "Epoch [10/10], Step [45/254], Image [1441/8158], Loss: 0.3666\n",
      "Epoch [10/10], Step [46/254], Image [1473/8158], Loss: 0.4292\n",
      "Epoch [10/10], Step [47/254], Image [1505/8158], Loss: 0.0897\n",
      "Epoch [10/10], Step [48/254], Image [1537/8158], Loss: 0.1712\n",
      "Epoch [10/10], Step [49/254], Image [1569/8158], Loss: 0.5731\n",
      "Epoch [10/10], Step [50/254], Image [1601/8158], Loss: 0.0887\n",
      "Epoch [10/10], Step [51/254], Image [1633/8158], Loss: 0.3354\n",
      "Epoch [10/10], Step [52/254], Image [1665/8158], Loss: 0.2879\n",
      "Epoch [10/10], Step [53/254], Image [1697/8158], Loss: 0.3117\n",
      "Epoch [10/10], Step [54/254], Image [1729/8158], Loss: 0.2047\n",
      "Epoch [10/10], Step [55/254], Image [1761/8158], Loss: 0.1382\n",
      "Epoch [10/10], Step [56/254], Image [1793/8158], Loss: 0.0978\n",
      "Epoch [10/10], Step [57/254], Image [1825/8158], Loss: 0.2793\n",
      "Epoch [10/10], Step [58/254], Image [1857/8158], Loss: 0.1896\n",
      "Epoch [10/10], Step [59/254], Image [1889/8158], Loss: 0.0788\n",
      "Epoch [10/10], Step [60/254], Image [1921/8158], Loss: 0.2183\n",
      "Epoch [10/10], Step [61/254], Image [1953/8158], Loss: 0.2160\n",
      "Epoch [10/10], Step [62/254], Image [1985/8158], Loss: 0.1858\n",
      "Epoch [10/10], Step [63/254], Image [2017/8158], Loss: 0.1669\n",
      "Epoch [10/10], Step [64/254], Image [2049/8158], Loss: 0.1221\n",
      "Epoch [10/10], Step [65/254], Image [2081/8158], Loss: 0.3751\n",
      "Epoch [10/10], Step [66/254], Image [2113/8158], Loss: 0.1342\n",
      "Epoch [10/10], Step [67/254], Image [2145/8158], Loss: 0.0833\n",
      "Epoch [10/10], Step [68/254], Image [2177/8158], Loss: 0.0285\n",
      "Epoch [10/10], Step [69/254], Image [2209/8158], Loss: 0.4189\n",
      "Epoch [10/10], Step [70/254], Image [2241/8158], Loss: 0.1238\n",
      "Epoch [10/10], Step [71/254], Image [2273/8158], Loss: 0.1565\n",
      "Epoch [10/10], Step [72/254], Image [2305/8158], Loss: 0.4613\n",
      "Epoch [10/10], Step [73/254], Image [2337/8158], Loss: 0.2274\n",
      "Epoch [10/10], Step [74/254], Image [2369/8158], Loss: 0.1061\n",
      "Epoch [10/10], Step [75/254], Image [2401/8158], Loss: 0.2084\n",
      "Epoch [10/10], Step [76/254], Image [2433/8158], Loss: 0.2451\n",
      "Epoch [10/10], Step [77/254], Image [2465/8158], Loss: 0.3865\n",
      "Epoch [10/10], Step [78/254], Image [2497/8158], Loss: 0.1481\n",
      "Epoch [10/10], Step [79/254], Image [2529/8158], Loss: 0.1393\n",
      "Epoch [10/10], Step [80/254], Image [2561/8158], Loss: 0.3292\n",
      "Epoch [10/10], Step [81/254], Image [2593/8158], Loss: 0.4084\n",
      "Epoch [10/10], Step [82/254], Image [2625/8158], Loss: 0.3510\n",
      "Epoch [10/10], Step [83/254], Image [2657/8158], Loss: 0.3767\n",
      "Epoch [10/10], Step [84/254], Image [2689/8158], Loss: 0.1916\n",
      "Epoch [10/10], Step [85/254], Image [2721/8158], Loss: 0.0978\n",
      "Epoch [10/10], Step [86/254], Image [2753/8158], Loss: 0.0740\n",
      "Epoch [10/10], Step [87/254], Image [2785/8158], Loss: 0.1563\n",
      "Epoch [10/10], Step [88/254], Image [2817/8158], Loss: 0.2883\n",
      "Epoch [10/10], Step [89/254], Image [2849/8158], Loss: 0.5543\n",
      "Epoch [10/10], Step [90/254], Image [2881/8158], Loss: 0.2295\n",
      "Epoch [10/10], Step [91/254], Image [2913/8158], Loss: 0.4011\n",
      "Epoch [10/10], Step [92/254], Image [2945/8158], Loss: 0.1656\n",
      "Epoch [10/10], Step [93/254], Image [2977/8158], Loss: 0.3473\n",
      "Epoch [10/10], Step [94/254], Image [3009/8158], Loss: 0.3705\n",
      "Epoch [10/10], Step [95/254], Image [3041/8158], Loss: 0.1774\n",
      "Epoch [10/10], Step [96/254], Image [3073/8158], Loss: 0.3398\n",
      "Epoch [10/10], Step [97/254], Image [3105/8158], Loss: 0.3135\n",
      "Epoch [10/10], Step [98/254], Image [3137/8158], Loss: 0.5478\n",
      "Epoch [10/10], Step [99/254], Image [3169/8158], Loss: 0.2192\n",
      "Epoch [10/10], Step [100/254], Image [3201/8158], Loss: 0.2914\n",
      "Epoch [10/10], Step [101/254], Image [3233/8158], Loss: 0.2640\n",
      "Epoch [10/10], Step [102/254], Image [3265/8158], Loss: 0.2811\n",
      "Epoch [10/10], Step [103/254], Image [3297/8158], Loss: 0.4133\n",
      "Epoch [10/10], Step [104/254], Image [3329/8158], Loss: 0.4534\n",
      "Epoch [10/10], Step [105/254], Image [3361/8158], Loss: 0.6246\n",
      "Epoch [10/10], Step [106/254], Image [3393/8158], Loss: 0.2510\n",
      "Epoch [10/10], Step [107/254], Image [3425/8158], Loss: 0.2275\n",
      "Epoch [10/10], Step [108/254], Image [3457/8158], Loss: 0.3595\n",
      "Epoch [10/10], Step [109/254], Image [3489/8158], Loss: 0.1148\n",
      "Epoch [10/10], Step [110/254], Image [3521/8158], Loss: 0.3708\n",
      "Epoch [10/10], Step [111/254], Image [3553/8158], Loss: 0.0911\n",
      "Epoch [10/10], Step [112/254], Image [3585/8158], Loss: 0.3908\n",
      "Epoch [10/10], Step [113/254], Image [3617/8158], Loss: 0.1860\n",
      "Epoch [10/10], Step [114/254], Image [3649/8158], Loss: 0.6443\n",
      "Epoch [10/10], Step [115/254], Image [3681/8158], Loss: 0.3472\n",
      "Epoch [10/10], Step [116/254], Image [3713/8158], Loss: 0.2590\n",
      "Epoch [10/10], Step [117/254], Image [3745/8158], Loss: 0.1419\n",
      "Epoch [10/10], Step [118/254], Image [3777/8158], Loss: 0.4552\n",
      "Epoch [10/10], Step [119/254], Image [3809/8158], Loss: 0.2733\n",
      "Epoch [10/10], Step [120/254], Image [3841/8158], Loss: 0.3701\n",
      "Epoch [10/10], Step [121/254], Image [3873/8158], Loss: 0.3704\n",
      "Epoch [10/10], Step [122/254], Image [3905/8158], Loss: 0.1677\n",
      "Epoch [10/10], Step [123/254], Image [3937/8158], Loss: 0.1933\n",
      "Epoch [10/10], Step [124/254], Image [3969/8158], Loss: 0.1497\n",
      "Epoch [10/10], Step [125/254], Image [4001/8158], Loss: 0.1829\n",
      "Epoch [10/10], Step [126/254], Image [4033/8158], Loss: 0.3159\n",
      "Epoch [10/10], Step [127/254], Image [4065/8158], Loss: 0.1788\n",
      "Epoch [10/10], Step [128/254], Image [4097/8158], Loss: 0.2789\n",
      "Epoch [10/10], Step [129/254], Image [4129/8158], Loss: 0.3749\n",
      "Epoch [10/10], Step [130/254], Image [4161/8158], Loss: 0.2123\n",
      "Epoch [10/10], Step [131/254], Image [4193/8158], Loss: 0.3887\n",
      "Epoch [10/10], Step [132/254], Image [4225/8158], Loss: 0.2964\n",
      "Epoch [10/10], Step [133/254], Image [4257/8158], Loss: 0.3266\n",
      "Epoch [10/10], Step [134/254], Image [4289/8158], Loss: 0.2494\n",
      "Epoch [10/10], Step [135/254], Image [4321/8158], Loss: 0.2995\n",
      "Epoch [10/10], Step [136/254], Image [4353/8158], Loss: 0.4854\n",
      "Epoch [10/10], Step [137/254], Image [4385/8158], Loss: 0.2816\n",
      "Epoch [10/10], Step [138/254], Image [4417/8158], Loss: 0.2741\n",
      "Epoch [10/10], Step [139/254], Image [4449/8158], Loss: 0.2397\n",
      "Epoch [10/10], Step [140/254], Image [4481/8158], Loss: 0.1781\n",
      "Epoch [10/10], Step [141/254], Image [4513/8158], Loss: 0.4725\n",
      "Epoch [10/10], Step [142/254], Image [4545/8158], Loss: 0.2699\n",
      "Epoch [10/10], Step [143/254], Image [4577/8158], Loss: 0.3022\n",
      "Epoch [10/10], Step [144/254], Image [4609/8158], Loss: 0.1061\n",
      "Epoch [10/10], Step [145/254], Image [4641/8158], Loss: 0.0110\n",
      "Epoch [10/10], Step [146/254], Image [4673/8158], Loss: 0.1226\n",
      "Epoch [10/10], Step [147/254], Image [4705/8158], Loss: 0.3771\n",
      "Epoch [10/10], Step [148/254], Image [4737/8158], Loss: 0.2370\n",
      "Epoch [10/10], Step [149/254], Image [4769/8158], Loss: 0.0511\n",
      "Epoch [10/10], Step [150/254], Image [4801/8158], Loss: 0.7255\n",
      "Epoch [10/10], Step [151/254], Image [4833/8158], Loss: 0.3590\n",
      "Epoch [10/10], Step [152/254], Image [4865/8158], Loss: 0.4131\n",
      "Epoch [10/10], Step [153/254], Image [4897/8158], Loss: 0.1321\n",
      "Epoch [10/10], Step [154/254], Image [4929/8158], Loss: 0.4514\n",
      "Epoch [10/10], Step [155/254], Image [4961/8158], Loss: 0.3206\n",
      "Epoch [10/10], Step [156/254], Image [4993/8158], Loss: 0.1459\n",
      "Epoch [10/10], Step [157/254], Image [5025/8158], Loss: 0.2316\n",
      "Epoch [10/10], Step [158/254], Image [5057/8158], Loss: 0.3926\n",
      "Epoch [10/10], Step [159/254], Image [5089/8158], Loss: 0.1605\n",
      "Epoch [10/10], Step [160/254], Image [5121/8158], Loss: 0.3187\n",
      "Epoch [10/10], Step [161/254], Image [5153/8158], Loss: 0.2453\n",
      "Epoch [10/10], Step [162/254], Image [5185/8158], Loss: 0.1331\n",
      "Epoch [10/10], Step [163/254], Image [5217/8158], Loss: 0.1216\n",
      "Epoch [10/10], Step [164/254], Image [5249/8158], Loss: 0.1422\n",
      "Epoch [10/10], Step [165/254], Image [5281/8158], Loss: 0.2937\n",
      "Epoch [10/10], Step [166/254], Image [5313/8158], Loss: 0.0994\n",
      "Epoch [10/10], Step [167/254], Image [5345/8158], Loss: 0.7851\n",
      "Epoch [10/10], Step [168/254], Image [5377/8158], Loss: 0.1521\n",
      "Epoch [10/10], Step [169/254], Image [5409/8158], Loss: 0.5679\n",
      "Epoch [10/10], Step [170/254], Image [5441/8158], Loss: 0.7180\n",
      "Epoch [10/10], Step [171/254], Image [5473/8158], Loss: 0.1769\n",
      "Epoch [10/10], Step [172/254], Image [5505/8158], Loss: 0.3340\n",
      "Epoch [10/10], Step [173/254], Image [5537/8158], Loss: 0.0561\n",
      "Epoch [10/10], Step [174/254], Image [5569/8158], Loss: 0.6017\n",
      "Epoch [10/10], Step [175/254], Image [5601/8158], Loss: 0.3530\n",
      "Epoch [10/10], Step [176/254], Image [5633/8158], Loss: 0.1082\n",
      "Epoch [10/10], Step [177/254], Image [5665/8158], Loss: 0.1923\n",
      "Epoch [10/10], Step [178/254], Image [5697/8158], Loss: 0.6305\n",
      "Epoch [10/10], Step [179/254], Image [5729/8158], Loss: 0.1020\n",
      "Epoch [10/10], Step [180/254], Image [5761/8158], Loss: 0.6504\n",
      "Epoch [10/10], Step [181/254], Image [5793/8158], Loss: 0.2583\n",
      "Epoch [10/10], Step [182/254], Image [5825/8158], Loss: 0.4271\n",
      "Epoch [10/10], Step [183/254], Image [5857/8158], Loss: 0.2583\n",
      "Epoch [10/10], Step [184/254], Image [5889/8158], Loss: 0.3945\n",
      "Epoch [10/10], Step [185/254], Image [5921/8158], Loss: 0.5116\n",
      "Epoch [10/10], Step [186/254], Image [5953/8158], Loss: 0.0874\n",
      "Epoch [10/10], Step [187/254], Image [5985/8158], Loss: 0.7167\n",
      "Epoch [10/10], Step [188/254], Image [6017/8158], Loss: 0.2577\n",
      "Epoch [10/10], Step [189/254], Image [6049/8158], Loss: 0.2101\n",
      "Epoch [10/10], Step [190/254], Image [6081/8158], Loss: 0.2276\n",
      "Epoch [10/10], Step [191/254], Image [6113/8158], Loss: 0.3958\n",
      "Epoch [10/10], Step [192/254], Image [6145/8158], Loss: 0.1190\n",
      "Epoch [10/10], Step [193/254], Image [6177/8158], Loss: 0.3086\n",
      "Epoch [10/10], Step [194/254], Image [6209/8158], Loss: 0.0370\n",
      "Epoch [10/10], Step [195/254], Image [6241/8158], Loss: 0.2087\n",
      "Epoch [10/10], Step [196/254], Image [6273/8158], Loss: 0.3007\n",
      "Epoch [10/10], Step [197/254], Image [6305/8158], Loss: 0.2060\n",
      "Epoch [10/10], Step [198/254], Image [6337/8158], Loss: 0.2283\n",
      "Epoch [10/10], Step [199/254], Image [6369/8158], Loss: 0.3501\n",
      "Epoch [10/10], Step [200/254], Image [6401/8158], Loss: 0.0652\n",
      "Epoch [10/10], Step [201/254], Image [6433/8158], Loss: 0.2340\n",
      "Epoch [10/10], Step [202/254], Image [6465/8158], Loss: 0.3202\n",
      "Epoch [10/10], Step [203/254], Image [6497/8158], Loss: 0.1927\n",
      "Epoch [10/10], Step [204/254], Image [6529/8158], Loss: 0.6146\n",
      "Epoch [10/10], Step [205/254], Image [6561/8158], Loss: 0.0712\n",
      "Epoch [10/10], Step [206/254], Image [6593/8158], Loss: 0.1087\n",
      "Epoch [10/10], Step [207/254], Image [6625/8158], Loss: 0.1210\n",
      "Epoch [10/10], Step [208/254], Image [6657/8158], Loss: 0.1613\n",
      "Epoch [10/10], Step [209/254], Image [6689/8158], Loss: 0.4843\n",
      "Epoch [10/10], Step [210/254], Image [6721/8158], Loss: 0.2257\n",
      "Epoch [10/10], Step [211/254], Image [6753/8158], Loss: 0.3339\n",
      "Epoch [10/10], Step [212/254], Image [6785/8158], Loss: 0.3114\n",
      "Epoch [10/10], Step [213/254], Image [6817/8158], Loss: 0.4722\n",
      "Epoch [10/10], Step [214/254], Image [6849/8158], Loss: 0.0947\n",
      "Epoch [10/10], Step [215/254], Image [6881/8158], Loss: 0.3659\n",
      "Epoch [10/10], Step [216/254], Image [6913/8158], Loss: 0.7351\n",
      "Epoch [10/10], Step [217/254], Image [6945/8158], Loss: 0.5400\n",
      "Epoch [10/10], Step [218/254], Image [6977/8158], Loss: 0.3402\n",
      "Epoch [10/10], Step [219/254], Image [7009/8158], Loss: 0.3224\n",
      "Epoch [10/10], Step [220/254], Image [7041/8158], Loss: 0.2788\n",
      "Epoch [10/10], Step [221/254], Image [7073/8158], Loss: 0.3330\n",
      "Epoch [10/10], Step [222/254], Image [7105/8158], Loss: 0.1148\n",
      "Epoch [10/10], Step [223/254], Image [7137/8158], Loss: 0.1275\n",
      "Epoch [10/10], Step [224/254], Image [7169/8158], Loss: 0.5416\n",
      "Epoch [10/10], Step [225/254], Image [7201/8158], Loss: 0.2749\n",
      "Epoch [10/10], Step [226/254], Image [7233/8158], Loss: 0.4139\n",
      "Epoch [10/10], Step [227/254], Image [7265/8158], Loss: 0.2593\n",
      "Epoch [10/10], Step [228/254], Image [7297/8158], Loss: 0.1880\n",
      "Epoch [10/10], Step [229/254], Image [7329/8158], Loss: 0.1862\n",
      "Epoch [10/10], Step [230/254], Image [7361/8158], Loss: 0.3101\n",
      "Epoch [10/10], Step [231/254], Image [7393/8158], Loss: 0.2372\n",
      "Epoch [10/10], Step [232/254], Image [7425/8158], Loss: 0.1727\n",
      "Epoch [10/10], Step [233/254], Image [7457/8158], Loss: 0.2311\n",
      "Epoch [10/10], Step [234/254], Image [7489/8158], Loss: 0.2007\n",
      "Epoch [10/10], Step [235/254], Image [7521/8158], Loss: 0.4469\n",
      "Epoch [10/10], Step [236/254], Image [7553/8158], Loss: 0.2711\n",
      "Epoch [10/10], Step [237/254], Image [7585/8158], Loss: 0.2895\n",
      "Epoch [10/10], Step [238/254], Image [7617/8158], Loss: 0.4117\n",
      "Epoch [10/10], Step [239/254], Image [7649/8158], Loss: 0.3031\n",
      "Epoch [10/10], Step [240/254], Image [7681/8158], Loss: 0.4140\n",
      "Epoch [10/10], Step [241/254], Image [7713/8158], Loss: 0.1305\n",
      "Epoch [10/10], Step [242/254], Image [7745/8158], Loss: 0.1636\n",
      "Epoch [10/10], Step [243/254], Image [7777/8158], Loss: 0.1090\n",
      "Epoch [10/10], Step [244/254], Image [7809/8158], Loss: 0.4095\n",
      "Epoch [10/10], Step [245/254], Image [7841/8158], Loss: 0.4654\n",
      "Epoch [10/10], Step [246/254], Image [7873/8158], Loss: 0.4161\n",
      "Epoch [10/10], Step [247/254], Image [7905/8158], Loss: 0.2147\n",
      "Epoch [10/10], Step [248/254], Image [7937/8158], Loss: 0.2001\n",
      "Epoch [10/10], Step [249/254], Image [7969/8158], Loss: 0.2451\n",
      "Epoch [10/10], Step [250/254], Image [8001/8158], Loss: 0.4940\n",
      "Epoch [10/10], Step [251/254], Image [8033/8158], Loss: 0.4713\n",
      "Epoch [10/10], Step [252/254], Image [8065/8158], Loss: 0.2714\n",
      "Epoch [10/10], Step [253/254], Image [8097/8158], Loss: 0.4145\n",
      "Epoch [10/10] completed. Average Loss: 0.2973\n",
      "Training complete. Model saved as 'simclr_model1.pth'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    image_folder = r\"C:\\images\"  # Path to your downloaded images folder\n",
    "    train_simclr(image_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
